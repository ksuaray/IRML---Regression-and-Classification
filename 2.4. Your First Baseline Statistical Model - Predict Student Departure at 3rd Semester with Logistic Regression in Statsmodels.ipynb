{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4c20ed1-b00f-4161-b883-6c3186108595",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83b297e1-8e5b-4d92-8183-97c0522e1f53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05467699-f3b0-4772-a155-76983006cde4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Introduction\n",
    "\n",
    "This is what we're here for. The world we live in thrives on information that yearns to be analyzed. Big tech has effectively used statistical and machine learning algorithms to glean critical, just in-time actionable insights from complex data. We've built up a mutifaceted understanding of our data and are ready to transition from observing patterns and relationships to utilizing these relationships to estimate and predict outcomes for new data.\n",
    "\n",
    "\n",
    " **Pandas**, **NumPy**, **Plotly** and **Scikit Learn** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02024745-9c54-499f-8739-6828d2dbeb24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Learning Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68027bca-7f06-4bec-812c-853bfadede47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Upon completion of this module, you will be able to \n",
    "\n",
    "**LO1: Translate Higher Education Challenges into Machine Learning Tasks.**\n",
    "\n",
    "**LO2: Prepare Machine Learning-Ready Data Using Pandas for Effective Feature Engineering.**\n",
    "\n",
    "**LO3:  Develop, Optimize, and Evaluate the Logistic Regression Model for Classifying Qualitative Variables in Education Using Scikit Learn.**\n",
    "\n",
    "**LO4: Deploy Trained Machine Learning Models to Facilitate High-Stakes Decision-Making in Higher Education.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5274f662-ea47-417e-861b-947930b252fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "258c8d4c-0d41-4ef7-94d7-a3b925c0547c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "###Higher Education Challenge: Modeling Retention/Dropout for Enrollment Management\n",
    "\n",
    "Shontelle has been an experienced administrator in higher education for over a decade, but nothing could have prepared her for the massive changes that resulted from covid-19 pandemic. As part of her job duties, she had overseen eight straight years of continued growth in enrollment of first year students to her university. All of a sudden, enrollment was dropping fast. Not only because of less applicants, but also students who started  out at the university were dropping out more often. As a first generation student herself, Shontelle is passionate about what a college degree can do for a family and their community. As an administrator, she is also aware that FTES impact the university's bottom line. While she understands that outreach and recruitment are critical processes that can help stop the bleeding, she directs her efforts toward retention - making sure matriculated students persist and have a viable path to graduation. In a three pronged approach, she \n",
    "\n",
    " - works with faculty in the Education department to conduct focus groups with first year students to hear about the chalenges they face that may make persistence to year 2 difficult. \n",
    " - conducts a thorough literature review to learn from others what best practices have emerged to promote persistence.\n",
    " - requests data from her Institutional Research team with the goal of supplementing the qualitative findings with quantitative insights. Her recent enrollment in the Machine Learning in Higher Education Certificate provides a perfect opportunity for her to analyze the data.\n",
    " \n",
    "These three streams of information will inform the policy recommendations she makes to the university president.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdeef194-ee0b-40aa-85c4-c80d5ab77e62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb02faa6-d4c8-4f2a-80ff-ca16c9708d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4adf9716-1137-440f-ab41-b86663d73ce8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d709f138-a7bc-4893-8561-b8d62b6922e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's use Python to determine how Shontelle can use institutional data to create predictive tools that will help inform her policy choices. Her Higher Ed model building challenge can be distilled into the following research statement:\n",
    "\n",
    "**For the population of students with high school data available in our database, and whose initial course enrollment at our instiution was as matriculated first time - first year students, how can we build a statistical/machine learning model that uses student data available at the end of semester 2 to predict student departure in semester 3?**\n",
    "\n",
    "**Population: The most recent cohort of students with high school data recorded, and semester 3 university data available**\n",
    "\n",
    "**Question:  How can we build a statistical model that utilizes student data available at the end of semester 2 to predict departure in semester 3?**\n",
    "\n",
    "\n",
    "This problem statement can be generalized to a wider population or tailored to a different sub population (such as transfer or international students).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65735c6b-a338-44ac-ad41-becd2d380343",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b68074fe-7f6d-4ca1-99a2-2f1c0f54129c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In Module 2: *Magic Pandas Library: Mastering Higher Education Data Preparation and Analysis*, we learned how to merge data that originated from multiple sources accross campus. The High School, Enrollment, Admissions, Course and Completion datasets all provide valuable information to assist us in our effort to predict students metrics in future semesters. As you recall, we've selected a subset of the variables from these data to include in the modeling phase. These include:\n",
    "1. Academic Performance Data\n",
    "\n",
    "      - Available at time of admission: high school GPAs\n",
    "\n",
    "      - Available at time of modeling: units attempted, completed, DFW, postsecondary GPAs available at time of modeling \n",
    "2. Demographic Data\n",
    "      - Gender, ethnicity, first gen status \n",
    "\n",
    "3. The target variable, **SEM_3_STATUS**, a qualitative variable coded as follows:\n",
    "\n",
    "| Code | Meaning | \n",
    "|---|---|\n",
    "|C |Continuing |\n",
    "|NR |Not Reached |\n",
    "|GD |Gap taken or Dropped |\n",
    "\n",
    "\n",
    "Let's load the necessary Python libraries to import the data and start to process it for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9aac7bb-f404-4e43-ab2e-0be51acb353e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Libraries for importing and preparing data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b918d3-219a-4f99-b6f9-14f26e4cd964",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We'll be executing quite a few commands that insert randomnes into the process, which will result in different answers every time we (and you) run this code. We can ensure reproducibility by setting a global seed for this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "108a5e1f-e866-4908-b169-56fced81d038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rms = 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d52baab-3fc5-4a9f-843f-34c313e98287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8597f1bc-fa06-4b62-9d02-11d7db751c55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now let's import the **final_out_retention** data we've been working with. Then, by typing the name we assign it, we can scope out the top and bottom 5 rows of the DataFrame and view its basic attributes in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2df1d965-9e91-4410-a895-f5adc652771e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>ENROLLMENT_YEAR</th>\n",
       "      <th>ENROLLMENT_TERM</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>FIRST_SEM_W</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>DFW_UNITS_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>CUM_GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>DFW_UNITS_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>CUM_GPA_2</th>\n",
       "      <th>UNITS_ATTEMPTED_3</th>\n",
       "      <th>UNITS_COMPLETED_3</th>\n",
       "      <th>DFW_UNITS_3</th>\n",
       "      <th>GPA_3</th>\n",
       "      <th>CUM_GPA_3</th>\n",
       "      <th>UNITS_ATTEMPTED_4</th>\n",
       "      <th>UNITS_COMPLETED_4</th>\n",
       "      <th>DFW_UNITS_4</th>\n",
       "      <th>GPA_4</th>\n",
       "      <th>CUM_GPA_4</th>\n",
       "      <th>SEM_3_STATUS</th>\n",
       "      <th>SEM_4_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000GPJ93V</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20204</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GD</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000M7YLAX</td>\n",
       "      <td>2015</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20154</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.588235</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000NSOJN5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.842105</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.921053</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000O3VNKL</td>\n",
       "      <td>2022</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20224</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.48</td>\n",
       "      <td>3.81</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NR</td>\n",
       "      <td>NR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000VJZY7Q</td>\n",
       "      <td>2011</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20114</td>\n",
       "      <td>Nonresident alien</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>2.562500</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.764706</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.769231</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.176471</td>\n",
       "      <td>2.825397</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108477</th>\n",
       "      <td>ZB7E7YA6N</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20204</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.07</td>\n",
       "      <td>2.88</td>\n",
       "      <td>3.38</td>\n",
       "      <td>Business</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.636364</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108478</th>\n",
       "      <td>ZMPYZ9E5I</td>\n",
       "      <td>2010</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20104</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.384615</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108479</th>\n",
       "      <td>ZQNCEV86E</td>\n",
       "      <td>2014</td>\n",
       "      <td>Spring</td>\n",
       "      <td>20142</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.111111</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108480</th>\n",
       "      <td>ZWH3KOPGP</td>\n",
       "      <td>2020</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20204</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.052632</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.117647</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108481</th>\n",
       "      <td>ZZUHM1SQ0</td>\n",
       "      <td>2018</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20184</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108482 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SID</th>\n      <th>ENROLLMENT_YEAR</th>\n      <th>ENROLLMENT_TERM</th>\n      <th>COHORT</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>FIRST_SEM_W</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>DFW_UNITS_1</th>\n      <th>GPA_1</th>\n      <th>CUM_GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>DFW_UNITS_2</th>\n      <th>GPA_2</th>\n      <th>CUM_GPA_2</th>\n      <th>UNITS_ATTEMPTED_3</th>\n      <th>UNITS_COMPLETED_3</th>\n      <th>DFW_UNITS_3</th>\n      <th>GPA_3</th>\n      <th>CUM_GPA_3</th>\n      <th>UNITS_ATTEMPTED_4</th>\n      <th>UNITS_COMPLETED_4</th>\n      <th>DFW_UNITS_4</th>\n      <th>GPA_4</th>\n      <th>CUM_GPA_4</th>\n      <th>SEM_3_STATUS</th>\n      <th>SEM_4_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>000GPJ93V</td>\n      <td>2020</td>\n      <td>Fall</td>\n      <td>20204</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>8.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>3.125000</td>\n      <td>3.125000</td>\n      <td>10.0</td>\n      <td>7.0</td>\n      <td>3.0</td>\n      <td>1.900000</td>\n      <td>2.444444</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>GD</td>\n      <td>GD</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000M7YLAX</td>\n      <td>2015</td>\n      <td>Fall</td>\n      <td>20154</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>2.250000</td>\n      <td>2.250000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.250000</td>\n      <td>2.250000</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>3.0</td>\n      <td>2.400000</td>\n      <td>2.307692</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.500000</td>\n      <td>2.588235</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000NSOJN5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.666667</td>\n      <td>3.666667</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.842105</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.892857</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.921053</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000O3VNKL</td>\n      <td>2022</td>\n      <td>Fall</td>\n      <td>20224</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.63</td>\n      <td>3.48</td>\n      <td>3.81</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>12.0</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NR</td>\n      <td>NR</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>000VJZY7Q</td>\n      <td>2011</td>\n      <td>Fall</td>\n      <td>20114</td>\n      <td>Nonresident alien</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>2.562500</td>\n      <td>2.562500</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>2.764706</td>\n      <td>2.666667</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>2.769231</td>\n      <td>2.695652</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>3.176471</td>\n      <td>2.825397</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108477</th>\n      <td>ZB7E7YA6N</td>\n      <td>2020</td>\n      <td>Fall</td>\n      <td>20204</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.07</td>\n      <td>2.88</td>\n      <td>3.38</td>\n      <td>Business</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>1.800000</td>\n      <td>1.800000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.250000</td>\n      <td>2.000000</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.000000</td>\n      <td>1.636364</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108478</th>\n      <td>ZMPYZ9E5I</td>\n      <td>2010</td>\n      <td>Fall</td>\n      <td>20104</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Liberal Arts</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.0</td>\n      <td>3.0</td>\n      <td>12.0</td>\n      <td>1.200000</td>\n      <td>1.200000</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>2.750000</td>\n      <td>1.888889</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.500000</td>\n      <td>2.384615</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108479</th>\n      <td>ZQNCEV86E</td>\n      <td>2014</td>\n      <td>Spring</td>\n      <td>20142</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Health</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>2.666667</td>\n      <td>2.666667</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>2.833333</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.666667</td>\n      <td>3.111111</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108480</th>\n      <td>ZWH3KOPGP</td>\n      <td>2020</td>\n      <td>Fall</td>\n      <td>20204</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Health</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>3.500000</td>\n      <td>3.500000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>2.846154</td>\n      <td>3.052632</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>3.200000</td>\n      <td>3.117647</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108481</th>\n      <td>ZZUHM1SQ0</td>\n      <td>2018</td>\n      <td>Fall</td>\n      <td>20184</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Liberal Arts</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n  </tbody>\n</table>\n<p>108482 rows × 34 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's ensure that we can view all columns of the dataframe, along with a head and tail look at the data\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "retention = pd.read_csv('/dbfs/FileStore/ml-file-store/bronze/final_out_retention.csv')\n",
    "\n",
    "retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e160991a-7385-4c6d-a972-687eb286f3d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Supervised learning cannot occur if the target is not observed. So let's determine whether any observations of the SEM_3_STATUS variable are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbb6c2eb-22d3-4c04-83be-9082f650299f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[5]: 0"
     ]
    }
   ],
   "source": [
    "retention['SEM_3_STATUS'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a752ad5b-fb9e-498e-b041-927c0599f65e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "No missing values, so we may proceed. Let's investigate the distribution of outcomes for our target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7537f742-edb3-4e04-a9af-c35112993b87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[6]: C     94586\nNR     7908\nGD     5988\nName: SEM_3_STATUS, dtype: int64"
     ]
    }
   ],
   "source": [
    "pd.value_counts(retention['SEM_3_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81daef1d-0e95-498f-b69a-87498524844d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Clearly the vast majority of students in our data persist through the third term. This is obviously a desired outcome, but the preponderance of retained students and scarcity of those who leave inherently makes our stated objective challenging. In the face of this challenge our task remains unchanged: use our classification model to reliably predict whether a student is a member of the minority class: those who leave the university for a variety of reasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd051737-d0b3-4783-a7cb-2170372f40cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c676a2cd-d27e-4659-840b-d826f5fc4678",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data availability is a necessary condition for data analysis, but it is not sufficient. There are a number of modifications we need to make to the data to prepare it for machine learning. The process of preparing the data for exploration and modeling is known as **data wrangling**, and will be performed here. \n",
    "To answer Shontelle's question, we need to build a model using cohorts for which term 3 grade data has already been collected. Thus we subset the data to create a dataframe consisting of the most recent cohort for which this is true, Fall 2021:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45471c47-ab80-41c7-81ca-0475353e6846",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>ENROLLMENT_YEAR</th>\n",
       "      <th>ENROLLMENT_TERM</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>FIRST_SEM_W</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>DFW_UNITS_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>CUM_GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>DFW_UNITS_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>CUM_GPA_2</th>\n",
       "      <th>UNITS_ATTEMPTED_3</th>\n",
       "      <th>UNITS_COMPLETED_3</th>\n",
       "      <th>DFW_UNITS_3</th>\n",
       "      <th>GPA_3</th>\n",
       "      <th>CUM_GPA_3</th>\n",
       "      <th>UNITS_ATTEMPTED_4</th>\n",
       "      <th>UNITS_COMPLETED_4</th>\n",
       "      <th>DFW_UNITS_4</th>\n",
       "      <th>GPA_4</th>\n",
       "      <th>CUM_GPA_4</th>\n",
       "      <th>SEM_3_STATUS</th>\n",
       "      <th>SEM_4_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000NSOJN5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.842105</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.892857</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.921053</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>006D4XDFZ</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.69</td>\n",
       "      <td>3.84</td>\n",
       "      <td>University Programs</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.828571</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.153846</td>\n",
       "      <td>3.645833</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>008KHPY7J</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00B7BSZKV</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>2.884615</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.061224</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>00FJI6JWK</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.294118</td>\n",
       "      <td>3.172414</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>3.048780</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.357143</td>\n",
       "      <td>3.127273</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108438</th>\n",
       "      <td>U9HW6MZNG</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>4.16</td>\n",
       "      <td>4.12</td>\n",
       "      <td>4.14</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.363636</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108440</th>\n",
       "      <td>UDDOGFL75</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3.714286</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108446</th>\n",
       "      <td>VNU2TKAMS</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Arts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108459</th>\n",
       "      <td>XAT5B0ZJF</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.98</td>\n",
       "      <td>3.04</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3.272727</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108467</th>\n",
       "      <td>YGBWF02SG</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>GD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7945 rows × 34 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SID</th>\n      <th>ENROLLMENT_YEAR</th>\n      <th>ENROLLMENT_TERM</th>\n      <th>COHORT</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>FIRST_SEM_W</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>DFW_UNITS_1</th>\n      <th>GPA_1</th>\n      <th>CUM_GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>DFW_UNITS_2</th>\n      <th>GPA_2</th>\n      <th>CUM_GPA_2</th>\n      <th>UNITS_ATTEMPTED_3</th>\n      <th>UNITS_COMPLETED_3</th>\n      <th>DFW_UNITS_3</th>\n      <th>GPA_3</th>\n      <th>CUM_GPA_3</th>\n      <th>UNITS_ATTEMPTED_4</th>\n      <th>UNITS_COMPLETED_4</th>\n      <th>DFW_UNITS_4</th>\n      <th>GPA_4</th>\n      <th>CUM_GPA_4</th>\n      <th>SEM_3_STATUS</th>\n      <th>SEM_4_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>000NSOJN5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Unknown</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.666667</td>\n      <td>3.666667</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.842105</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.892857</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.921053</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>006D4XDFZ</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.66</td>\n      <td>3.69</td>\n      <td>3.84</td>\n      <td>University Programs</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.750000</td>\n      <td>3.750000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.750000</td>\n      <td>3.750000</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>3.828571</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>3.153846</td>\n      <td>3.645833</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>008KHPY7J</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>2.571429</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>3.0</td>\n      <td>2.000000</td>\n      <td>2.400000</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.666667</td>\n      <td>2.000000</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>00B7BSZKV</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>13.0</td>\n      <td>10.0</td>\n      <td>3.0</td>\n      <td>2.307692</td>\n      <td>2.307692</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>3.461538</td>\n      <td>2.884615</td>\n      <td>10.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>2.916667</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>0.0</td>\n      <td>3.461538</td>\n      <td>3.061224</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>00FJI6JWK</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>17.0</td>\n      <td>17.0</td>\n      <td>0.0</td>\n      <td>3.294118</td>\n      <td>3.172414</td>\n      <td>12.0</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>2.750000</td>\n      <td>3.048780</td>\n      <td>14.0</td>\n      <td>14.0</td>\n      <td>0.0</td>\n      <td>3.357143</td>\n      <td>3.127273</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>108438</th>\n      <td>U9HW6MZNG</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>4.16</td>\n      <td>4.12</td>\n      <td>4.14</td>\n      <td>Engineering</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>3.600000</td>\n      <td>3.600000</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>3.200000</td>\n      <td>3.400000</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.000000</td>\n      <td>3.363636</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108440</th>\n      <td>UDDOGFL75</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Liberal Arts</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>4.000000</td>\n      <td>4.000000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.333333</td>\n      <td>3.714286</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>3.800000</td>\n      <td>3.750000</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108446</th>\n      <td>VNU2TKAMS</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Arts</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>9.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>0.666667</td>\n      <td>0.666667</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.000000</td>\n      <td>0.222222</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108459</th>\n      <td>XAT5B0ZJF</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.16</td>\n      <td>2.98</td>\n      <td>3.04</td>\n      <td>Liberal Arts</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.500000</td>\n      <td>2.500000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>3.750000</td>\n      <td>3.125000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.666667</td>\n      <td>3.272727</td>\n      <td>C</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>108467</th>\n      <td>YGBWF02SG</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Engineering</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>2.500000</td>\n      <td>1.666667</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>C</td>\n      <td>GD</td>\n    </tr>\n  </tbody>\n</table>\n<p>7945 rows × 34 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "retention21 = retention[retention['COHORT']==20214]\n",
    "retention21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25bf7047-5c1c-49a2-8d46-5ea175febe0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is will be our primary dataframe for this analysis. It consists of 7,945 observations, uniquely identified by SID (as well as their row index from the original **fry** data frame), and 33 variables. Note that selecting this cohort removes all NR values from our target: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5639465-f5e1-4fc1-bbc0-7befa01878e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[8]: C     7271\nGD     674\nName: SEM_3_STATUS, dtype: int64"
     ]
    }
   ],
   "source": [
    "pd.value_counts(retention21['SEM_3_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab389408-49f8-468d-ab0b-878a09604d30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: Why were all of the *NR* values removed from the SEM_3_STATUS variable when we selected the Fall 2021 cohort?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bacb8e7e-7036-4224-8100-d4c1e08ee6f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The removal of the *NR* values is a good thing, but there are clearly some challenges we'll need to overcome in the composition of our data:\n",
    "\n",
    " - Class imbalance in target\n",
    " - Rare classes in features\n",
    " - Missing values in features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "46a5f94c-f52b-407f-b9b7-e7efa0aa77a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First of all, there is definitely some ***imbalance*** in the data; the split between our two classes is not even close to 50-50. This will be addressed below\n",
    "\n",
    "Next, note let's take a look at the distribution of values in our qualitative variables. If it turns out that there are some values that are rare, they could cause issues with our downstream data processing. One way to avoid this is to consolidate rare classes into one. Note that consolidating or dropping variables is not a reflection of their importance or relevance to the analysis; instead they highlight one of the limitations of machine learning and the importance of human oversight to create a legitimate representation of the truth. \n",
    "\n",
    "Let's investigate the class distribution for **RACE_ETHNICITY** and consolidate rare occurences into an 'Other' class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63743149-1787-4400-9035-cce0a5b203de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[9]: Hispanic                                     3922\nAsian                                        1624\nWhite                                        1255\nNonresident alien                             348\nTwo or More Races                             325\nBlack or African American                     298\nUnknown                                       149\nNative Hawaiian or Other Pacific Islander      14\nAmerican Indian or Alaska Native               10\nName: RACE_ETHNICITY, dtype: int64"
     ]
    }
   ],
   "source": [
    "#Distribution of classes in RACE_ETHNICITY\n",
    "pd.value_counts(retention21['RACE_ETHNICITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fdf2833-ac4e-44b4-a2b6-7e38f8abf0ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/pandas/core/indexing.py:1817: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value, pi)\nOut[10]: Hispanic                     3922\nAsian                        1624\nWhite                        1255\nNonresident alien             348\nTwo or More Races             325\nBlack or African American     298\nOther                         173\nName: RACE_ETHNICITY, dtype: int64"
     ]
    }
   ],
   "source": [
    "#Consolidating the three smallest classes into one 'Other' class\n",
    "condition = (retention21['RACE_ETHNICITY'] == 'American Indian or Alaska Native') | \\\n",
    "            (retention21['RACE_ETHNICITY'] == 'Native Hawaiian or Other Pacific Islander') | \\\n",
    "            (retention21['RACE_ETHNICITY'] == 'Unknown')\n",
    "\n",
    "# Get the original indices where the condition is true using loc\n",
    "indices_true = retention21.loc[condition].index\n",
    "\n",
    "# Update 'RACE_ETHNICITY' to 'Other' for rows with true condition\n",
    "retention21.loc[indices_true, 'RACE_ETHNICITY'] = 'Other'\n",
    "\n",
    "pd.value_counts(retention21['RACE_ETHNICITY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd111467-83b3-4079-8072-db73b8f3c19c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Investigating **FIRST_GEN_STATUS**, it is clear that this is not an issue in this case, as no classes are rare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ab464f1-1b93-4142-a9fa-59d26914facb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[11]: Continuing Generation    4707\nFirst Generation         2508\nUnknown                   730\nName: FIRST_GEN_STATUS, dtype: int64"
     ]
    }
   ],
   "source": [
    "#Distribution of classes in FIRST_GEN_STATUS\n",
    "pd.value_counts(retention21['FIRST_GEN_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e394ad3-5142-41b5-884a-5a14bfba8b5e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Finally, for **GENDER**, we drop the rare Non-binary class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea97a7b3-8aff-4d57-9a48-a2c1bba49cd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[12]: Female        4780\nMale          3149\nNon-binary      16\nName: GENDER, dtype: int64"
     ]
    }
   ],
   "source": [
    "#Distribution of classes in GENDER\n",
    "pd.value_counts(retention21['GENDER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8bdaa3b-bee8-444b-b23c-40307bff89fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retention21a = retention21[~(retention21['GENDER']=='Non-binary')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7508fdf7-2885-4d58-9a1d-14bcf2b1e38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next, a quick glance indicates we've got some missing values. We'll address this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de464602-4f0a-444b-a633-e16700e6c139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: SID                     0\nENROLLMENT_YEAR         0\nENROLLMENT_TERM         0\nCOHORT                  0\nRACE_ETHNICITY          0\nGENDER                  0\nFIRST_GEN_STATUS        0\nHS_GPA               2793\nHS_MATH_GPA          2793\nHS_ENGL_GPA          2793\nCOLLEGE                 0\nFIRST_SEM_W             0\nUNITS_ATTEMPTED_1       0\nUNITS_COMPLETED_1       0\nDFW_UNITS_1             0\nGPA_1                   0\nCUM_GPA_1               0\nUNITS_ATTEMPTED_2       0\nUNITS_COMPLETED_2       0\nDFW_UNITS_2             0\nGPA_2                   0\nCUM_GPA_2               0\nUNITS_ATTEMPTED_3     674\nUNITS_COMPLETED_3     674\nDFW_UNITS_3           674\nGPA_3                 674\nCUM_GPA_3             674\nUNITS_ATTEMPTED_4    1219\nUNITS_COMPLETED_4    1219\nDFW_UNITS_4          1219\nGPA_4                1219\nCUM_GPA_4            1219\nSEM_3_STATUS            0\nSEM_4_STATUS            0\ndtype: int64"
     ]
    }
   ],
   "source": [
    "retention21a.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4581e111-0c14-4e3c-8ade-17c28fb3b1d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As mentioned in *Module 3: Explaining the Machine Learning Cycle Without Hyperparameter Tuning* we observed that a learning algorithm is only useful to the extent that we can confidently apply it to unseen data to make accurate predictions. The ability to generalize is measured by an investigation of model performance on a random sample of the full data called the test set. Before we explore or analyze our data it is imperative that we split it into a training and test set. This step will introduce us to Python's machine learning powerhouse, **[scikit learn](https://scikit-learn.org/stable/index.html)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e5e51e-225f-4bdd-ad70-3f0d95496198",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Data Splitting \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e12a4b-9067-42a9-9119-faa218e6474a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Full Data to Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3591e16-7de0-4725-81fd-d3585bc39d0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Data splitting is one of the most important steps of the machine learning cycle. We've all had instructors that, let's just say, provided alot of friendly *guidance* for what material would appear on an exam (they were pretty popular professors). Often this was in the form of a \"practice exam\". This led to a scenario where the exam was for all intents and purposes observed before exam day, and those who could memorize well were likely to achieve the most success. As much as stressed out college students might enjoy it, this arrangement does not facilitate genuine learning, which is demonstrated by the ability to accurately generalize concepts and constructs to new scenarios.  This is why we split data. So that instead of memorizing content and being tested on how well we can repeat it, we are attempting to learn the \"how\" and \"why\" behind the data generating process so that when new data comes from the process, we can legitimately demonstrate a deep level of understanding. Splitting the data into a train set an a test set, and not using the test set at all to learn patterns in the data will enable our model to demonstrate this deeper understanding. Let's load the **train_test_split** module from the scikit learn library and get our study on! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a5c1323-407a-418f-9615-19e719b58e30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Class for data splitting\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc11e13-ee13-4fb5-bb6d-934f9442b64a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Figure 1 displays the first step of the data splitting process: identify and isolate the feature matrix (\\\\(X\\\\)) and label vector (\\\\(y\\\\)) in the context of an easy to visualize dataframe. The figure is followed by the code that gets this process started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b124515-a8ec-4c7c-9e0a-f6d6ddce5fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Figure 1:** Seperating our curated DataFrame into a feature matrix \\\\((X\\\\)) and label vector \\\\((y\\\\)). An example with a DataFrame with 15 observations.\n",
    "\n",
    "\n",
    "![ih](files/ml-file-store/bronze/Xy_pic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5259728b-16f9-4b1f-9583-14ee19a0bdff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the feature matrix by removing the target, as well as identifier, colinear and unobservable variables\n",
    "X = retention21a.drop(['SID','ENROLLMENT_YEAR','ENROLLMENT_TERM','COHORT','HS_GPA','FIRST_SEM_W','DFW_UNITS_1','CUM_GPA_1','DFW_UNITS_2','CUM_GPA_2','UNITS_COMPLETED_3','DFW_UNITS_3','GPA_3','CUM_GPA_3','UNITS_ATTEMPTED_4','UNITS_COMPLETED_4','DFW_UNITS_4','GPA_4','CUM_GPA_4','SEM_3_STATUS','SEM_4_STATUS','UNITS_ATTEMPTED_3'],axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a95261cb-adf7-4e40-b101-fabde43ab7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE : For each variable dropped in the code chunk above, give a rationale by classifying them as target, identifier, colinear and/or unobservable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39c89e64-09d9-41fe-b6aa-68f9411f3c37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For the target variable, we need a column in which 1 represents students who leave in semester 3, and 0 represents students who were retained. Thus we need to **one hot encode** the \"GD\" class in our target: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d884d9-263f-4ae6-a8e7-a85eb82bc787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create the target vector by first selecting the target variable\n",
    "y_cat = retention21a['SEM_3_STATUS']\n",
    "#The one hot encoding for the GD class\n",
    "y=pd.get_dummies(y_cat)['GD']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588cecd5-d167-4277-8796-e31bb8848148",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The initial split was a vertical one, seperating features from label. We proceed with a horizontal split, randomly holding out a specified percentage of observations for testing.\n",
    "\n",
    "Let's create an 80-20 split of the data for training, and testing on an unlearned hold out set. One of the most useful functions in scikit learn, **[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)** gets the job done in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1bd1c750-79a0-4ca5-9276-bfba3f26ac23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state=rms)\n",
    "\n",
    "#The random_state variable makes the code reproducible - everytime we run this code, the same observations will be allocated to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b288b88c-6476-4c07-b566-3b6d4856598c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Figure 2:** An example of an 80%-20% train-test split on a dataframe with 15 observations. Randomly sample 20% * 15 = 3 values to hold out for model testing: Observations 2,6 and 13.\n",
    "![ih](files/ml-file-store/bronze/80_20_Xy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28bc209f-bb43-49b3-90d0-3385ddfc8ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "From our original 7929 observations, 20% \\\\(\\times\\\\) 7929 \\\\(\\approxeq\\\\) 1586 will be reserved for model testing. To prevent *data leakage*, they will not be part of our data exploration or model fitting whatsoever; we don't want to peek at the test before exam day, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de236d43-2ffd-4fa4-ad68-7e93e8ace16d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6343, 12) (1586, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab6fa16-5738-4492-a895-d3067bb0cb31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: We chose an 80-20 train-test split for our data.** \n",
    "\n",
    "**a. In your own words explain what this means, and why it's a must.**\n",
    "\n",
    "**b. In what ways could this be considered better than a 90-10 split? In what ways is it worse?**\n",
    "\n",
    "**c. In what ways could this considered better than a 70-30 split? In what ways is it worse?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9793552a-851f-468c-99ae-e21ce7de3256",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Training to Build and Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "130b5f86-0e89-457a-9568-5964270b8f92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next we need to split our training data into a portion used to fit the data (build set), and an initially untouched part we can use to calibrate our algorithm inputs (validation set). We'll make the validation set 1/8 of the training data, resulting in a 70-10-20 build-validate-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c94118f-5b46-4a71-9232-d078f5ecfd62",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_build, X_val, y_build, y_val = train_test_split(X_train,y_train,test_size=0.125,random_state=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ef09435-52b4-43fc-97ab-034dd35f8c3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With this completed, we shift our attention to data quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a345398-7940-4ea8-9523-ef47e882e9a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Addressing Missingness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bba7318a-e601-4bbc-9e63-42c6fc086b24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As mentioned above, an essential data preprocessing step for modeling in scikit learn is accounting for missingness in our observations. Scikit learn models will not run with missing data, so we need to decide how to deal with it. \n",
    "Let's investigate missingness in our training set, and use that to determine the most effective way to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7131c1bb-4562-48f3-a37c-a783781bc334",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 5550 entries, 105755 to 23293\nData columns (total 12 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   RACE_ETHNICITY     5550 non-null   object \n 1   GENDER             5550 non-null   object \n 2   FIRST_GEN_STATUS   5550 non-null   object \n 3   HS_MATH_GPA        3584 non-null   float64\n 4   HS_ENGL_GPA        3584 non-null   float64\n 5   COLLEGE            5550 non-null   object \n 6   UNITS_ATTEMPTED_1  5550 non-null   float64\n 7   UNITS_COMPLETED_1  5550 non-null   float64\n 8   GPA_1              5550 non-null   float64\n 9   UNITS_ATTEMPTED_2  5550 non-null   float64\n 10  UNITS_COMPLETED_2  5550 non-null   float64\n 11  GPA_2              5550 non-null   float64\ndtypes: float64(8), object(4)\nmemory usage: 563.7+ KB\n<class 'pandas.core.frame.DataFrame'>\nInt64Index: 793 entries, 66167 to 75331\nData columns (total 12 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   RACE_ETHNICITY     793 non-null    object \n 1   GENDER             793 non-null    object \n 2   FIRST_GEN_STATUS   793 non-null    object \n 3   HS_MATH_GPA        513 non-null    float64\n 4   HS_ENGL_GPA        513 non-null    float64\n 5   COLLEGE            793 non-null    object \n 6   UNITS_ATTEMPTED_1  793 non-null    float64\n 7   UNITS_COMPLETED_1  793 non-null    float64\n 8   GPA_1              793 non-null    float64\n 9   UNITS_ATTEMPTED_2  793 non-null    float64\n 10  UNITS_COMPLETED_2  793 non-null    float64\n 11  GPA_2              793 non-null    float64\ndtypes: float64(8), object(4)\nmemory usage: 80.5+ KB\nOut[21]: (None, None)"
     ]
    }
   ],
   "source": [
    "X_build.info(), X_val.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1e5556-9a73-46ca-87b2-bccdae4a258d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It is very clear from the head-and-tail look at the data above, as well as the **.info()** output that there are an abundance of values missing from our data, coded as *NaN*. This comes as no surprise, as we recall that there are many students for whom high school data is not available. Missingness is a common challenge faced in the data preparation stage, and often need not be directly addressed for exploratory data analysis. However, in the **Analyze** phase, the methods used in the Python libraries associated with predictive modeling - statsmodels and scikit-learn - require complete data. Thus an executive decision needs to be made before we can proceed. Ultimately we have three choices:\n",
    "1. Remove all observations with missing values\n",
    "2. Replace missing values with plausible values\n",
    "3. Exclude variables with missing values from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8784616-1115-468e-a0e4-be6c1be8e018",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: For the three possibilties listed here, state what you believe the shape the resulting DataFrame would be. Write code to perform each and verify your conjectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d5b0074-4dd5-40ce-8104-8c24955bdbf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "For the current analysis, we choose option 1: drop incomplete observations. Our goal is to create a model that utilized data that is available for the typical domestic applicant. We can visualize missingness below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9551a05d-17d6-4103-8c09-e23152b79cc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[22]: RACE_ETHNICITY          0\nGENDER                  0\nFIRST_GEN_STATUS        0\nHS_MATH_GPA          1966\nHS_ENGL_GPA          1966\nCOLLEGE                 0\nUNITS_ATTEMPTED_1       0\nUNITS_COMPLETED_1       0\nGPA_1                   0\nUNITS_ATTEMPTED_2       0\nUNITS_COMPLETED_2       0\nGPA_2                   0\ndtype: int64"
     ]
    }
   ],
   "source": [
    "#The .isna() method goes column by column and indicates whether a given value is missing or not, then .sum() aggregates these indicators.\n",
    "NaN_counts = X_build.isna().sum()\n",
    "NaN_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75c4dcaf-964a-4f4b-9a02-2e4179728e2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[23]: 1966"
     ]
    }
   ],
   "source": [
    "NaN_counts[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "096a1d25-d937-4f12-bf62-8e3ff14255a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Over 2000 missing observations entails alot of data to drop, but it is a necessary step if we want to proceed by incorporating high school data in our model, thus avoiding option 3. above. To whatever extent possible, we should use domain knowledge or critical investigation to ascertain *why* data are missing, as this has massive implications for model bias and generalizability. The primary framework for understanding missingness has three possibilities:\n",
    "\n",
    "  1. MCAR - Missing Completely at Random - reasons for missingness are unrelated to any observed variables\n",
    "\n",
    "  2. MAR - Missing at Random - reasons for missingness in a specific variable are unrelated to that variable, and due to some other observed variable\n",
    "\n",
    "  3. MNAR - Missing not at Random - reasons for missingness in a specific variable are related directly to that variable\n",
    "\n",
    "In this scenario, it is most likely that high school is data for observations corresponding to international students, students who were homeschooled or went to a private school. As such, if we restrict our population of interest (and thus scope of our model implementation) to exclude these demographics, bias is mitigated if we drop observations with missing data. \n",
    "In addition, in anticipation of our inclusion of DFW rate, let's remove any observations with 0 units attempted in terms 1 and 2.\n",
    "To enable use in our model, we'll need to do the same with the test data (without explicitly viewing it, of course).  Let's take a look at the complete training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b07121e3-466a-43ee-89c9-1f21c86ac1ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Identify the rows in our data with no missing values\n",
    "complete_index_build = (X_build['HS_MATH_GPA'].notna()) & (X_build['UNITS_ATTEMPTED_1']!=0) & (X_build['UNITS_ATTEMPTED_2']!=0)\n",
    "X_build_c = X_build[complete_index_build]\n",
    "y_build_c = y_build[complete_index_build]\n",
    "y_build_c.name = 'SEM_3_STATUS'\n",
    "\n",
    "complete_index_val = (X_val['HS_MATH_GPA'].notna()) & (X_val['UNITS_ATTEMPTED_1']!=0) & (X_val['UNITS_ATTEMPTED_2']!=0)\n",
    "X_val_c = X_val[complete_index_val]\n",
    "y_val_c = y_val[complete_index_val]\n",
    "y_val_c.name = 'SEM_3_STATUS'\n",
    "\n",
    "complete_index_test = (X_test['HS_MATH_GPA'].notna()) & (X_test['UNITS_ATTEMPTED_1']!=0) & (X_test['UNITS_ATTEMPTED_2']!=0)\n",
    "X_test_c = X_test[complete_index_test]\n",
    "y_test_c = y_test[complete_index_test]\n",
    "y_test_c.name = 'SEM_3_STATUS'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e294e3c3-2577-4790-9b9d-00bd8b34621a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "EXERCISE: loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "78cda6c2-de98-4678-8efb-e6c6011da84d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105755</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.34</td>\n",
       "      <td>Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.81</td>\n",
       "      <td>Arts</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.27</td>\n",
       "      <td>Arts</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>Nonresident alien</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.62</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97456</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.50</td>\n",
       "      <td>University Programs</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.37</td>\n",
       "      <td>Health</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92178</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.95</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35031</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.16</td>\n",
       "      <td>Arts</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43284</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.51</td>\n",
       "      <td>Health</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3573 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>GPA_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105755</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.09</td>\n      <td>2.34</td>\n      <td>Science</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.000000</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>73202</th>\n      <td>White</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.70</td>\n      <td>3.81</td>\n      <td>Arts</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>4.000000</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>3.687500</td>\n    </tr>\n    <tr>\n      <th>8941</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.44</td>\n      <td>3.27</td>\n      <td>Arts</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.000000</td>\n      <td>13.0</td>\n      <td>6.0</td>\n      <td>1.692308</td>\n    </tr>\n    <tr>\n      <th>35002</th>\n      <td>Nonresident alien</td>\n      <td>Female</td>\n      <td>Unknown</td>\n      <td>3.16</td>\n      <td>3.62</td>\n      <td>Engineering</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>97456</th>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.28</td>\n      <td>2.50</td>\n      <td>University Programs</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>14.0</td>\n      <td>10.0</td>\n      <td>1.500000</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15681</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>2.22</td>\n      <td>2.37</td>\n      <td>Health</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>3.000000</td>\n      <td>13.0</td>\n      <td>10.0</td>\n      <td>3.076923</td>\n    </tr>\n    <tr>\n      <th>92178</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.59</td>\n      <td>3.95</td>\n      <td>Liberal Arts</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>3.625000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>3.769231</td>\n    </tr>\n    <tr>\n      <th>35031</th>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.62</td>\n      <td>4.16</td>\n      <td>Arts</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.750000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>4.000000</td>\n    </tr>\n    <tr>\n      <th>7549</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.80</td>\n      <td>3.40</td>\n      <td>Liberal Arts</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3.400000</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3.600000</td>\n    </tr>\n    <tr>\n      <th>43284</th>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>2.94</td>\n      <td>2.51</td>\n      <td>Health</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.250000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>2.666667</td>\n    </tr>\n  </tbody>\n</table>\n<p>3573 rows × 12 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The complete training data (features)\n",
    "X_build_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1596328e-7bbe-41ab-aa00-bbf7f5a91043",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Armed with a complete data set on our selected cohort, we're a step closer to predictive modeling. That being said, there is still a gap between having a complete dataset, and having data prepared for analysis. Let's take some steps to get us ready for that goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82d3f4c1-7d31-4c94-834e-d033e28b5517",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6769ae6-9dac-4ecf-acf3-6a874817aea9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ae7172-0e3c-4eee-809a-c731394f018d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The strength of statistical and machine learning models is directly connected to the nature of the underlying relationship between the features and our target variable. Indeed, our assumption is that such a relationship genuinely exists, and our main task is to approximate it as accurately as possible. Before we get there though, there are still a couple of hurdles to overcome. The methods for predictive analytics in the scikit learn library will not accept our training data *(X_build_c,y_build_c)* as currently constitued. We'll need to transform some variables to prepare them for modeling. We may also need to create new variables from old ones based on our domain knowledge to enhance our analysis. This endeavor is known as *Feature Engineering*, and is an integral part of the Preparation stage for statistical analysis and machine learning. To inform this step, let's get some visuals on our data that could lead to hidden insights or confirm common trade knowledge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63c9566c-4ef0-4b02-9982-edabe0a87caf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Recall (based on the .info() comand) that in our data we see two types of variables:\n",
    " 1. *object* (4): Qualitative - Values are strings\n",
    " 2. *float64* (23): Quantitative - Values count or measure student academic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dbc379bf-dfe0-4889-ad10-a6ec5b2b7797",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 3573 entries, 105755 to 43284\nData columns (total 12 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   RACE_ETHNICITY     3573 non-null   object \n 1   GENDER             3573 non-null   object \n 2   FIRST_GEN_STATUS   3573 non-null   object \n 3   HS_MATH_GPA        3573 non-null   float64\n 4   HS_ENGL_GPA        3573 non-null   float64\n 5   COLLEGE            3573 non-null   object \n 6   UNITS_ATTEMPTED_1  3573 non-null   float64\n 7   UNITS_COMPLETED_1  3573 non-null   float64\n 8   GPA_1              3573 non-null   float64\n 9   UNITS_ATTEMPTED_2  3573 non-null   float64\n 10  UNITS_COMPLETED_2  3573 non-null   float64\n 11  GPA_2              3573 non-null   float64\ndtypes: float64(8), object(4)\nmemory usage: 362.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_build_c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c78fe47a-297f-499b-b7d4-2a5ced7e6cc3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Variable type is an important characteristic when exploring relationships between features. Note that the methods described here call for joint exploration of features and label. The *train_test_split* function requires us to seperate them. So let's concatenate the X dataframe and y series into one pandas dataframe. We'll return to the seperated X-y version of the data later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a31bb610-2911-4a97-b6f0-1cf628fb924c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>SEM_3_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105755</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.34</td>\n",
       "      <td>Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.81</td>\n",
       "      <td>Arts</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.27</td>\n",
       "      <td>Arts</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>Nonresident alien</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.62</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97456</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.50</td>\n",
       "      <td>University Programs</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15681</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.37</td>\n",
       "      <td>Health</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92178</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.95</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.625000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.769231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35031</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.62</td>\n",
       "      <td>4.16</td>\n",
       "      <td>Arts</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7549</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.40</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43284</th>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>2.94</td>\n",
       "      <td>2.51</td>\n",
       "      <td>Health</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3573 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>GPA_2</th>\n      <th>SEM_3_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105755</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.09</td>\n      <td>2.34</td>\n      <td>Science</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.000000</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>1.666667</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73202</th>\n      <td>White</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.70</td>\n      <td>3.81</td>\n      <td>Arts</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>4.000000</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>3.687500</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8941</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.44</td>\n      <td>3.27</td>\n      <td>Arts</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.000000</td>\n      <td>13.0</td>\n      <td>6.0</td>\n      <td>1.692308</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35002</th>\n      <td>Nonresident alien</td>\n      <td>Female</td>\n      <td>Unknown</td>\n      <td>3.16</td>\n      <td>3.62</td>\n      <td>Engineering</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>4.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97456</th>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.28</td>\n      <td>2.50</td>\n      <td>University Programs</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>14.0</td>\n      <td>10.0</td>\n      <td>1.500000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15681</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>2.22</td>\n      <td>2.37</td>\n      <td>Health</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>3.000000</td>\n      <td>13.0</td>\n      <td>10.0</td>\n      <td>3.076923</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>92178</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.59</td>\n      <td>3.95</td>\n      <td>Liberal Arts</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>3.625000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>3.769231</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35031</th>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.62</td>\n      <td>4.16</td>\n      <td>Arts</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.750000</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>4.000000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7549</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.80</td>\n      <td>3.40</td>\n      <td>Liberal Arts</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3.400000</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3.600000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>43284</th>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>2.94</td>\n      <td>2.51</td>\n      <td>Health</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.250000</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>2.666667</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3573 rows × 13 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xy_build_c = pd.concat([X_build_c,y_build_c],axis = 1)\n",
    "Xy_build_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73e1ba04-7bf2-47e7-bca5-2ff259726b5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####Quantitative Explanatory and Qualitative Response\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45607c93-9d9b-4db2-be7e-df4082cd0c5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using the Xy_build_c dataframe, we can explore whether there appears to be evidence of a relationship between our quantitative features and third term retention. The *groupby* method allows us to compare and contrast the values of descriptive statistics by retention status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e3bfd65-2f89-43c1-ac99-d5f10e7c567b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM_3_STATUS\n0    3236\n1     337\ndtype: int64\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEM_3_STATUS</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.516085</td>\n",
       "      <td>3.766276</td>\n",
       "      <td>13.007417</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>3.189934</td>\n",
       "      <td>13.278739</td>\n",
       "      <td>12.221261</td>\n",
       "      <td>3.081059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.328783</td>\n",
       "      <td>3.566320</td>\n",
       "      <td>11.905045</td>\n",
       "      <td>7.240356</td>\n",
       "      <td>1.906692</td>\n",
       "      <td>11.335312</td>\n",
       "      <td>5.724036</td>\n",
       "      <td>1.585598</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>GPA_2</th>\n    </tr>\n    <tr>\n      <th>SEM_3_STATUS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.516085</td>\n      <td>3.766276</td>\n      <td>13.007417</td>\n      <td>12.170581</td>\n      <td>3.189934</td>\n      <td>13.278739</td>\n      <td>12.221261</td>\n      <td>3.081059</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.328783</td>\n      <td>3.566320</td>\n      <td>11.905045</td>\n      <td>7.240356</td>\n      <td>1.906692</td>\n      <td>11.335312</td>\n      <td>5.724036</td>\n      <td>1.585598</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Xy_build_c.groupby(by='SEM_3_STATUS',).size())\n",
    "Xy_build_c.groupby(by='SEM_3_STATUS').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab18f0f7-b2d8-43ec-8e63-088858d50bb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "It is clear that there seem to be differences in mean academic indicators across the academic timeline. It starts out subtly in the high school data but seems to get more pronounced from there through term 1 to term 2. These differences indicate that the quantitative variables could be predictive of SEM_3_STATUS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27451742-044a-4591-b698-fbdd6370209a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: Compare the SEM_3_STATUS groups based on the *median* values of the quantitative variables in the Xy_build_c DataFrame. How do results compare/contrast with those for the mean?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3467a1f-6e9c-41b1-875a-24f44b36e28e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In addition to numerical measures, any graphical object we can use to understand one dimensional data (such as histograms, dotplots) can be plotted based on SEM_3_STATUS to visualize differences. We will be using **[plotly express](https://plotly.com/python/plotly-express/)**, a powerful module for creating interactive data visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f9821d4-f7e7-499b-8444-e50d2b9441b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Import the plotly.express module from the plotly library\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "500bf1be-fea8-47b0-8b4f-4943ef4b80f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Side-by-side boxplots are a great way to visualize the differences between the distributions of quantitative variables based on some qualitative factor. First compare semester 2 GPA for students that left in semester 3 versus those that did not. Hover over the plots to identify key descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "508e4785-9ff7-4e81-a22d-7bf371539bde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\")) {                    Plotly.newPlot(                        \"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>GPA_2=%{x}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"notched\":false,\"offsetgroup\":\"0\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[1.6666666666666667,3.6875,1.6923076923076923,4.0,1.5,2.75,2.071428571428572,4.0,2.25,4.0,2.25,2.75,4.0,3.1,3.5384615384615383,3.0,3.25,4.0,4.0,2.4,2.6,3.5384615384615383,3.333333333333333,4.0,2.4375,3.0,2.6923076923076925,3.5,3.8,3.333333333333333,3.5625,2.625,1.0,3.8,2.933333333333333,2.6666666666666665,2.6,4.0,3.5384615384615383,3.6,3.769230769230769,4.0,2.1333333333333333,1.5454545454545454,2.8,3.125,3.0,4.0,3.7142857142857135,4.0,3.4285714285714284,3.75,2.1333333333333333,2.7142857142857144,3.0,3.8,3.5384615384615383,4.0,3.4,3.5,4.0,4.0,2.4615384615384617,3.75,4.0,2.6,2.6,2.125,3.769230769230769,1.8,4.0,3.8,3.5,2.6923076923076925,2.0,2.0,4.0,3.5,3.733333333333333,3.5,4.0,4.0,4.0,4.0,3.733333333333333,3.3125,3.076923076923077,1.0,3.4,0.3333333333333333,2.4,4.0,2.9166666666666665,3.8125,2.25,4.0,2.3846153846153846,3.5,4.0,3.0,3.230769230769231,3.25,4.0,3.0,4.0,2.6875,3.272727272727273,4.0,4.0,2.6666666666666665,2.5,3.5,2.5454545454545454,3.1578947368421053,2.6666666666666665,3.1666666666666665,3.0,4.0,3.8,3.8125,3.533333333333333,3.1818181818181817,2.0,3.466666666666667,4.0,3.1875,4.0,3.647058823529412,2.5,3.4,3.333333333333333,3.692307692307693,2.0,4.0,3.8125,3.2,3.625,3.0,3.3076923076923075,1.0,4.0,3.0,2.923076923076923,2.363636363636364,4.0,2.8125,2.4,2.466666666666667,3.5,2.75,4.0,1.25,3.0,3.4,3.7,3.769230769230769,2.333333333333333,3.5,2.8,3.5384615384615383,3.4,3.0,4.0,4.0,3.375,3.4615384615384617,3.2,3.333333333333333,2.3125,0.2857142857142857,3.25,3.4615384615384617,3.2,1.1666666666666667,2.4166666666666665,3.5384615384615383,2.75,3.25,3.733333333333333,4.0,3.533333333333333,2.0,2.2,2.5,4.0,3.4,3.6,2.6923076923076925,0.0,3.6666666666666665,2.0,3.6666666666666665,3.75,3.2,2.6666666666666665,3.625,1.8571428571428568,3.25,4.0,3.5625,3.75,3.6,2.0,2.8461538461538463,2.75,3.25,3.0,2.6923076923076925,3.5384615384615383,3.0625,3.4375,3.4,2.6,1.6923076923076923,2.25,3.4,3.272727272727273,3.25,2.8,3.5384615384615383,2.7857142857142856,3.2857142857142856,2.1538461538461537,3.7142857142857135,3.5454545454545454,1.5555555555555556,1.5,3.4,3.6,4.0,2.25,3.6666666666666665,3.2857142857142856,2.75,4.0,4.0,4.0,3.727272727272727,3.75,3.769230769230769,3.25,3.7142857142857135,3.0,0.0,3.615384615384616,3.8,3.2,3.117647058823529,4.0,2.8,4.0,2.75,4.0,3.769230769230769,2.5,3.933333333333333,2.25,1.8,4.0,2.9285714285714284,3.8125,4.0,3.6,3.5384615384615383,3.230769230769231,4.0,1.8,3.066666666666667,0.5,3.0,2.1538461538461537,2.0,3.75,3.071428571428572,3.5,2.833333333333333,3.4615384615384617,3.9375,3.6666666666666665,3.1538461538461537,3.8,3.2,2.5,3.625,2.090909090909091,4.0,3.3076923076923075,4.0,2.0,2.0,3.588235294117647,3.6,3.0,3.0,3.3846153846153846,3.25,4.0,4.0,0.0,3.5625,2.4615384615384617,3.692307692307693,3.769230769230769,3.333333333333333,2.6,3.6,0.6428571428571429,3.583333333333333,3.6666666666666665,3.066666666666667,3.75,0.5,3.5,2.6923076923076925,3.1538461538461537,2.8461538461538463,3.1538461538461537,4.0,3.5454545454545454,3.733333333333333,3.2,4.0,2.5,4.0,2.5,3.625,2.0,3.8,3.25,3.6,3.75,4.0,4.0,3.4615384615384617,1.181818181818182,3.0,3.3125,3.0,3.375,3.0,2.642857142857143,3.0,2.0,4.0,2.5,2.909090909090909,3.333333333333333,2.0,4.0,4.0,3.0,2.75,3.357142857142857,3.8,2.2,2.6,4.0,3.0,1.5833333333333333,2.571428571428572,3.75,2.857142857142857,3.4,2.4,3.066666666666667,0.0,3.727272727272727,2.25,4.0,3.4166666666666665,3.769230769230769,4.0,1.3333333333333333,3.333333333333333,4.0,2.6,2.9375,3.5384615384615383,3.4615384615384617,1.6666666666666667,3.6,4.0,2.4,0.0,4.0,3.2,2.625,3.1538461538461537,2.2,3.8125,2.5,4.0,3.333333333333333,4.0,3.0,3.0625,3.0,4.0,1.3846153846153846,3.8,3.4375,2.5,3.0,3.8,3.0,3.0,3.3846153846153846,4.0,2.583333333333333,4.0,4.0,2.5,4.0,3.0,3.333333333333333,2.4285714285714284,3.2666666666666666,2.230769230769231,3.5454545454545454,4.0,4.0,3.3846153846153846,4.0,0.25,3.076923076923077,4.0,4.0,2.7142857142857144,3.533333333333333,3.3846153846153846,3.0,3.625,1.5625,3.5,3.357142857142857,3.25,2.857142857142857,3.75,3.0625,3.0,3.692307692307693,3.6,2.75,2.2,2.0,4.0,4.0,3.0,3.692307692307693,4.0,2.0,3.75,1.0,3.6,2.6666666666666665,3.5454545454545454,3.25,2.8,3.6666666666666665,2.5384615384615383,2.0,2.75,3.0,3.25,2.2,3.2,1.6,3.0,2.0,3.272727272727273,3.066666666666667,3.6875,3.1538461538461537,3.6,2.2142857142857144,3.1666666666666665,3.375,3.5625,1.4285714285714286,3.2666666666666666,4.0,2.0,1.0,4.0,3.1333333333333333,3.4,3.25,3.75,3.5,3.25,2.7857142857142856,3.8,3.6,3.727272727272727,2.4615384615384617,4.0,1.9166666666666667,2.5,3.0,2.8181818181818183,3.4,3.2,3.0,2.230769230769231,3.5,4.0,3.6,3.4,3.3076923076923075,3.2,2.923076923076923,2.75,4.0,1.5,3.0,3.625,3.5,4.0,3.0,4.0,3.5,4.0,2.8,1.4285714285714286,4.0,3.692307692307693,2.5,2.8,3.25,3.0,2.8,4.0,2.0,2.0,3.4,3.8,3.8333333333333335,1.9230769230769231,2.7058823529411766,3.117647058823529,3.3076923076923075,0.5384615384615384,4.0,1.4285714285714286,3.4,2.0,0.2,4.0,3.2,4.0,3.8125,3.6,4.0,3.8,4.0,1.8,3.076923076923077,1.0,3.0,3.8125,2.5,3.8,3.5,3.375,3.6,3.0,1.9090909090909087,1.6,3.2857142857142856,3.625,3.2666666666666666,3.0,3.4615384615384617,2.0,2.5,2.0,4.0,2.4,3.0,2.4615384615384617,3.4615384615384617,3.5,3.0,3.4,2.8666666666666667,0.6,1.3333333333333333,3.4615384615384617,3.1666666666666665,3.5,3.0,3.333333333333333,2.8461538461538463,3.0,3.5,4.0,2.0,3.8,2.5,3.2,2.4615384615384617,3.8,4.0,3.25,1.3333333333333333,3.3076923076923075,3.0,3.6666666666666665,3.8,3.25,3.0,3.8,3.7857142857142856,2.8181818181818183,3.8,3.071428571428572,3.0,1.9,3.0,3.25,2.6,4.0,3.533333333333333,3.2,3.8333333333333335,3.733333333333333,2.0625,3.5384615384615383,2.75,3.5,3.8,3.5,1.25,3.8,3.75,2.9166666666666665,4.0,3.8,3.2,2.6,3.0,0.1875,4.0,2.0,3.2,3.588235294117647,1.6666666666666667,4.0,4.0,3.5,2.272727272727273,3.4,3.7777777777777777,3.083333333333333,1.6153846153846154,3.8125,3.6,3.8125,3.333333333333333,2.333333333333333,2.25,1.0666666666666669,0.8,3.1875,3.75,3.5,3.615384615384616,0.0,3.75,3.1538461538461537,3.692307692307693,3.3846153846153846,1.9230769230769231,2.5,2.4,3.6666666666666665,3.0,3.692307692307693,2.25,2.6,2.8125,3.1666666666666665,3.066666666666667,3.0,3.75,3.75,4.0,3.8125,4.0,2.8461538461538463,2.4,2.6,3.5,4.0,0.0,3.2,1.6666666666666667,3.692307692307693,3.75,3.8,4.0,3.75,2.4615384615384617,3.1875,2.333333333333333,3.625,3.8,3.727272727272727,1.9285714285714288,3.1666666666666665,3.4,4.0,2.75,3.0,2.076923076923077,2.6666666666666665,3.230769230769231,2.647058823529412,4.0,3.25,1.5,3.333333333333333,3.2222222222222223,3.1538461538461537,3.923076923076923,4.0,2.25,2.1333333333333333,4.0,3.75,3.333333333333333,3.0,3.6,3.0,4.0,3.25,2.4375,3.0,3.75,2.5,3.5625,3.4,2.5,3.0625,1.6666666666666667,3.230769230769231,3.75,4.0,3.0,4.0,3.0,3.6,2.4,3.1875,4.0,3.75,1.6,2.75,3.8,4.0,3.2,3.5,3.4705882352941178,3.25,3.230769230769231,1.8,2.4,2.75,1.7272727272727273,4.0,3.1875,2.4,2.75,3.75,3.071428571428572,2.5,3.4,3.375,3.5,4.0,2.176470588235294,3.2142857142857144,4.0,3.6,4.0,1.4615384615384617,2.25,3.7857142857142856,3.0,3.769230769230769,4.0,1.9333333333333331,3.2,4.0,4.0,4.0,1.9166666666666667,3.5,2.5625,3.6666666666666665,3.571428571428572,3.0625,4.0,2.071428571428572,3.8,3.0,2.9166666666666665,2.8461538461538463,3.7142857142857135,2.5,4.0,2.6153846153846154,2.0,4.0,3.1875,2.5,3.2666666666666666,3.75,4.0,3.0,2.6,3.5,4.0,3.4375,3.4,3.5625,2.357142857142857,1.3076923076923077,3.6666666666666665,3.2,3.75,1.6666666666666667,2.0,2.75,3.6,4.0,2.923076923076923,3.4615384615384617,2.2,2.8,2.571428571428572,2.0,3.0,3.333333333333333,2.8666666666666667,1.8,3.8,3.8,3.6,3.0,0.0,3.4166666666666665,3.8125,3.25,4.0,2.571428571428572,3.0,3.0,2.125,1.6363636363636365,2.0,2.0,3.0,2.066666666666667,3.6,0.0,3.333333333333333,1.4,2.75,4.0,0.0,2.8,4.0,2.230769230769231,3.6,3.6666666666666665,3.25,3.0,2.0,2.8,3.764705882352941,4.0,3.2,3.0,3.0,3.0,2.0,3.75,2.75,4.0,1.6,3.571428571428572,3.6,4.0,3.6,2.5,2.4615384615384617,3.727272727272727,4.0,2.25,3.8,4.0,3.5,4.0,4.0,2.230769230769231,3.8,4.0,3.8,2.933333333333333,3.75,3.4166666666666665,2.923076923076923,3.6,2.6666666666666665,3.6,4.0,2.357142857142857,4.0,3.2,2.8,4.0,2.7333333333333334,3.2,2.8,4.0,3.230769230769231,3.25,2.5,2.0,1.6153846153846154,4.0,3.1333333333333333,4.0,1.4545454545454546,3.75,3.625,2.75,4.0,3.2142857142857144,2.4,3.692307692307693,3.230769230769231,3.0,4.0,2.75,3.5,3.7058823529411766,4.0,2.1666666666666665,3.0,3.6666666666666665,4.0,3.0,3.4705882352941178,3.0,3.75,1.75,4.0,2.230769230769231,3.75,3.4,2.0,3.272727272727273,3.5625,2.8,0.1666666666666666,3.8125,3.8125,1.8,3.1,2.75,3.0,0.0,3.8,2.4,3.142857142857143,2.923076923076923,2.875,2.769230769230769,3.692307692307693,3.4545454545454546,3.0,3.1538461538461537,3.692307692307693,2.8181818181818183,2.75,3.625,3.25,3.6666666666666665,1.9411764705882355,4.0,1.9090909090909087,3.692307692307693,3.625,2.75,3.571428571428572,2.75,2.75,1.0,2.0,3.75,4.0,2.272727272727273,2.75,3.2142857142857144,3.6666666666666665,3.6,3.4,4.0,2.769230769230769,3.25,3.5,3.0,2.6153846153846154,1.75,1.6666666666666667,3.4615384615384617,3.5384615384615383,3.272727272727273,3.5384615384615383,3.3529411764705883,2.6,1.3888888888888888,4.0,3.625,3.7777777777777777,4.0,3.0,3.571428571428572,3.25,2.0,4.0,3.0,4.0,3.0,4.0,3.272727272727273,3.5454545454545454,2.357142857142857,4.0,4.0,3.230769230769231,3.555555555555556,3.7857142857142856,4.0,4.0,3.333333333333333,4.0,3.3125,2.6,1.2857142857142858,2.2142857142857144,2.5,2.4285714285714284,3.6,3.1538461538461537,1.25,2.4615384615384617,3.6666666666666665,3.625,3.6,3.5,3.25,2.5,3.333333333333333,2.8,3.8,4.0,4.0,2.8461538461538463,3.8125,3.230769230769231,3.75,3.571428571428572,3.6666666666666665,3.5384615384615383,3.8,1.2352941176470589,3.2,2.75,3.6666666666666665,0.0,3.4,3.6666666666666665,3.769230769230769,3.75,4.0,3.75,2.8181818181818183,3.2142857142857144,3.0,3.75,3.8,2.272727272727273,4.0,2.7142857142857144,3.25,3.176470588235294,3.769230769230769,4.0,3.230769230769231,3.333333333333333,2.5,3.5,3.357142857142857,3.692307692307693,3.0,3.5,3.1875,2.7,3.0,3.75,3.2,3.6666666666666665,2.25,3.4375,3.5,3.6666666666666665,3.6,2.6,2.4615384615384617,3.571428571428572,2.8,3.2,2.8,3.0,2.2142857142857144,2.0,2.1818181818181817,2.25,3.2,4.0,4.0,0.4615384615384615,4.0,1.6666666666666667,3.6,3.5454545454545454,3.1666666666666665,2.25,3.75,1.5,0.4615384615384615,3.2,3.642857142857143,4.0,2.6,3.4,2.4615384615384617,3.2857142857142856,3.076923076923077,2.8,2.4615384615384617,3.2,3.333333333333333,2.3125,2.2857142857142856,3.75,3.4,3.6,0.6153846153846154,3.0,3.6666666666666665,4.0,3.2857142857142856,4.0,3.625,3.4,3.2777777777777777,4.0,1.5,4.0,1.3076923076923077,4.0,3.2,3.8,4.0,4.0,3.0,4.0,2.7777777777777777,3.6,3.5,3.8,2.8,3.2,3.066666666666667,2.1333333333333333,4.0,2.4615384615384617,3.75,4.0,1.75,3.5,2.375,2.875,3.0,3.0,3.2,0.9375,3.6666666666666665,4.0,3.6,3.2,3.0,3.642857142857143,4.0,2.4615384615384617,3.5384615384615383,4.0,4.0,3.1538461538461537,3.0,4.0,4.0,2.533333333333333,3.75,4.0,3.3076923076923075,0.8,3.230769230769231,3.4375,4.0,2.6,2.0,4.0,3.0,3.2142857142857144,3.071428571428572,3.6,3.4,3.6,0.6666666666666666,4.0,3.1538461538461537,2.4,1.4,0.375,3.769230769230769,4.0,3.5625,4.0,2.4,2.25,3.6,4.0,2.8,2.363636363636364,4.0,4.0,3.8125,3.769230769230769,3.8125,2.7333333333333334,1.8,3.5,2.7333333333333334,2.7333333333333334,2.5384615384615383,1.3636363636363635,3.4545454545454546,2.8,3.25,4.0,2.6153846153846154,3.5,1.8,3.25,2.8,4.0,3.357142857142857,3.0,3.5625,3.357142857142857,1.25,3.6666666666666665,1.5,2.75,4.0,4.0,3.8,4.0,1.3,2.5454545454545454,2.0,4.0,3.75,1.6153846153846154,3.5384615384615383,3.2,3.769230769230769,3.0,3.8125,4.0,4.0,3.25,3.6666666666666665,3.8,3.0,2.6153846153846154,1.8,3.8,2.75,3.75,3.6,2.0,1.6,3.5,3.923076923076923,3.230769230769231,3.909090909090909,4.0,3.8,4.0,3.0,3.4,3.230769230769231,3.5625,4.0,3.2,0.0,0.2,4.0,4.0,3.2,2.4615384615384617,3.2,1.9230769230769231,0.4285714285714285,2.0,2.1666666666666665,3.0,3.8125,3.4,3.25,3.6666666666666665,3.5,4.0,3.5,2.727272727272727,2.727272727272727,0.3333333333333333,4.0,3.571428571428572,0.6153846153846154,3.6,3.0,2.8,3.0,3.0,3.0,3.533333333333333,2.75,3.5,1.75,3.0,4.0,3.5,3.533333333333333,1.6,3.8,4.0,3.5,3.4,3.642857142857143,2.6153846153846154,4.0,3.625,3.0625,2.6923076923076925,3.5,3.75,3.6,4.0,2.769230769230769,3.692307692307693,2.8,2.5,2.5,3.8,2.8,2.25,3.615384615384616,3.5,3.8,3.066666666666667,3.642857142857143,2.0,3.25,2.8461538461538463,1.9230769230769231,4.0,3.5,3.5625,2.25,3.5454545454545454,3.6,2.466666666666667,3.636363636363636,3.4,3.0,3.571428571428572,3.0,2.1538461538461537,3.8,3.625,2.75,3.75,2.2142857142857144,0.8,3.0,3.235294117647059,2.6,3.2,4.0,4.0,2.75,3.25,3.75,2.4615384615384617,3.4,4.0,3.75,2.5454545454545454,3.5454545454545454,3.5,3.2,2.1875,3.230769230769231,4.0,3.6666666666666665,4.0,2.625,2.2857142857142856,3.6,2.7857142857142856,3.0,3.692307692307693,4.0,3.4,3.0625,3.4,3.6,3.25,1.75,3.4,2.6923076923076925,3.25,2.6153846153846154,4.0,1.2142857142857142,2.230769230769231,3.090909090909091,3.2,4.0,4.0,2.75,3.642857142857143,2.5625,3.117647058823529,3.2,4.0,3.5,2.9375,4.0,1.0666666666666669,2.8,3.7142857142857135,4.0,3.0625,2.555555555555556,4.0,3.230769230769231,2.2142857142857144,3.4375,4.0,1.5,2.6,3.8125,3.0,3.0,3.0,3.4,2.8,2.8461538461538463,3.2857142857142856,1.75,3.2,2.6875,3.8,2.4285714285714284,3.6,3.4,3.5,3.823529411764706,3.5625,2.6,3.642857142857143,3.4166666666666665,3.0,3.5,3.090909090909091,2.5,3.066666666666667,3.0,3.466666666666667,2.1538461538461537,2.9285714285714284,4.0,1.8,3.0,3.375,3.2,2.8,4.0,1.4,2.0,4.0,3.75,2.8461538461538463,1.6666666666666667,2.5,0.0,3.466666666666667,3.636363636363636,3.25,3.7142857142857135,4.0,3.0,3.333333333333333,3.2,3.8125,3.6875,1.8,4.0,3.2666666666666666,3.8,3.6,2.857142857142857,4.0,4.0,3.75,1.4545454545454546,3.8,3.6,3.8125,3.6,2.5,3.4,2.8181818181818183,1.6,3.75,2.333333333333333,3.75,3.6666666666666665,2.0,2.4166666666666665,3.6,4.0,4.0,2.875,4.0,3.142857142857143,2.75,2.6,2.375,3.3,3.8125,3.6,2.571428571428572,3.0625,3.636363636363636,2.5,4.0,3.2666666666666666,3.8,3.2,3.8,2.0,3.5,3.25,4.0,2.7857142857142856,4.0,3.8,2.9166666666666665,2.75,3.4615384615384617,2.5,4.0,2.9375,4.0,3.0,4.0,2.3846153846153846,1.8461538461538465,2.0625,2.5,3.0,2.7,3.25,3.625,3.6666666666666665,2.0625,3.4,3.25,3.1666666666666665,3.6,3.0,1.5,4.0,3.4615384615384617,3.125,3.375,3.8125,2.6153846153846154,2.0625,3.6666666666666665,3.4,4.0,1.0,1.75,4.0,4.0,4.0,3.5,2.75,4.0,4.0,3.0,4.0,2.923076923076923,3.333333333333333,3.625,3.5,4.0,2.4,4.0,4.0,3.0,1.6875,3.5625,3.642857142857143,3.4,4.0,2.5,1.6,1.3076923076923077,4.0,3.733333333333333,3.4615384615384617,2.4,3.8125,3.5625,3.375,3.4,3.733333333333333,4.0,3.25,3.142857142857143,4.0,4.0,3.8,3.4545454545454546,3.25,2.4,2.7,3.5384615384615383,3.5,3.8125,3.235294117647059,3.75,1.2,3.647058823529412,3.5,2.3076923076923075,2.8666666666666667,3.6,0.75,3.0625,2.75,2.2222222222222223,4.0,3.6,3.0,3.625,4.0,3.0625,1.5,3.2142857142857144,4.0,2.4,3.2,0.0,3.5,3.0,1.1538461538461535,2.75,3.2142857142857144,2.4,3.3846153846153846,3.2,2.75,1.8,3.6,3.2,3.8125,2.5625,3.7857142857142856,0.9166666666666666,3.0,3.2142857142857144,2.6153846153846154,3.692307692307693,4.0,3.0,3.333333333333333,3.25,4.0,2.3076923076923075,3.8,3.25,3.125,2.75,2.9375,2.5,3.5,3.8125,3.0,4.0,2.4,3.75,3.4,4.0,3.3125,3.727272727272727,4.0,1.6666666666666667,3.333333333333333,2.75,3.8,2.75,2.0,3.2,3.0,2.857142857142857,3.8125,1.0,4.0,2.25,2.363636363636364,4.0,3.25,3.357142857142857,0.9333333333333332,2.769230769230769,3.75,4.0,1.4166666666666667,3.75,1.0,3.6,3.7142857142857135,4.0,3.615384615384616,3.8,2.333333333333333,3.4,3.090909090909091,3.75,2.6923076923076925,2.25,4.0,3.769230769230769,1.75,3.2,2.2,2.75,3.2,3.0,3.75,3.375,3.8125,3.526315789473684,3.533333333333333,4.0,2.0,3.7857142857142856,3.0,2.6666666666666665,2.0,4.0,3.272727272727273,2.888888888888889,3.090909090909091,3.0,4.0,1.25,3.8,3.0,2.8,4.0,2.2222222222222223,3.0,4.0,1.6923076923076923,4.0,3.0,3.5,3.75,2.75,4.0,4.0,3.615384615384616,3.0625,1.25,3.0,3.0,1.25,3.5,3.8,0.375,3.8,0.9333333333333332,3.6666666666666665,2.2142857142857144,3.2,2.8461538461538463,1.8,3.2,3.25,2.5,3.8,3.769230769230769,2.7142857142857144,1.75,4.0,2.75,3.0,3.75,3.25,3.4615384615384617,3.4,2.4285714285714284,1.5384615384615383,3.2,4.0,2.8,1.0,3.733333333333333,3.25,2.5,3.4285714285714284,3.0,3.4166666666666665,3.571428571428572,2.125,3.0,3.0,4.0,3.0,2.857142857142857,1.5,3.0,4.0,2.8181818181818183,3.8,2.1538461538461537,3.083333333333333,1.5,2.0,4.0,2.2,3.4375,2.5,3.5454545454545454,1.3333333333333333,3.75,4.0,1.6666666666666667,4.0,3.6,1.5,2.5,3.4,3.0,3.0,1.5,4.0,2.0,4.0,4.0,3.533333333333333,3.4,2.9375,3.4,4.0,4.0,4.0,3.8125,2.1333333333333333,3.0,1.2,2.9375,2.1818181818181817,2.25,2.375,3.0,3.533333333333333,1.0,2.75,1.25,3.6,3.2,2.75,4.0,2.1538461538461537,2.75,3.5,4.0,4.0,4.0,3.272727272727273,3.0,4.0,1.1333333333333333,3.0,3.75,2.8181818181818183,1.0,2.833333333333333,2.6666666666666665,3.4,3.4285714285714284,3.7142857142857135,3.8,4.0,2.9285714285714284,3.7142857142857135,2.75,4.0,2.923076923076923,2.4285714285714284,1.4,3.0,3.2857142857142856,3.142857142857143,2.25,3.6666666666666665,4.0,3.769230769230769,2.0,3.5,1.0769230769230769,4.0,4.0,2.7142857142857144,3.882352941176471,4.0,3.75,3.25,4.0,3.5,3.25,3.2,3.1666666666666665,3.5,2.6666666666666665,3.25,3.230769230769231,2.8125,3.5,3.090909090909091,3.25,3.0,3.5,3.6,2.5,2.2,3.75,3.6,3.0,3.5,3.4,2.8,2.75,3.2,2.333333333333333,3.1538461538461537,3.4375,3.1875,2.25,3.692307692307693,3.5,2.7142857142857144,3.0,3.5,3.4,2.25,4.0,3.076923076923077,2.833333333333333,3.4375,1.6153846153846154,2.9166666666666665,2.2,4.0,3.0,3.2,3.5,3.230769230769231,2.4444444444444446,4.0,4.0,3.5625,3.625,4.0,3.5,3.733333333333333,1.3846153846153846,3.083333333333333,3.3076923076923075,3.8,4.0,1.25,1.3333333333333333,2.5625,3.25,2.857142857142857,3.4,3.5,3.25,2.8,3.0,3.8,2.3076923076923075,4.0,0.8571428571428571,3.6666666666666665,3.076923076923077,3.4,4.0,2.533333333333333,2.6,3.0,3.769230769230769,3.375,3.6,4.0,2.75,2.2,4.0,3.6,3.8,2.6,3.5,3.3529411764705883,3.6875,3.6,4.0,4.0,3.5,1.6875,3.6875,2.5,3.923076923076923,4.0,3.769230769230769,3.7,4.0,2.8461538461538463,0.5,3.75,2.5,3.2,3.692307692307693,2.75,3.0,3.75,3.357142857142857,3.571428571428572,0.8,3.727272727272727,3.363636363636364,3.75,4.0,3.6666666666666665,4.0,3.3125,2.0,4.0,3.75,2.0,2.9375,2.764705882352941,3.1538461538461537,3.0,2.923076923076923,4.0,2.8,3.6,3.5294117647058822,4.0,1.9375,3.0,2.0,3.75,0.8235294117647058,2.0,3.0,4.0,3.4285714285714284,2.75,2.1666666666666665,2.5625,3.4444444444444446,3.1333333333333333,3.0,3.333333333333333,2.4,3.230769230769231,3.75,4.0,3.4,4.0,0.75,3.0,4.0,3.4,2.5,1.1666666666666667,2.2,2.7333333333333334,1.5384615384615383,4.0,1.4,3.4166666666666665,4.0,3.75,1.5,3.25,3.769230769230769,3.4,3.0,2.6,2.3076923076923075,3.5625,3.3,3.8,3.3076923076923075,3.5454545454545454,2.75,2.25,3.2142857142857144,3.6,3.8125,3.692307692307693,3.769230769230769,3.75,0.0,2.25,3.3125,3.6,4.0,2.5,3.5,3.4,3.642857142857143,2.6666666666666665,3.75,3.0,3.75,3.769230769230769,2.6666666666666665,2.4166666666666665,3.6,3.1818181818181817,3.5454545454545454,2.75,2.0,3.8125,4.0,3.727272727272727,3.0,3.5384615384615383,4.0,3.4,3.142857142857143,1.8,2.25,2.857142857142857,3.0625,2.083333333333333,3.375,1.5,3.6,3.2,3.0,3.625,1.75,3.090909090909091,3.769230769230769,3.0,2.1666666666666665,3.25,2.642857142857143,3.4615384615384617,3.8,2.3,3.333333333333333,2.1538461538461537,2.5,1.5,3.6,3.333333333333333,4.0,1.6666666666666667,4.0,3.571428571428572,4.0,3.0,3.25,3.583333333333333,3.615384615384616,3.5,2.8,3.5,3.230769230769231,2.75,3.6,2.5294117647058822,3.8,2.4166666666666665,1.5,3.2857142857142856,3.0,4.0,3.8,3.090909090909091,1.0,2.25,3.8,3.1875,3.6,2.923076923076923,3.692307692307693,3.4615384615384617,3.466666666666667,3.764705882352941,4.0,3.375,3.692307692307693,1.75,3.5384615384615383,3.5384615384615383,3.5,4.0,2.6666666666666665,4.0,4.0,1.0714285714285714,4.0,2.2142857142857144,3.823529411764706,3.4,2.5,3.0625,2.75,3.4,3.5,4.0,3.2142857142857144,2.6,4.0,0.0,3.25,3.5,3.769230769230769,3.5,3.1538461538461537,3.6,2.8461538461538463,1.8,0.6666666666666666,1.0,3.0,3.071428571428572,3.7857142857142856,3.375,2.2,3.8,4.0,4.0,3.4,3.8,2.3846153846153846,4.0,1.0,2.5294117647058822,2.5,4.0,4.0,4.0,2.333333333333333,2.75,3.2,3.5454545454545454,2.8461538461538463,3.3125,2.8,4.0,3.625,4.0,4.0,3.533333333333333,4.0,3.8,3.0,4.0,3.1666666666666665,2.7857142857142856,4.0,2.125,3.0,3.3529411764705883,3.8,2.2857142857142856,2.071428571428572,2.9375,4.0,3.6666666666666665,2.8,2.75,2.7142857142857144,2.9375,1.5714285714285714,3.2142857142857144,3.5,2.6153846153846154,2.5,2.5,4.0,3.066666666666667,3.333333333333333,2.3125,2.25,3.8125,2.6923076923076925,3.4,3.5625,2.8461538461538463,2.642857142857143,2.769230769230769,3.625,3.2,2.9285714285714284,3.333333333333333,2.5,2.6,2.333333333333333,3.0,4.0,3.6666666666666665,3.0,2.8,4.0,0.4,3.2,3.2,2.0,3.75,3.8,2.8461538461538463,4.0,3.75,3.7142857142857135,2.25,3.75,3.25,3.0,2.6,2.5,3.6666666666666665,3.375,2.8,3.230769230769231,3.4375,4.0,2.6666666666666665,2.0,2.6923076923076925,3.4,3.9166666666666665,3.769230769230769,3.4615384615384617,2.833333333333333,3.25,3.4,2.923076923076923,3.0,2.8181818181818183,3.2857142857142856,1.5,4.0,1.5,4.0,0.0,2.5625,2.8,2.25,2.6666666666666665,3.7857142857142856,3.8,3.6666666666666665,0.6,4.0,3.75,3.5,3.2857142857142856,3.2,3.0,3.25,3.583333333333333,3.0,2.923076923076923,2.6666666666666665,3.0,4.0,3.0,3.0,2.5454545454545454,2.823529411764706,2.066666666666667,3.4,3.333333333333333,2.0,3.692307692307693,3.142857142857143,1.5,3.4,2.25,4.0,3.0,4.0,3.4,2.6923076923076925,2.9285714285714284,2.9285714285714284,3.0,2.4,3.2,4.0,3.2,3.0,3.0,3.0,4.0,1.8,2.357142857142857,2.4285714285714284,3.071428571428572,4.0,2.7142857142857144,4.0,3.3125,1.5,3.75,3.375,3.6,3.4,2.5,4.0,3.411764705882353,3.0,3.230769230769231,3.8125,3.5,3.8,4.0,4.0,2.857142857142857,3.75,3.25,2.3529411764705883,3.5,4.0,3.071428571428572,2.4,3.4615384615384617,4.0,3.0,3.2142857142857144,2.6923076923076925,4.0,3.6666666666666665,2.571428571428572,3.642857142857143,2.5,1.3333333333333333,3.75,2.4166666666666665,3.5454545454545454,4.0,2.090909090909091,3.25,4.0,1.25,3.4,4.0,4.0,3.647058823529412,1.2,3.4,3.3076923076923075,3.5,2.75,3.769230769230769,3.6,3.8,2.333333333333333,3.6,3.75,2.6666666666666665,4.0,2.833333333333333,3.25,3.8,2.75,4.0,3.5454545454545454,2.0,4.0,4.0,3.7142857142857135,2.230769230769231,1.5,2.4,1.2,1.125,2.2,1.2307692307692308,1.0,2.75,3.8125,4.0,2.642857142857143,3.6666666666666665,3.2,3.333333333333333,3.909090909090909,3.75,3.75,3.0,3.6,4.0,3.2,3.4,3.1538461538461537,3.0,2.8,3.25,2.6,2.5,2.2,3.2857142857142856,3.0,2.0,4.0,4.0,2.75,0.4615384615384615,3.4,3.25,3.0,4.0,2.0,3.8,2.75,2.0,3.090909090909091,4.0,3.6666666666666665,2.8461538461538463,3.642857142857143,3.8,2.6666666666666665,4.0,3.1875,3.6,2.25,2.75,1.25,4.0,4.0,3.076923076923077,3.0,3.8,3.6,3.5625,1.2307692307692308,2.2,3.333333333333333,2.25,1.375,2.8,3.733333333333333,1.5,4.0,3.466666666666667,2.0,2.5,3.375,3.769230769230769,2.6923076923076925,3.2,2.272727272727273,2.857142857142857,1.5,1.6,3.272727272727273,2.9285714285714284,3.8125,4.0,3.0,2.230769230769231,3.294117647058824,2.6,2.5625,3.375,3.0,4.0,1.5625,2.5,1.0,4.0,0.8888888888888888,4.0,0.5,4.0,4.0,3.0,3.615384615384616,3.0,3.2,3.2,1.8,3.8,3.0,2.8461538461538463,3.5,2.923076923076923,3.75,3.4285714285714284,4.0,3.0,3.75,3.4,3.5625,4.0,3.2,2.076923076923077,2.75,1.8571428571428568,3.2857142857142856,3.272727272727273,2.9166666666666665,3.5454545454545454,3.636363636363636,2.909090909090909,1.9090909090909087,2.0,2.571428571428572,2.2142857142857144,2.6666666666666665,2.8461538461538463,4.0,4.0,4.0,3.0,2.333333333333333,3.75,4.0,4.0,3.0,1.4285714285714286,2.8461538461538463,2.357142857142857,3.6,2.6,1.75,3.0625,4.0,3.8,1.5,2.25,2.3076923076923075,1.6666666666666667,3.769230769230769,2.75,3.5,3.2,4.0,3.0,2.0,3.25,3.4615384615384617,4.0,3.0,4.0,2.5,2.4375,3.625,3.8,2.5,3.6666666666666665,3.0,3.2,3.4615384615384617,0.0,3.4444444444444446,3.2,2.466666666666667,3.8,0.0,4.0,3.5,3.1538461538461537,3.75,4.0,2.0,2.25,3.2,3.6,2.4285714285714284,3.6,4.0,3.0,0.0,4.0,3.6,2.8181818181818183,3.5,2.833333333333333,3.0,3.75,3.4375,3.5384615384615383,4.0,3.466666666666667,4.0,1.3125,4.0,0.2,3.6666666666666665,3.375,1.4,3.5,2.933333333333333,3.090909090909091,2.8,3.0,3.4,3.230769230769231,2.5384615384615383,4.0,3.0,2.0,2.0,3.5454545454545454,3.076923076923077,2.0,4.0,1.5,1.9285714285714288,4.0,3.5384615384615383,3.7142857142857135,3.6,3.857142857142857,3.75,3.0,3.8,2.6,1.2,4.0,1.7,3.5384615384615383,3.0,2.75,3.2,2.9411764705882355,3.8,3.2,4.0,3.6,1.5,3.0625,3.3846153846153846,3.4615384615384617,3.0,3.2,3.5,4.0,3.0,3.769230769230769,2.5625,3.625,3.7142857142857135,1.9,3.6,1.4,2.1538461538461537,3.4,3.0,2.857142857142857,4.0,4.0,2.0,3.5,3.6875,3.75,2.4615384615384617,3.2,3.357142857142857,2.0,2.3846153846153846,3.4166666666666665,4.0,3.8,3.636363636363636,1.9375,2.6,3.8333333333333335,3.1666666666666665,2.2,1.8,4.0,3.363636363636364,3.142857142857143,4.0,3.0,3.5625,3.6,2.0,2.6666666666666665,0.0,2.5,1.5,3.4,2.25,3.6666666666666665,2.142857142857143,3.75,3.375,4.0,3.4,0.0,3.25,2.9375,1.5,3.75,2.647058823529412,3.272727272727273,4.0,3.4,3.25,2.5,4.0,3.0,3.0,2.9,1.6428571428571428,2.1666666666666665,3.2,2.642857142857143,3.5,1.9230769230769231,3.1538461538461537,2.933333333333333,2.636363636363636,0.3846153846153846,2.0,2.333333333333333,3.6666666666666665,4.0,4.0,3.625,2.0,2.5,4.0,2.6666666666666665,2.25,4.0,3.1538461538461537,4.0,2.3846153846153846,2.0,2.9285714285714284,3.8125,3.8125,4.0,3.5,3.8125,1.2307692307692308,1.3333333333333333,3.3529411764705883,3.2142857142857144,3.5384615384615383,4.0,1.8,3.4,1.0,4.0,3.75,1.3333333333333333,2.0,3.75,3.4,2.0,4.0,4.0,4.0,3.142857142857143,3.5,2.6923076923076925,3.0,3.769230769230769,3.5,3.0,3.0,1.9090909090909087,3.3125,3.75,3.0,3.2142857142857144,4.0,2.75,4.0,2.076923076923077,2.0,2.0,3.25,3.333333333333333,3.4,3.647058823529412,3.2666666666666666,3.375,2.4,2.0,3.5,2.75,2.071428571428572,3.5,3.823529411764706,4.0,3.0,3.0,2.4,4.0,2.6923076923076925,3.125,3.0,3.0,2.75,4.0,3.764705882352941,4.0,3.7857142857142856,3.333333333333333,2.8,2.6875,3.2,3.3,3.25,3.066666666666667,4.0,4.0,3.4,3.5384615384615383,3.6666666666666665,3.0,2.333333333333333,3.0,2.4285714285714284,4.0,3.8125,2.083333333333333,4.0,3.0,2.4,3.625,3.8125,2.5,2.0,2.75,4.0,3.769230769230769,0.0,3.8125,2.333333333333333,2.75,4.0,4.0,2.8461538461538463,4.0,2.5,2.2666666666666666,4.0,2.5,2.0,2.75,3.0,3.8461538461538463,4.0,3.5,3.4,2.933333333333333,3.25,4.0,3.25,3.6,3.8,2.4375,0.0,3.4285714285714284,4.0,1.9285714285714288,3.7857142857142856,3.692307692307693,2.7333333333333334,3.5,3.823529411764706,3.769230769230769,3.5,2.0625,3.533333333333333,4.0,3.0,3.6,3.8,0.0,3.333333333333333,2.75,3.4444444444444446,3.25,2.857142857142857,4.0,3.333333333333333,3.4285714285714284,2.8,4.0,3.357142857142857,3.2857142857142856,3.769230769230769,0.8571428571428571,0.6428571428571429,1.6,1.4545454545454546,3.5,2.9411764705882355,2.8,0.6666666666666666,4.0,2.0,2.75,3.2857142857142856,2.4,2.5,3.2,2.75,3.25,4.0,2.909090909090909,4.0,4.0,3.8125,4.0,3.2,2.75,4.0,2.8461538461538463,1.5384615384615383,3.5,3.571428571428572,1.0,4.0,2.2,3.625,3.8,3.363636363636364,4.0,3.3846153846153846,3.6,4.0,4.0,3.5,2.923076923076923,3.25,2.5,4.0,2.6,3.4,3.6,3.4615384615384617,3.8,3.75,3.4,2.0,4.0,4.0,3.0,3.4,3.3076923076923075,3.0,2.8461538461538463,2.5625,2.769230769230769,2.8125,3.5625,2.25,3.5,0.4285714285714285,3.3846153846153846,1.75,3.7857142857142856,2.5,3.0,4.0,3.3076923076923075,2.8,3.4,3.0,2.375,3.066666666666667,3.692307692307693,4.0,3.0,2.7857142857142856,4.0,4.0,3.8,2.272727272727273,2.0,2.4615384615384617,3.25,2.8,3.769230769230769,3.466666666666667,1.75,3.571428571428572,2.6,1.0,3.2,3.071428571428572,2.1538461538461537,1.5,2.6153846153846154,4.0,3.642857142857143,1.1428571428571428,4.0,3.0,4.0,3.6,3.4615384615384617,2.9285714285714284,3.4,4.0,3.466666666666667,3.076923076923077,1.5,2.5,3.4375,2.8125,2.25,0.75,3.4,3.769230769230769,3.75,4.0,2.7142857142857144,2.933333333333333,2.833333333333333,4.0,3.1333333333333333,3.25,2.5,2.75,2.375,3.2,3.0,3.0,3.75,2.8666666666666667,2.583333333333333,3.642857142857143,2.6923076923076925,3.0,2.7142857142857144,2.466666666666667,2.5,3.4,2.6923076923076925,2.375,2.2,2.076923076923077,4.0,2.0,3.333333333333333,3.25,2.923076923076923,2.5,3.4615384615384617,4.0,4.0,1.0,4.0,3.25,3.25,3.357142857142857,3.75,2.4545454545454546,3.571428571428572,3.0,3.25,3.0625,2.5,2.9,3.2,3.8333333333333335,3.076923076923077,3.769230769230769,4.0,3.6,2.6666666666666665],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>GPA_2=%{x}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"notched\":false,\"offsetgroup\":\"1\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[3.333333333333333,0.0,1.0,1.3333333333333333,0.0,0.5,0.0,0.6,1.4,0.75,0.0,3.0,3.571428571428572,0.2666666666666666,1.5,2.333333333333333,1.0,2.6875,3.3846153846153846,0.4615384615384615,0.0,0.0,1.5,3.0,2.363636363636364,4.0,2.75,0.0,0.0,1.2857142857142858,2.727272727272727,1.3333333333333333,1.5,3.5,3.333333333333333,0.0,1.0,0.0,0.0,3.5384615384615383,0.0,3.0,1.8,2.8125,1.0,1.25,0.2222222222222222,0.0,3.230769230769231,3.5384615384615383,0.0,1.2,0.625,1.3333333333333333,0.0,0.0,2.8,0.0,1.1538461538461535,0.25,0.0,0.6,1.0833333333333333,1.0,1.5,1.0,0.25,4.0,1.0,0.25,4.0,0.2857142857142857,0.75,0.9,2.5,2.7,3.5,3.0,0.0,1.8,3.5,3.5,3.0,2.071428571428572,0.0,0.75,0.0,1.0,2.0,2.0,0.3076923076923077,2.9375,1.2857142857142858,4.0,3.6,0.4,0.0,0.4,1.0,0.0,1.5,2.6666666666666665,3.6666666666666665,1.375,0.0,0.0,4.0,0.0,0.0,0.0,0.5,4.0,2.5,0.3,0.0,4.0,0.2,0.0,3.5,3.8,0.4,1.6666666666666667,0.0,0.3333333333333333,1.75,0.0,1.3333333333333333,3.176470588235294,2.333333333333333,2.0,0.0,3.0,1.0,2.5,0.0,0.75,0.375,3.6666666666666665,0.75,0.1538461538461538,1.5,0.0,2.0,3.235294117647059,0.0,2.5,2.8666666666666667,1.7,1.1,0.0,3.5,2.4,0.0,4.0,2.25,3.769230769230769,2.6,4.0,0.2,1.3333333333333333,3.142857142857143,0.0,2.5,1.3333333333333333,0.0,1.0,1.4285714285714286,2.7142857142857144,0.6666666666666666,0.25,1.5,4.0,2.75,2.5,0.9375,0.0,0.0,3.2,3.2,0.0,0.1428571428571428,0.0,2.75,0.0,1.6666666666666667,3.25,3.5,3.0,1.25,0.0,0.5,0.0,2.25,1.0,1.6,0.0,2.923076923076923,0.8571428571428571,4.0,0.75,3.0,2.4285714285714284,3.25,0.6666666666666666,2.1666666666666665,0.0,1.0,2.4615384615384617,3.75,4.0,0.0,0.4,2.6,0.8,1.0,1.0,2.4375,1.375,2.0,3.764705882352941,2.0,0.0,3.111111111111111,3.6666666666666665,3.5,2.8461538461538463,1.3333333333333333,0.75,0.0,0.0,0.0,1.0,1.25,2.75,2.0,1.3333333333333333,3.363636363636364,0.0,0.0,3.25,2.0,0.8888888888888888,0.8181818181818182,1.5,3.25,2.6,3.235294117647059,0.0,1.5,4.0,0.0,1.5,0.2142857142857142,0.75,3.071428571428572,0.5,0.0,3.1538461538461537,0.375,2.076923076923077,0.0,3.125,4.0,0.1875,0.6,3.25,3.230769230769231,4.0,0.2222222222222222,3.125,1.0,0.0,2.8,2.333333333333333,0.0,0.0,1.1111111111111112,2.0625,0.25,0.0,3.0,0.0,4.0,0.4,0.0,2.571428571428572,0.1333333333333333,3.769230769230769,0.0,3.0,1.0,2.0,0.0,4.0,0.8,4.0,1.5,4.0,3.75,1.9375,3.333333333333333,1.0,3.5,2.5454545454545454,2.0,3.6,2.5,0.0,3.0,0.3,3.333333333333333,0.0,0.0,0.0,0.0,1.25,1.5,3.4,0.5,2.2857142857142856,0.0,0.0,0.0,3.2,0.4615384615384615,0.3846153846153846,2.0,3.071428571428572,4.0,1.3333333333333333,2.8181818181818183,2.588235294117647,2.0,0.6,1.5714285714285714,1.6666666666666667,0.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"GPA_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"SEM_3_STATUS\"},\"categoryorder\":\"array\",\"categoryarray\":[1,0]},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\")) {                    Plotly.newPlot(                        \"7815687e-8cb1-4ec8-a6fa-6f0c25cc6746\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>GPA_2=%{x}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"notched\":false,\"offsetgroup\":\"0\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[1.6666666666666667,3.6875,1.6923076923076923,4.0,1.5,2.75,2.071428571428572,4.0,2.25,4.0,2.25,2.75,4.0,3.1,3.5384615384615383,3.0,3.25,4.0,4.0,2.4,2.6,3.5384615384615383,3.333333333333333,4.0,2.4375,3.0,2.6923076923076925,3.5,3.8,3.333333333333333,3.5625,2.625,1.0,3.8,2.933333333333333,2.6666666666666665,2.6,4.0,3.5384615384615383,3.6,3.769230769230769,4.0,2.1333333333333333,1.5454545454545454,2.8,3.125,3.0,4.0,3.7142857142857135,4.0,3.4285714285714284,3.75,2.1333333333333333,2.7142857142857144,3.0,3.8,3.5384615384615383,4.0,3.4,3.5,4.0,4.0,2.4615384615384617,3.75,4.0,2.6,2.6,2.125,3.769230769230769,1.8,4.0,3.8,3.5,2.6923076923076925,2.0,2.0,4.0,3.5,3.733333333333333,3.5,4.0,4.0,4.0,4.0,3.733333333333333,3.3125,3.076923076923077,1.0,3.4,0.3333333333333333,2.4,4.0,2.9166666666666665,3.8125,2.25,4.0,2.3846153846153846,3.5,4.0,3.0,3.230769230769231,3.25,4.0,3.0,4.0,2.6875,3.272727272727273,4.0,4.0,2.6666666666666665,2.5,3.5,2.5454545454545454,3.1578947368421053,2.6666666666666665,3.1666666666666665,3.0,4.0,3.8,3.8125,3.533333333333333,3.1818181818181817,2.0,3.466666666666667,4.0,3.1875,4.0,3.647058823529412,2.5,3.4,3.333333333333333,3.692307692307693,2.0,4.0,3.8125,3.2,3.625,3.0,3.3076923076923075,1.0,4.0,3.0,2.923076923076923,2.363636363636364,4.0,2.8125,2.4,2.466666666666667,3.5,2.75,4.0,1.25,3.0,3.4,3.7,3.769230769230769,2.333333333333333,3.5,2.8,3.5384615384615383,3.4,3.0,4.0,4.0,3.375,3.4615384615384617,3.2,3.333333333333333,2.3125,0.2857142857142857,3.25,3.4615384615384617,3.2,1.1666666666666667,2.4166666666666665,3.5384615384615383,2.75,3.25,3.733333333333333,4.0,3.533333333333333,2.0,2.2,2.5,4.0,3.4,3.6,2.6923076923076925,0.0,3.6666666666666665,2.0,3.6666666666666665,3.75,3.2,2.6666666666666665,3.625,1.8571428571428568,3.25,4.0,3.5625,3.75,3.6,2.0,2.8461538461538463,2.75,3.25,3.0,2.6923076923076925,3.5384615384615383,3.0625,3.4375,3.4,2.6,1.6923076923076923,2.25,3.4,3.272727272727273,3.25,2.8,3.5384615384615383,2.7857142857142856,3.2857142857142856,2.1538461538461537,3.7142857142857135,3.5454545454545454,1.5555555555555556,1.5,3.4,3.6,4.0,2.25,3.6666666666666665,3.2857142857142856,2.75,4.0,4.0,4.0,3.727272727272727,3.75,3.769230769230769,3.25,3.7142857142857135,3.0,0.0,3.615384615384616,3.8,3.2,3.117647058823529,4.0,2.8,4.0,2.75,4.0,3.769230769230769,2.5,3.933333333333333,2.25,1.8,4.0,2.9285714285714284,3.8125,4.0,3.6,3.5384615384615383,3.230769230769231,4.0,1.8,3.066666666666667,0.5,3.0,2.1538461538461537,2.0,3.75,3.071428571428572,3.5,2.833333333333333,3.4615384615384617,3.9375,3.6666666666666665,3.1538461538461537,3.8,3.2,2.5,3.625,2.090909090909091,4.0,3.3076923076923075,4.0,2.0,2.0,3.588235294117647,3.6,3.0,3.0,3.3846153846153846,3.25,4.0,4.0,0.0,3.5625,2.4615384615384617,3.692307692307693,3.769230769230769,3.333333333333333,2.6,3.6,0.6428571428571429,3.583333333333333,3.6666666666666665,3.066666666666667,3.75,0.5,3.5,2.6923076923076925,3.1538461538461537,2.8461538461538463,3.1538461538461537,4.0,3.5454545454545454,3.733333333333333,3.2,4.0,2.5,4.0,2.5,3.625,2.0,3.8,3.25,3.6,3.75,4.0,4.0,3.4615384615384617,1.181818181818182,3.0,3.3125,3.0,3.375,3.0,2.642857142857143,3.0,2.0,4.0,2.5,2.909090909090909,3.333333333333333,2.0,4.0,4.0,3.0,2.75,3.357142857142857,3.8,2.2,2.6,4.0,3.0,1.5833333333333333,2.571428571428572,3.75,2.857142857142857,3.4,2.4,3.066666666666667,0.0,3.727272727272727,2.25,4.0,3.4166666666666665,3.769230769230769,4.0,1.3333333333333333,3.333333333333333,4.0,2.6,2.9375,3.5384615384615383,3.4615384615384617,1.6666666666666667,3.6,4.0,2.4,0.0,4.0,3.2,2.625,3.1538461538461537,2.2,3.8125,2.5,4.0,3.333333333333333,4.0,3.0,3.0625,3.0,4.0,1.3846153846153846,3.8,3.4375,2.5,3.0,3.8,3.0,3.0,3.3846153846153846,4.0,2.583333333333333,4.0,4.0,2.5,4.0,3.0,3.333333333333333,2.4285714285714284,3.2666666666666666,2.230769230769231,3.5454545454545454,4.0,4.0,3.3846153846153846,4.0,0.25,3.076923076923077,4.0,4.0,2.7142857142857144,3.533333333333333,3.3846153846153846,3.0,3.625,1.5625,3.5,3.357142857142857,3.25,2.857142857142857,3.75,3.0625,3.0,3.692307692307693,3.6,2.75,2.2,2.0,4.0,4.0,3.0,3.692307692307693,4.0,2.0,3.75,1.0,3.6,2.6666666666666665,3.5454545454545454,3.25,2.8,3.6666666666666665,2.5384615384615383,2.0,2.75,3.0,3.25,2.2,3.2,1.6,3.0,2.0,3.272727272727273,3.066666666666667,3.6875,3.1538461538461537,3.6,2.2142857142857144,3.1666666666666665,3.375,3.5625,1.4285714285714286,3.2666666666666666,4.0,2.0,1.0,4.0,3.1333333333333333,3.4,3.25,3.75,3.5,3.25,2.7857142857142856,3.8,3.6,3.727272727272727,2.4615384615384617,4.0,1.9166666666666667,2.5,3.0,2.8181818181818183,3.4,3.2,3.0,2.230769230769231,3.5,4.0,3.6,3.4,3.3076923076923075,3.2,2.923076923076923,2.75,4.0,1.5,3.0,3.625,3.5,4.0,3.0,4.0,3.5,4.0,2.8,1.4285714285714286,4.0,3.692307692307693,2.5,2.8,3.25,3.0,2.8,4.0,2.0,2.0,3.4,3.8,3.8333333333333335,1.9230769230769231,2.7058823529411766,3.117647058823529,3.3076923076923075,0.5384615384615384,4.0,1.4285714285714286,3.4,2.0,0.2,4.0,3.2,4.0,3.8125,3.6,4.0,3.8,4.0,1.8,3.076923076923077,1.0,3.0,3.8125,2.5,3.8,3.5,3.375,3.6,3.0,1.9090909090909087,1.6,3.2857142857142856,3.625,3.2666666666666666,3.0,3.4615384615384617,2.0,2.5,2.0,4.0,2.4,3.0,2.4615384615384617,3.4615384615384617,3.5,3.0,3.4,2.8666666666666667,0.6,1.3333333333333333,3.4615384615384617,3.1666666666666665,3.5,3.0,3.333333333333333,2.8461538461538463,3.0,3.5,4.0,2.0,3.8,2.5,3.2,2.4615384615384617,3.8,4.0,3.25,1.3333333333333333,3.3076923076923075,3.0,3.6666666666666665,3.8,3.25,3.0,3.8,3.7857142857142856,2.8181818181818183,3.8,3.071428571428572,3.0,1.9,3.0,3.25,2.6,4.0,3.533333333333333,3.2,3.8333333333333335,3.733333333333333,2.0625,3.5384615384615383,2.75,3.5,3.8,3.5,1.25,3.8,3.75,2.9166666666666665,4.0,3.8,3.2,2.6,3.0,0.1875,4.0,2.0,3.2,3.588235294117647,1.6666666666666667,4.0,4.0,3.5,2.272727272727273,3.4,3.7777777777777777,3.083333333333333,1.6153846153846154,3.8125,3.6,3.8125,3.333333333333333,2.333333333333333,2.25,1.0666666666666669,0.8,3.1875,3.75,3.5,3.615384615384616,0.0,3.75,3.1538461538461537,3.692307692307693,3.3846153846153846,1.9230769230769231,2.5,2.4,3.6666666666666665,3.0,3.692307692307693,2.25,2.6,2.8125,3.1666666666666665,3.066666666666667,3.0,3.75,3.75,4.0,3.8125,4.0,2.8461538461538463,2.4,2.6,3.5,4.0,0.0,3.2,1.6666666666666667,3.692307692307693,3.75,3.8,4.0,3.75,2.4615384615384617,3.1875,2.333333333333333,3.625,3.8,3.727272727272727,1.9285714285714288,3.1666666666666665,3.4,4.0,2.75,3.0,2.076923076923077,2.6666666666666665,3.230769230769231,2.647058823529412,4.0,3.25,1.5,3.333333333333333,3.2222222222222223,3.1538461538461537,3.923076923076923,4.0,2.25,2.1333333333333333,4.0,3.75,3.333333333333333,3.0,3.6,3.0,4.0,3.25,2.4375,3.0,3.75,2.5,3.5625,3.4,2.5,3.0625,1.6666666666666667,3.230769230769231,3.75,4.0,3.0,4.0,3.0,3.6,2.4,3.1875,4.0,3.75,1.6,2.75,3.8,4.0,3.2,3.5,3.4705882352941178,3.25,3.230769230769231,1.8,2.4,2.75,1.7272727272727273,4.0,3.1875,2.4,2.75,3.75,3.071428571428572,2.5,3.4,3.375,3.5,4.0,2.176470588235294,3.2142857142857144,4.0,3.6,4.0,1.4615384615384617,2.25,3.7857142857142856,3.0,3.769230769230769,4.0,1.9333333333333331,3.2,4.0,4.0,4.0,1.9166666666666667,3.5,2.5625,3.6666666666666665,3.571428571428572,3.0625,4.0,2.071428571428572,3.8,3.0,2.9166666666666665,2.8461538461538463,3.7142857142857135,2.5,4.0,2.6153846153846154,2.0,4.0,3.1875,2.5,3.2666666666666666,3.75,4.0,3.0,2.6,3.5,4.0,3.4375,3.4,3.5625,2.357142857142857,1.3076923076923077,3.6666666666666665,3.2,3.75,1.6666666666666667,2.0,2.75,3.6,4.0,2.923076923076923,3.4615384615384617,2.2,2.8,2.571428571428572,2.0,3.0,3.333333333333333,2.8666666666666667,1.8,3.8,3.8,3.6,3.0,0.0,3.4166666666666665,3.8125,3.25,4.0,2.571428571428572,3.0,3.0,2.125,1.6363636363636365,2.0,2.0,3.0,2.066666666666667,3.6,0.0,3.333333333333333,1.4,2.75,4.0,0.0,2.8,4.0,2.230769230769231,3.6,3.6666666666666665,3.25,3.0,2.0,2.8,3.764705882352941,4.0,3.2,3.0,3.0,3.0,2.0,3.75,2.75,4.0,1.6,3.571428571428572,3.6,4.0,3.6,2.5,2.4615384615384617,3.727272727272727,4.0,2.25,3.8,4.0,3.5,4.0,4.0,2.230769230769231,3.8,4.0,3.8,2.933333333333333,3.75,3.4166666666666665,2.923076923076923,3.6,2.6666666666666665,3.6,4.0,2.357142857142857,4.0,3.2,2.8,4.0,2.7333333333333334,3.2,2.8,4.0,3.230769230769231,3.25,2.5,2.0,1.6153846153846154,4.0,3.1333333333333333,4.0,1.4545454545454546,3.75,3.625,2.75,4.0,3.2142857142857144,2.4,3.692307692307693,3.230769230769231,3.0,4.0,2.75,3.5,3.7058823529411766,4.0,2.1666666666666665,3.0,3.6666666666666665,4.0,3.0,3.4705882352941178,3.0,3.75,1.75,4.0,2.230769230769231,3.75,3.4,2.0,3.272727272727273,3.5625,2.8,0.1666666666666666,3.8125,3.8125,1.8,3.1,2.75,3.0,0.0,3.8,2.4,3.142857142857143,2.923076923076923,2.875,2.769230769230769,3.692307692307693,3.4545454545454546,3.0,3.1538461538461537,3.692307692307693,2.8181818181818183,2.75,3.625,3.25,3.6666666666666665,1.9411764705882355,4.0,1.9090909090909087,3.692307692307693,3.625,2.75,3.571428571428572,2.75,2.75,1.0,2.0,3.75,4.0,2.272727272727273,2.75,3.2142857142857144,3.6666666666666665,3.6,3.4,4.0,2.769230769230769,3.25,3.5,3.0,2.6153846153846154,1.75,1.6666666666666667,3.4615384615384617,3.5384615384615383,3.272727272727273,3.5384615384615383,3.3529411764705883,2.6,1.3888888888888888,4.0,3.625,3.7777777777777777,4.0,3.0,3.571428571428572,3.25,2.0,4.0,3.0,4.0,3.0,4.0,3.272727272727273,3.5454545454545454,2.357142857142857,4.0,4.0,3.230769230769231,3.555555555555556,3.7857142857142856,4.0,4.0,3.333333333333333,4.0,3.3125,2.6,1.2857142857142858,2.2142857142857144,2.5,2.4285714285714284,3.6,3.1538461538461537,1.25,2.4615384615384617,3.6666666666666665,3.625,3.6,3.5,3.25,2.5,3.333333333333333,2.8,3.8,4.0,4.0,2.8461538461538463,3.8125,3.230769230769231,3.75,3.571428571428572,3.6666666666666665,3.5384615384615383,3.8,1.2352941176470589,3.2,2.75,3.6666666666666665,0.0,3.4,3.6666666666666665,3.769230769230769,3.75,4.0,3.75,2.8181818181818183,3.2142857142857144,3.0,3.75,3.8,2.272727272727273,4.0,2.7142857142857144,3.25,3.176470588235294,3.769230769230769,4.0,3.230769230769231,3.333333333333333,2.5,3.5,3.357142857142857,3.692307692307693,3.0,3.5,3.1875,2.7,3.0,3.75,3.2,3.6666666666666665,2.25,3.4375,3.5,3.6666666666666665,3.6,2.6,2.4615384615384617,3.571428571428572,2.8,3.2,2.8,3.0,2.2142857142857144,2.0,2.1818181818181817,2.25,3.2,4.0,4.0,0.4615384615384615,4.0,1.6666666666666667,3.6,3.5454545454545454,3.1666666666666665,2.25,3.75,1.5,0.4615384615384615,3.2,3.642857142857143,4.0,2.6,3.4,2.4615384615384617,3.2857142857142856,3.076923076923077,2.8,2.4615384615384617,3.2,3.333333333333333,2.3125,2.2857142857142856,3.75,3.4,3.6,0.6153846153846154,3.0,3.6666666666666665,4.0,3.2857142857142856,4.0,3.625,3.4,3.2777777777777777,4.0,1.5,4.0,1.3076923076923077,4.0,3.2,3.8,4.0,4.0,3.0,4.0,2.7777777777777777,3.6,3.5,3.8,2.8,3.2,3.066666666666667,2.1333333333333333,4.0,2.4615384615384617,3.75,4.0,1.75,3.5,2.375,2.875,3.0,3.0,3.2,0.9375,3.6666666666666665,4.0,3.6,3.2,3.0,3.642857142857143,4.0,2.4615384615384617,3.5384615384615383,4.0,4.0,3.1538461538461537,3.0,4.0,4.0,2.533333333333333,3.75,4.0,3.3076923076923075,0.8,3.230769230769231,3.4375,4.0,2.6,2.0,4.0,3.0,3.2142857142857144,3.071428571428572,3.6,3.4,3.6,0.6666666666666666,4.0,3.1538461538461537,2.4,1.4,0.375,3.769230769230769,4.0,3.5625,4.0,2.4,2.25,3.6,4.0,2.8,2.363636363636364,4.0,4.0,3.8125,3.769230769230769,3.8125,2.7333333333333334,1.8,3.5,2.7333333333333334,2.7333333333333334,2.5384615384615383,1.3636363636363635,3.4545454545454546,2.8,3.25,4.0,2.6153846153846154,3.5,1.8,3.25,2.8,4.0,3.357142857142857,3.0,3.5625,3.357142857142857,1.25,3.6666666666666665,1.5,2.75,4.0,4.0,3.8,4.0,1.3,2.5454545454545454,2.0,4.0,3.75,1.6153846153846154,3.5384615384615383,3.2,3.769230769230769,3.0,3.8125,4.0,4.0,3.25,3.6666666666666665,3.8,3.0,2.6153846153846154,1.8,3.8,2.75,3.75,3.6,2.0,1.6,3.5,3.923076923076923,3.230769230769231,3.909090909090909,4.0,3.8,4.0,3.0,3.4,3.230769230769231,3.5625,4.0,3.2,0.0,0.2,4.0,4.0,3.2,2.4615384615384617,3.2,1.9230769230769231,0.4285714285714285,2.0,2.1666666666666665,3.0,3.8125,3.4,3.25,3.6666666666666665,3.5,4.0,3.5,2.727272727272727,2.727272727272727,0.3333333333333333,4.0,3.571428571428572,0.6153846153846154,3.6,3.0,2.8,3.0,3.0,3.0,3.533333333333333,2.75,3.5,1.75,3.0,4.0,3.5,3.533333333333333,1.6,3.8,4.0,3.5,3.4,3.642857142857143,2.6153846153846154,4.0,3.625,3.0625,2.6923076923076925,3.5,3.75,3.6,4.0,2.769230769230769,3.692307692307693,2.8,2.5,2.5,3.8,2.8,2.25,3.615384615384616,3.5,3.8,3.066666666666667,3.642857142857143,2.0,3.25,2.8461538461538463,1.9230769230769231,4.0,3.5,3.5625,2.25,3.5454545454545454,3.6,2.466666666666667,3.636363636363636,3.4,3.0,3.571428571428572,3.0,2.1538461538461537,3.8,3.625,2.75,3.75,2.2142857142857144,0.8,3.0,3.235294117647059,2.6,3.2,4.0,4.0,2.75,3.25,3.75,2.4615384615384617,3.4,4.0,3.75,2.5454545454545454,3.5454545454545454,3.5,3.2,2.1875,3.230769230769231,4.0,3.6666666666666665,4.0,2.625,2.2857142857142856,3.6,2.7857142857142856,3.0,3.692307692307693,4.0,3.4,3.0625,3.4,3.6,3.25,1.75,3.4,2.6923076923076925,3.25,2.6153846153846154,4.0,1.2142857142857142,2.230769230769231,3.090909090909091,3.2,4.0,4.0,2.75,3.642857142857143,2.5625,3.117647058823529,3.2,4.0,3.5,2.9375,4.0,1.0666666666666669,2.8,3.7142857142857135,4.0,3.0625,2.555555555555556,4.0,3.230769230769231,2.2142857142857144,3.4375,4.0,1.5,2.6,3.8125,3.0,3.0,3.0,3.4,2.8,2.8461538461538463,3.2857142857142856,1.75,3.2,2.6875,3.8,2.4285714285714284,3.6,3.4,3.5,3.823529411764706,3.5625,2.6,3.642857142857143,3.4166666666666665,3.0,3.5,3.090909090909091,2.5,3.066666666666667,3.0,3.466666666666667,2.1538461538461537,2.9285714285714284,4.0,1.8,3.0,3.375,3.2,2.8,4.0,1.4,2.0,4.0,3.75,2.8461538461538463,1.6666666666666667,2.5,0.0,3.466666666666667,3.636363636363636,3.25,3.7142857142857135,4.0,3.0,3.333333333333333,3.2,3.8125,3.6875,1.8,4.0,3.2666666666666666,3.8,3.6,2.857142857142857,4.0,4.0,3.75,1.4545454545454546,3.8,3.6,3.8125,3.6,2.5,3.4,2.8181818181818183,1.6,3.75,2.333333333333333,3.75,3.6666666666666665,2.0,2.4166666666666665,3.6,4.0,4.0,2.875,4.0,3.142857142857143,2.75,2.6,2.375,3.3,3.8125,3.6,2.571428571428572,3.0625,3.636363636363636,2.5,4.0,3.2666666666666666,3.8,3.2,3.8,2.0,3.5,3.25,4.0,2.7857142857142856,4.0,3.8,2.9166666666666665,2.75,3.4615384615384617,2.5,4.0,2.9375,4.0,3.0,4.0,2.3846153846153846,1.8461538461538465,2.0625,2.5,3.0,2.7,3.25,3.625,3.6666666666666665,2.0625,3.4,3.25,3.1666666666666665,3.6,3.0,1.5,4.0,3.4615384615384617,3.125,3.375,3.8125,2.6153846153846154,2.0625,3.6666666666666665,3.4,4.0,1.0,1.75,4.0,4.0,4.0,3.5,2.75,4.0,4.0,3.0,4.0,2.923076923076923,3.333333333333333,3.625,3.5,4.0,2.4,4.0,4.0,3.0,1.6875,3.5625,3.642857142857143,3.4,4.0,2.5,1.6,1.3076923076923077,4.0,3.733333333333333,3.4615384615384617,2.4,3.8125,3.5625,3.375,3.4,3.733333333333333,4.0,3.25,3.142857142857143,4.0,4.0,3.8,3.4545454545454546,3.25,2.4,2.7,3.5384615384615383,3.5,3.8125,3.235294117647059,3.75,1.2,3.647058823529412,3.5,2.3076923076923075,2.8666666666666667,3.6,0.75,3.0625,2.75,2.2222222222222223,4.0,3.6,3.0,3.625,4.0,3.0625,1.5,3.2142857142857144,4.0,2.4,3.2,0.0,3.5,3.0,1.1538461538461535,2.75,3.2142857142857144,2.4,3.3846153846153846,3.2,2.75,1.8,3.6,3.2,3.8125,2.5625,3.7857142857142856,0.9166666666666666,3.0,3.2142857142857144,2.6153846153846154,3.692307692307693,4.0,3.0,3.333333333333333,3.25,4.0,2.3076923076923075,3.8,3.25,3.125,2.75,2.9375,2.5,3.5,3.8125,3.0,4.0,2.4,3.75,3.4,4.0,3.3125,3.727272727272727,4.0,1.6666666666666667,3.333333333333333,2.75,3.8,2.75,2.0,3.2,3.0,2.857142857142857,3.8125,1.0,4.0,2.25,2.363636363636364,4.0,3.25,3.357142857142857,0.9333333333333332,2.769230769230769,3.75,4.0,1.4166666666666667,3.75,1.0,3.6,3.7142857142857135,4.0,3.615384615384616,3.8,2.333333333333333,3.4,3.090909090909091,3.75,2.6923076923076925,2.25,4.0,3.769230769230769,1.75,3.2,2.2,2.75,3.2,3.0,3.75,3.375,3.8125,3.526315789473684,3.533333333333333,4.0,2.0,3.7857142857142856,3.0,2.6666666666666665,2.0,4.0,3.272727272727273,2.888888888888889,3.090909090909091,3.0,4.0,1.25,3.8,3.0,2.8,4.0,2.2222222222222223,3.0,4.0,1.6923076923076923,4.0,3.0,3.5,3.75,2.75,4.0,4.0,3.615384615384616,3.0625,1.25,3.0,3.0,1.25,3.5,3.8,0.375,3.8,0.9333333333333332,3.6666666666666665,2.2142857142857144,3.2,2.8461538461538463,1.8,3.2,3.25,2.5,3.8,3.769230769230769,2.7142857142857144,1.75,4.0,2.75,3.0,3.75,3.25,3.4615384615384617,3.4,2.4285714285714284,1.5384615384615383,3.2,4.0,2.8,1.0,3.733333333333333,3.25,2.5,3.4285714285714284,3.0,3.4166666666666665,3.571428571428572,2.125,3.0,3.0,4.0,3.0,2.857142857142857,1.5,3.0,4.0,2.8181818181818183,3.8,2.1538461538461537,3.083333333333333,1.5,2.0,4.0,2.2,3.4375,2.5,3.5454545454545454,1.3333333333333333,3.75,4.0,1.6666666666666667,4.0,3.6,1.5,2.5,3.4,3.0,3.0,1.5,4.0,2.0,4.0,4.0,3.533333333333333,3.4,2.9375,3.4,4.0,4.0,4.0,3.8125,2.1333333333333333,3.0,1.2,2.9375,2.1818181818181817,2.25,2.375,3.0,3.533333333333333,1.0,2.75,1.25,3.6,3.2,2.75,4.0,2.1538461538461537,2.75,3.5,4.0,4.0,4.0,3.272727272727273,3.0,4.0,1.1333333333333333,3.0,3.75,2.8181818181818183,1.0,2.833333333333333,2.6666666666666665,3.4,3.4285714285714284,3.7142857142857135,3.8,4.0,2.9285714285714284,3.7142857142857135,2.75,4.0,2.923076923076923,2.4285714285714284,1.4,3.0,3.2857142857142856,3.142857142857143,2.25,3.6666666666666665,4.0,3.769230769230769,2.0,3.5,1.0769230769230769,4.0,4.0,2.7142857142857144,3.882352941176471,4.0,3.75,3.25,4.0,3.5,3.25,3.2,3.1666666666666665,3.5,2.6666666666666665,3.25,3.230769230769231,2.8125,3.5,3.090909090909091,3.25,3.0,3.5,3.6,2.5,2.2,3.75,3.6,3.0,3.5,3.4,2.8,2.75,3.2,2.333333333333333,3.1538461538461537,3.4375,3.1875,2.25,3.692307692307693,3.5,2.7142857142857144,3.0,3.5,3.4,2.25,4.0,3.076923076923077,2.833333333333333,3.4375,1.6153846153846154,2.9166666666666665,2.2,4.0,3.0,3.2,3.5,3.230769230769231,2.4444444444444446,4.0,4.0,3.5625,3.625,4.0,3.5,3.733333333333333,1.3846153846153846,3.083333333333333,3.3076923076923075,3.8,4.0,1.25,1.3333333333333333,2.5625,3.25,2.857142857142857,3.4,3.5,3.25,2.8,3.0,3.8,2.3076923076923075,4.0,0.8571428571428571,3.6666666666666665,3.076923076923077,3.4,4.0,2.533333333333333,2.6,3.0,3.769230769230769,3.375,3.6,4.0,2.75,2.2,4.0,3.6,3.8,2.6,3.5,3.3529411764705883,3.6875,3.6,4.0,4.0,3.5,1.6875,3.6875,2.5,3.923076923076923,4.0,3.769230769230769,3.7,4.0,2.8461538461538463,0.5,3.75,2.5,3.2,3.692307692307693,2.75,3.0,3.75,3.357142857142857,3.571428571428572,0.8,3.727272727272727,3.363636363636364,3.75,4.0,3.6666666666666665,4.0,3.3125,2.0,4.0,3.75,2.0,2.9375,2.764705882352941,3.1538461538461537,3.0,2.923076923076923,4.0,2.8,3.6,3.5294117647058822,4.0,1.9375,3.0,2.0,3.75,0.8235294117647058,2.0,3.0,4.0,3.4285714285714284,2.75,2.1666666666666665,2.5625,3.4444444444444446,3.1333333333333333,3.0,3.333333333333333,2.4,3.230769230769231,3.75,4.0,3.4,4.0,0.75,3.0,4.0,3.4,2.5,1.1666666666666667,2.2,2.7333333333333334,1.5384615384615383,4.0,1.4,3.4166666666666665,4.0,3.75,1.5,3.25,3.769230769230769,3.4,3.0,2.6,2.3076923076923075,3.5625,3.3,3.8,3.3076923076923075,3.5454545454545454,2.75,2.25,3.2142857142857144,3.6,3.8125,3.692307692307693,3.769230769230769,3.75,0.0,2.25,3.3125,3.6,4.0,2.5,3.5,3.4,3.642857142857143,2.6666666666666665,3.75,3.0,3.75,3.769230769230769,2.6666666666666665,2.4166666666666665,3.6,3.1818181818181817,3.5454545454545454,2.75,2.0,3.8125,4.0,3.727272727272727,3.0,3.5384615384615383,4.0,3.4,3.142857142857143,1.8,2.25,2.857142857142857,3.0625,2.083333333333333,3.375,1.5,3.6,3.2,3.0,3.625,1.75,3.090909090909091,3.769230769230769,3.0,2.1666666666666665,3.25,2.642857142857143,3.4615384615384617,3.8,2.3,3.333333333333333,2.1538461538461537,2.5,1.5,3.6,3.333333333333333,4.0,1.6666666666666667,4.0,3.571428571428572,4.0,3.0,3.25,3.583333333333333,3.615384615384616,3.5,2.8,3.5,3.230769230769231,2.75,3.6,2.5294117647058822,3.8,2.4166666666666665,1.5,3.2857142857142856,3.0,4.0,3.8,3.090909090909091,1.0,2.25,3.8,3.1875,3.6,2.923076923076923,3.692307692307693,3.4615384615384617,3.466666666666667,3.764705882352941,4.0,3.375,3.692307692307693,1.75,3.5384615384615383,3.5384615384615383,3.5,4.0,2.6666666666666665,4.0,4.0,1.0714285714285714,4.0,2.2142857142857144,3.823529411764706,3.4,2.5,3.0625,2.75,3.4,3.5,4.0,3.2142857142857144,2.6,4.0,0.0,3.25,3.5,3.769230769230769,3.5,3.1538461538461537,3.6,2.8461538461538463,1.8,0.6666666666666666,1.0,3.0,3.071428571428572,3.7857142857142856,3.375,2.2,3.8,4.0,4.0,3.4,3.8,2.3846153846153846,4.0,1.0,2.5294117647058822,2.5,4.0,4.0,4.0,2.333333333333333,2.75,3.2,3.5454545454545454,2.8461538461538463,3.3125,2.8,4.0,3.625,4.0,4.0,3.533333333333333,4.0,3.8,3.0,4.0,3.1666666666666665,2.7857142857142856,4.0,2.125,3.0,3.3529411764705883,3.8,2.2857142857142856,2.071428571428572,2.9375,4.0,3.6666666666666665,2.8,2.75,2.7142857142857144,2.9375,1.5714285714285714,3.2142857142857144,3.5,2.6153846153846154,2.5,2.5,4.0,3.066666666666667,3.333333333333333,2.3125,2.25,3.8125,2.6923076923076925,3.4,3.5625,2.8461538461538463,2.642857142857143,2.769230769230769,3.625,3.2,2.9285714285714284,3.333333333333333,2.5,2.6,2.333333333333333,3.0,4.0,3.6666666666666665,3.0,2.8,4.0,0.4,3.2,3.2,2.0,3.75,3.8,2.8461538461538463,4.0,3.75,3.7142857142857135,2.25,3.75,3.25,3.0,2.6,2.5,3.6666666666666665,3.375,2.8,3.230769230769231,3.4375,4.0,2.6666666666666665,2.0,2.6923076923076925,3.4,3.9166666666666665,3.769230769230769,3.4615384615384617,2.833333333333333,3.25,3.4,2.923076923076923,3.0,2.8181818181818183,3.2857142857142856,1.5,4.0,1.5,4.0,0.0,2.5625,2.8,2.25,2.6666666666666665,3.7857142857142856,3.8,3.6666666666666665,0.6,4.0,3.75,3.5,3.2857142857142856,3.2,3.0,3.25,3.583333333333333,3.0,2.923076923076923,2.6666666666666665,3.0,4.0,3.0,3.0,2.5454545454545454,2.823529411764706,2.066666666666667,3.4,3.333333333333333,2.0,3.692307692307693,3.142857142857143,1.5,3.4,2.25,4.0,3.0,4.0,3.4,2.6923076923076925,2.9285714285714284,2.9285714285714284,3.0,2.4,3.2,4.0,3.2,3.0,3.0,3.0,4.0,1.8,2.357142857142857,2.4285714285714284,3.071428571428572,4.0,2.7142857142857144,4.0,3.3125,1.5,3.75,3.375,3.6,3.4,2.5,4.0,3.411764705882353,3.0,3.230769230769231,3.8125,3.5,3.8,4.0,4.0,2.857142857142857,3.75,3.25,2.3529411764705883,3.5,4.0,3.071428571428572,2.4,3.4615384615384617,4.0,3.0,3.2142857142857144,2.6923076923076925,4.0,3.6666666666666665,2.571428571428572,3.642857142857143,2.5,1.3333333333333333,3.75,2.4166666666666665,3.5454545454545454,4.0,2.090909090909091,3.25,4.0,1.25,3.4,4.0,4.0,3.647058823529412,1.2,3.4,3.3076923076923075,3.5,2.75,3.769230769230769,3.6,3.8,2.333333333333333,3.6,3.75,2.6666666666666665,4.0,2.833333333333333,3.25,3.8,2.75,4.0,3.5454545454545454,2.0,4.0,4.0,3.7142857142857135,2.230769230769231,1.5,2.4,1.2,1.125,2.2,1.2307692307692308,1.0,2.75,3.8125,4.0,2.642857142857143,3.6666666666666665,3.2,3.333333333333333,3.909090909090909,3.75,3.75,3.0,3.6,4.0,3.2,3.4,3.1538461538461537,3.0,2.8,3.25,2.6,2.5,2.2,3.2857142857142856,3.0,2.0,4.0,4.0,2.75,0.4615384615384615,3.4,3.25,3.0,4.0,2.0,3.8,2.75,2.0,3.090909090909091,4.0,3.6666666666666665,2.8461538461538463,3.642857142857143,3.8,2.6666666666666665,4.0,3.1875,3.6,2.25,2.75,1.25,4.0,4.0,3.076923076923077,3.0,3.8,3.6,3.5625,1.2307692307692308,2.2,3.333333333333333,2.25,1.375,2.8,3.733333333333333,1.5,4.0,3.466666666666667,2.0,2.5,3.375,3.769230769230769,2.6923076923076925,3.2,2.272727272727273,2.857142857142857,1.5,1.6,3.272727272727273,2.9285714285714284,3.8125,4.0,3.0,2.230769230769231,3.294117647058824,2.6,2.5625,3.375,3.0,4.0,1.5625,2.5,1.0,4.0,0.8888888888888888,4.0,0.5,4.0,4.0,3.0,3.615384615384616,3.0,3.2,3.2,1.8,3.8,3.0,2.8461538461538463,3.5,2.923076923076923,3.75,3.4285714285714284,4.0,3.0,3.75,3.4,3.5625,4.0,3.2,2.076923076923077,2.75,1.8571428571428568,3.2857142857142856,3.272727272727273,2.9166666666666665,3.5454545454545454,3.636363636363636,2.909090909090909,1.9090909090909087,2.0,2.571428571428572,2.2142857142857144,2.6666666666666665,2.8461538461538463,4.0,4.0,4.0,3.0,2.333333333333333,3.75,4.0,4.0,3.0,1.4285714285714286,2.8461538461538463,2.357142857142857,3.6,2.6,1.75,3.0625,4.0,3.8,1.5,2.25,2.3076923076923075,1.6666666666666667,3.769230769230769,2.75,3.5,3.2,4.0,3.0,2.0,3.25,3.4615384615384617,4.0,3.0,4.0,2.5,2.4375,3.625,3.8,2.5,3.6666666666666665,3.0,3.2,3.4615384615384617,0.0,3.4444444444444446,3.2,2.466666666666667,3.8,0.0,4.0,3.5,3.1538461538461537,3.75,4.0,2.0,2.25,3.2,3.6,2.4285714285714284,3.6,4.0,3.0,0.0,4.0,3.6,2.8181818181818183,3.5,2.833333333333333,3.0,3.75,3.4375,3.5384615384615383,4.0,3.466666666666667,4.0,1.3125,4.0,0.2,3.6666666666666665,3.375,1.4,3.5,2.933333333333333,3.090909090909091,2.8,3.0,3.4,3.230769230769231,2.5384615384615383,4.0,3.0,2.0,2.0,3.5454545454545454,3.076923076923077,2.0,4.0,1.5,1.9285714285714288,4.0,3.5384615384615383,3.7142857142857135,3.6,3.857142857142857,3.75,3.0,3.8,2.6,1.2,4.0,1.7,3.5384615384615383,3.0,2.75,3.2,2.9411764705882355,3.8,3.2,4.0,3.6,1.5,3.0625,3.3846153846153846,3.4615384615384617,3.0,3.2,3.5,4.0,3.0,3.769230769230769,2.5625,3.625,3.7142857142857135,1.9,3.6,1.4,2.1538461538461537,3.4,3.0,2.857142857142857,4.0,4.0,2.0,3.5,3.6875,3.75,2.4615384615384617,3.2,3.357142857142857,2.0,2.3846153846153846,3.4166666666666665,4.0,3.8,3.636363636363636,1.9375,2.6,3.8333333333333335,3.1666666666666665,2.2,1.8,4.0,3.363636363636364,3.142857142857143,4.0,3.0,3.5625,3.6,2.0,2.6666666666666665,0.0,2.5,1.5,3.4,2.25,3.6666666666666665,2.142857142857143,3.75,3.375,4.0,3.4,0.0,3.25,2.9375,1.5,3.75,2.647058823529412,3.272727272727273,4.0,3.4,3.25,2.5,4.0,3.0,3.0,2.9,1.6428571428571428,2.1666666666666665,3.2,2.642857142857143,3.5,1.9230769230769231,3.1538461538461537,2.933333333333333,2.636363636363636,0.3846153846153846,2.0,2.333333333333333,3.6666666666666665,4.0,4.0,3.625,2.0,2.5,4.0,2.6666666666666665,2.25,4.0,3.1538461538461537,4.0,2.3846153846153846,2.0,2.9285714285714284,3.8125,3.8125,4.0,3.5,3.8125,1.2307692307692308,1.3333333333333333,3.3529411764705883,3.2142857142857144,3.5384615384615383,4.0,1.8,3.4,1.0,4.0,3.75,1.3333333333333333,2.0,3.75,3.4,2.0,4.0,4.0,4.0,3.142857142857143,3.5,2.6923076923076925,3.0,3.769230769230769,3.5,3.0,3.0,1.9090909090909087,3.3125,3.75,3.0,3.2142857142857144,4.0,2.75,4.0,2.076923076923077,2.0,2.0,3.25,3.333333333333333,3.4,3.647058823529412,3.2666666666666666,3.375,2.4,2.0,3.5,2.75,2.071428571428572,3.5,3.823529411764706,4.0,3.0,3.0,2.4,4.0,2.6923076923076925,3.125,3.0,3.0,2.75,4.0,3.764705882352941,4.0,3.7857142857142856,3.333333333333333,2.8,2.6875,3.2,3.3,3.25,3.066666666666667,4.0,4.0,3.4,3.5384615384615383,3.6666666666666665,3.0,2.333333333333333,3.0,2.4285714285714284,4.0,3.8125,2.083333333333333,4.0,3.0,2.4,3.625,3.8125,2.5,2.0,2.75,4.0,3.769230769230769,0.0,3.8125,2.333333333333333,2.75,4.0,4.0,2.8461538461538463,4.0,2.5,2.2666666666666666,4.0,2.5,2.0,2.75,3.0,3.8461538461538463,4.0,3.5,3.4,2.933333333333333,3.25,4.0,3.25,3.6,3.8,2.4375,0.0,3.4285714285714284,4.0,1.9285714285714288,3.7857142857142856,3.692307692307693,2.7333333333333334,3.5,3.823529411764706,3.769230769230769,3.5,2.0625,3.533333333333333,4.0,3.0,3.6,3.8,0.0,3.333333333333333,2.75,3.4444444444444446,3.25,2.857142857142857,4.0,3.333333333333333,3.4285714285714284,2.8,4.0,3.357142857142857,3.2857142857142856,3.769230769230769,0.8571428571428571,0.6428571428571429,1.6,1.4545454545454546,3.5,2.9411764705882355,2.8,0.6666666666666666,4.0,2.0,2.75,3.2857142857142856,2.4,2.5,3.2,2.75,3.25,4.0,2.909090909090909,4.0,4.0,3.8125,4.0,3.2,2.75,4.0,2.8461538461538463,1.5384615384615383,3.5,3.571428571428572,1.0,4.0,2.2,3.625,3.8,3.363636363636364,4.0,3.3846153846153846,3.6,4.0,4.0,3.5,2.923076923076923,3.25,2.5,4.0,2.6,3.4,3.6,3.4615384615384617,3.8,3.75,3.4,2.0,4.0,4.0,3.0,3.4,3.3076923076923075,3.0,2.8461538461538463,2.5625,2.769230769230769,2.8125,3.5625,2.25,3.5,0.4285714285714285,3.3846153846153846,1.75,3.7857142857142856,2.5,3.0,4.0,3.3076923076923075,2.8,3.4,3.0,2.375,3.066666666666667,3.692307692307693,4.0,3.0,2.7857142857142856,4.0,4.0,3.8,2.272727272727273,2.0,2.4615384615384617,3.25,2.8,3.769230769230769,3.466666666666667,1.75,3.571428571428572,2.6,1.0,3.2,3.071428571428572,2.1538461538461537,1.5,2.6153846153846154,4.0,3.642857142857143,1.1428571428571428,4.0,3.0,4.0,3.6,3.4615384615384617,2.9285714285714284,3.4,4.0,3.466666666666667,3.076923076923077,1.5,2.5,3.4375,2.8125,2.25,0.75,3.4,3.769230769230769,3.75,4.0,2.7142857142857144,2.933333333333333,2.833333333333333,4.0,3.1333333333333333,3.25,2.5,2.75,2.375,3.2,3.0,3.0,3.75,2.8666666666666667,2.583333333333333,3.642857142857143,2.6923076923076925,3.0,2.7142857142857144,2.466666666666667,2.5,3.4,2.6923076923076925,2.375,2.2,2.076923076923077,4.0,2.0,3.333333333333333,3.25,2.923076923076923,2.5,3.4615384615384617,4.0,4.0,1.0,4.0,3.25,3.25,3.357142857142857,3.75,2.4545454545454546,3.571428571428572,3.0,3.25,3.0625,2.5,2.9,3.2,3.8333333333333335,3.076923076923077,3.769230769230769,4.0,3.6,2.6666666666666665],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>GPA_2=%{x}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"notched\":false,\"offsetgroup\":\"1\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[3.333333333333333,0.0,1.0,1.3333333333333333,0.0,0.5,0.0,0.6,1.4,0.75,0.0,3.0,3.571428571428572,0.2666666666666666,1.5,2.333333333333333,1.0,2.6875,3.3846153846153846,0.4615384615384615,0.0,0.0,1.5,3.0,2.363636363636364,4.0,2.75,0.0,0.0,1.2857142857142858,2.727272727272727,1.3333333333333333,1.5,3.5,3.333333333333333,0.0,1.0,0.0,0.0,3.5384615384615383,0.0,3.0,1.8,2.8125,1.0,1.25,0.2222222222222222,0.0,3.230769230769231,3.5384615384615383,0.0,1.2,0.625,1.3333333333333333,0.0,0.0,2.8,0.0,1.1538461538461535,0.25,0.0,0.6,1.0833333333333333,1.0,1.5,1.0,0.25,4.0,1.0,0.25,4.0,0.2857142857142857,0.75,0.9,2.5,2.7,3.5,3.0,0.0,1.8,3.5,3.5,3.0,2.071428571428572,0.0,0.75,0.0,1.0,2.0,2.0,0.3076923076923077,2.9375,1.2857142857142858,4.0,3.6,0.4,0.0,0.4,1.0,0.0,1.5,2.6666666666666665,3.6666666666666665,1.375,0.0,0.0,4.0,0.0,0.0,0.0,0.5,4.0,2.5,0.3,0.0,4.0,0.2,0.0,3.5,3.8,0.4,1.6666666666666667,0.0,0.3333333333333333,1.75,0.0,1.3333333333333333,3.176470588235294,2.333333333333333,2.0,0.0,3.0,1.0,2.5,0.0,0.75,0.375,3.6666666666666665,0.75,0.1538461538461538,1.5,0.0,2.0,3.235294117647059,0.0,2.5,2.8666666666666667,1.7,1.1,0.0,3.5,2.4,0.0,4.0,2.25,3.769230769230769,2.6,4.0,0.2,1.3333333333333333,3.142857142857143,0.0,2.5,1.3333333333333333,0.0,1.0,1.4285714285714286,2.7142857142857144,0.6666666666666666,0.25,1.5,4.0,2.75,2.5,0.9375,0.0,0.0,3.2,3.2,0.0,0.1428571428571428,0.0,2.75,0.0,1.6666666666666667,3.25,3.5,3.0,1.25,0.0,0.5,0.0,2.25,1.0,1.6,0.0,2.923076923076923,0.8571428571428571,4.0,0.75,3.0,2.4285714285714284,3.25,0.6666666666666666,2.1666666666666665,0.0,1.0,2.4615384615384617,3.75,4.0,0.0,0.4,2.6,0.8,1.0,1.0,2.4375,1.375,2.0,3.764705882352941,2.0,0.0,3.111111111111111,3.6666666666666665,3.5,2.8461538461538463,1.3333333333333333,0.75,0.0,0.0,0.0,1.0,1.25,2.75,2.0,1.3333333333333333,3.363636363636364,0.0,0.0,3.25,2.0,0.8888888888888888,0.8181818181818182,1.5,3.25,2.6,3.235294117647059,0.0,1.5,4.0,0.0,1.5,0.2142857142857142,0.75,3.071428571428572,0.5,0.0,3.1538461538461537,0.375,2.076923076923077,0.0,3.125,4.0,0.1875,0.6,3.25,3.230769230769231,4.0,0.2222222222222222,3.125,1.0,0.0,2.8,2.333333333333333,0.0,0.0,1.1111111111111112,2.0625,0.25,0.0,3.0,0.0,4.0,0.4,0.0,2.571428571428572,0.1333333333333333,3.769230769230769,0.0,3.0,1.0,2.0,0.0,4.0,0.8,4.0,1.5,4.0,3.75,1.9375,3.333333333333333,1.0,3.5,2.5454545454545454,2.0,3.6,2.5,0.0,3.0,0.3,3.333333333333333,0.0,0.0,0.0,0.0,1.25,1.5,3.4,0.5,2.2857142857142856,0.0,0.0,0.0,3.2,0.4615384615384615,0.3846153846153846,2.0,3.071428571428572,4.0,1.3333333333333333,2.8181818181818183,2.588235294117647,2.0,0.6,1.5714285714285714,1.6666666666666667,0.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"GPA_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"SEM_3_STATUS\"},\"categoryorder\":\"array\",\"categoryarray\":[1,0]},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(Xy_build_c, x='GPA_2', y='SEM_3_STATUS', color='SEM_3_STATUS', boxmode=\"overlay\")\n",
    "fig.update_layout(boxmode='group')  # To group the box plots by category\n",
    "fig.update_traces(orientation='h') # horizontal box plots\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50bec602-eee6-4b20-8438-878bd3605e09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next compare semester 2 units completed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34a1616a-c8ee-4fad-a7af-852de0538657",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"6b08582f-b83b-4f4f-8b3b-4f1e40252259\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b08582f-b83b-4f4f-8b3b-4f1e40252259\")) {                    Plotly.newPlot(                        \"6b08582f-b83b-4f4f-8b3b-4f1e40252259\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>UNITS_COMPLETED_2=%{x}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"notched\":false,\"offsetgroup\":\"0\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[4.0,16.0,6.0,9.0,10.0,12.0,10.0,13.0,12.0,17.0,9.0,9.0,11.0,10.0,13.0,12.0,12.0,17.0,15.0,9.0,15.0,13.0,9.0,11.0,11.0,12.0,13.0,12.0,15.0,9.0,16.0,8.0,3.0,15.0,15.0,12.0,15.0,16.0,13.0,15.0,13.0,12.0,12.0,6.0,15.0,16.0,15.0,15.0,14.0,16.0,14.0,12.0,10.0,14.0,12.0,15.0,13.0,15.0,15.0,12.0,15.0,15.0,13.0,12.0,12.0,15.0,12.0,6.0,13.0,12.0,12.0,15.0,12.0,13.0,5.0,6.0,14.0,14.0,15.0,6.0,12.0,15.0,14.0,13.0,15.0,16.0,13.0,5.0,15.0,1.0,15.0,7.0,12.0,16.0,9.0,9.0,9.0,16.0,14.0,12.0,13.0,12.0,16.0,12.0,12.0,13.0,11.0,15.0,15.0,15.0,9.0,12.0,11.0,19.0,9.0,12.0,9.0,7.0,15.0,16.0,15.0,11.0,9.0,15.0,16.0,16.0,6.0,17.0,12.0,15.0,12.0,13.0,9.0,6.0,16.0,15.0,16.0,9.0,13.0,3.0,12.0,12.0,13.0,11.0,15.0,13.0,12.0,10.0,6.0,12.0,17.0,6.0,15.0,15.0,10.0,13.0,9.0,12.0,15.0,13.0,15.0,15.0,14.0,13.0,16.0,13.0,15.0,18.0,16.0,1.0,12.0,13.0,15.0,4.0,9.0,13.0,12.0,12.0,15.0,16.0,15.0,9.0,15.0,12.0,10.0,15.0,15.0,13.0,0.0,9.0,3.0,9.0,12.0,12.0,9.0,16.0,9.0,12.0,15.0,16.0,12.0,15.0,7.0,13.0,12.0,12.0,13.0,13.0,13.0,13.0,16.0,15.0,15.0,3.0,12.0,15.0,11.0,12.0,15.0,13.0,14.0,14.0,9.0,14.0,11.0,5.0,6.0,15.0,15.0,13.0,9.0,9.0,14.0,12.0,15.0,13.0,11.0,11.0,12.0,13.0,12.0,14.0,12.0,0.0,13.0,15.0,15.0,17.0,16.0,15.0,13.0,12.0,11.0,13.0,12.0,15.0,9.0,9.0,15.0,13.0,16.0,14.0,15.0,13.0,13.0,12.0,12.0,15.0,0.0,8.0,9.0,9.0,12.0,14.0,12.0,12.0,13.0,16.0,9.0,13.0,15.0,15.0,9.0,16.0,9.0,18.0,13.0,16.0,9.0,10.0,17.0,15.0,6.0,15.0,13.0,12.0,13.0,8.0,0.0,16.0,10.0,13.0,13.0,9.0,12.0,15.0,3.0,12.0,12.0,15.0,12.0,0.0,8.0,13.0,13.0,13.0,13.0,15.0,11.0,15.0,15.0,14.0,12.0,15.0,12.0,16.0,6.0,15.0,12.0,15.0,12.0,17.0,12.0,13.0,6.0,14.0,16.0,12.0,16.0,15.0,14.0,15.0,9.0,11.0,6.0,11.0,9.0,6.0,15.0,13.0,15.0,12.0,14.0,15.0,9.0,15.0,12.0,15.0,7.0,10.0,12.0,14.0,15.0,12.0,15.0,0.0,11.0,16.0,14.0,12.0,13.0,12.0,3.0,12.0,15.0,12.0,16.0,13.0,13.0,6.0,15.0,16.0,12.0,0.0,12.0,15.0,16.0,13.0,12.0,16.0,14.0,15.0,15.0,15.0,15.0,12.0,9.0,13.0,6.0,15.0,16.0,9.0,14.0,15.0,12.0,12.0,13.0,15.0,12.0,18.0,15.0,12.0,13.0,12.0,9.0,11.0,15.0,13.0,11.0,16.0,13.0,13.0,16.0,0.0,13.0,11.0,16.0,14.0,15.0,13.0,12.0,16.0,6.0,12.0,14.0,12.0,14.0,12.0,16.0,9.0,13.0,15.0,12.0,12.0,6.0,13.0,13.0,15.0,13.0,11.0,6.0,12.0,3.0,15.0,6.0,11.0,16.0,15.0,18.0,13.0,6.0,12.0,9.0,12.0,12.0,15.0,6.0,15.0,12.0,11.0,15.0,16.0,13.0,15.0,14.0,12.0,16.0,16.0,6.0,15.0,11.0,7.0,3.0,13.0,15.0,15.0,16.0,12.0,12.0,12.0,14.0,15.0,15.0,11.0,13.0,12.0,8.0,12.0,15.0,11.0,15.0,15.0,9.0,13.0,12.0,9.0,15.0,15.0,13.0,15.0,13.0,12.0,15.0,6.0,15.0,16.0,12.0,12.0,12.0,15.0,14.0,12.0,15.0,8.0,15.0,13.0,9.0,12.0,12.0,15.0,12.0,15.0,6.0,5.0,15.0,15.0,18.0,10.0,14.0,17.0,13.0,0.0,15.0,6.0,15.0,10.0,0.0,11.0,5.0,13.0,16.0,15.0,13.0,15.0,16.0,9.0,13.0,3.0,12.0,16.0,14.0,15.0,6.0,16.0,15.0,15.0,8.0,9.0,7.0,16.0,13.0,3.0,13.0,5.0,12.0,12.0,12.0,12.0,15.0,13.0,13.0,12.0,9.0,15.0,15.0,3.0,3.0,13.0,12.0,12.0,13.0,15.0,13.0,9.0,6.0,13.0,9.0,15.0,9.0,15.0,13.0,15.0,3.0,12.0,3.0,13.0,15.0,12.0,15.0,12.0,9.0,15.0,14.0,11.0,15.0,14.0,3.0,6.0,14.0,12.0,15.0,15.0,15.0,15.0,18.0,15.0,11.0,13.0,12.0,12.0,15.0,12.0,6.0,15.0,12.0,12.0,15.0,15.0,15.0,12.0,15.0,0.0,15.0,3.0,15.0,17.0,3.0,12.0,16.0,12.0,11.0,15.0,18.0,12.0,7.0,16.0,15.0,16.0,9.0,6.0,9.0,6.0,3.0,16.0,12.0,12.0,13.0,0.0,16.0,13.0,13.0,13.0,6.0,9.0,12.0,12.0,15.0,13.0,5.0,15.0,16.0,12.0,15.0,15.0,12.0,12.0,12.0,16.0,15.0,9.0,12.0,15.0,12.0,15.0,0.0,15.0,7.0,13.0,12.0,15.0,9.0,16.0,13.0,16.0,6.0,16.0,15.0,11.0,9.0,16.0,15.0,14.0,9.0,14.0,9.0,9.0,13.0,17.0,15.0,12.0,3.0,12.0,18.0,13.0,13.0,13.0,9.0,12.0,15.0,12.0,18.0,15.0,15.0,15.0,14.0,12.0,13.0,15.0,8.0,9.0,16.0,15.0,9.0,16.0,6.0,13.0,12.0,15.0,15.0,16.0,13.0,15.0,15.0,16.0,15.0,12.0,6.0,12.0,15.0,11.0,15.0,12.0,17.0,12.0,13.0,9.0,12.0,12.0,8.0,15.0,16.0,15.0,12.0,12.0,14.0,13.0,15.0,16.0,12.0,12.0,14.0,14.0,15.0,10.0,14.0,3.0,9.0,14.0,15.0,13.0,11.0,12.0,15.0,14.0,15.0,9.0,7.0,12.0,16.0,18.0,14.0,13.0,12.0,9.0,15.0,15.0,12.0,9.0,14.0,12.0,16.0,13.0,10.0,14.0,16.0,12.0,15.0,12.0,15.0,15.0,15.0,12.0,16.0,16.0,15.0,16.0,14.0,4.0,9.0,15.0,12.0,6.0,14.0,12.0,15.0,14.0,13.0,13.0,12.0,12.0,14.0,9.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,13.0,0.0,12.0,16.0,12.0,12.0,10.0,15.0,3.0,6.0,6.0,6.0,9.0,15.0,12.0,15.0,0.0,15.0,8.0,12.0,13.0,0.0,12.0,14.0,13.0,15.0,15.0,12.0,12.0,12.0,15.0,17.0,12.0,15.0,9.0,12.0,12.0,6.0,12.0,12.0,16.0,6.0,14.0,15.0,16.0,15.0,6.0,13.0,11.0,14.0,9.0,15.0,15.0,6.0,14.0,11.0,8.0,15.0,6.0,15.0,12.0,12.0,12.0,13.0,10.0,12.0,15.0,15.0,11.0,12.0,15.0,15.0,12.0,15.0,15.0,15.0,14.0,13.0,4.0,9.0,9.0,9.0,16.0,15.0,16.0,5.0,12.0,16.0,12.0,16.0,14.0,12.0,13.0,13.0,12.0,10.0,12.0,12.0,17.0,17.0,12.0,12.0,15.0,14.0,12.0,17.0,12.0,12.0,6.0,12.0,10.0,16.0,15.0,10.0,11.0,16.0,15.0,1.0,16.0,16.0,9.0,10.0,12.0,10.0,0.0,15.0,12.0,14.0,13.0,16.0,13.0,13.0,11.0,14.0,13.0,13.0,11.0,12.0,16.0,12.0,9.0,12.0,12.0,7.0,13.0,16.0,9.0,14.0,12.0,9.0,0.0,10.0,16.0,14.0,11.0,9.0,14.0,9.0,15.0,15.0,16.0,13.0,12.0,12.0,15.0,13.0,6.0,6.0,13.0,13.0,11.0,13.0,17.0,10.0,9.0,11.0,16.0,18.0,15.0,12.0,14.0,12.0,4.0,13.0,15.0,16.0,9.0,15.0,11.0,11.0,10.0,13.0,15.0,13.0,9.0,14.0,14.0,16.0,12.0,13.0,16.0,15.0,3.0,14.0,12.0,14.0,15.0,13.0,3.0,13.0,15.0,16.0,15.0,12.0,16.0,9.0,9.0,15.0,15.0,17.0,13.0,13.0,16.0,13.0,12.0,7.0,9.0,13.0,15.0,6.0,12.0,13.0,9.0,0.0,15.0,9.0,13.0,12.0,11.0,12.0,11.0,14.0,15.0,16.0,15.0,11.0,15.0,10.0,16.0,17.0,13.0,18.0,13.0,9.0,9.0,12.0,14.0,13.0,15.0,12.0,16.0,10.0,12.0,12.0,15.0,12.0,9.0,16.0,16.0,15.0,15.0,15.0,13.0,7.0,15.0,15.0,15.0,10.0,11.0,10.0,9.0,9.0,12.0,12.0,14.0,3.0,13.0,3.0,15.0,11.0,12.0,9.0,16.0,9.0,3.0,15.0,14.0,12.0,15.0,15.0,13.0,14.0,13.0,15.0,13.0,15.0,15.0,10.0,4.0,12.0,15.0,15.0,1.0,12.0,9.0,12.0,14.0,15.0,16.0,15.0,18.0,16.0,3.0,12.0,7.0,12.0,15.0,15.0,12.0,16.0,7.0,14.0,9.0,15.0,12.0,15.0,15.0,15.0,15.0,11.0,13.0,13.0,12.0,15.0,9.0,12.0,16.0,16.0,16.0,16.0,15.0,6.0,9.0,16.0,15.0,15.0,12.0,14.0,15.0,13.0,13.0,12.0,15.0,13.0,11.0,14.0,15.0,15.0,16.0,15.0,13.0,6.0,13.0,16.0,9.0,12.0,9.0,13.0,12.0,14.0,14.0,15.0,15.0,15.0,3.0,18.0,13.0,12.0,7.0,2.0,13.0,18.0,16.0,17.0,12.0,9.0,15.0,13.0,15.0,6.0,13.0,16.0,16.0,13.0,16.0,11.0,6.0,12.0,12.0,15.0,9.0,5.0,11.0,12.0,16.0,13.0,13.0,12.0,9.0,12.0,15.0,15.0,14.0,6.0,16.0,14.0,3.0,18.0,7.0,12.0,12.0,15.0,15.0,14.0,1.0,11.0,12.0,18.0,16.0,7.0,13.0,12.0,13.0,12.0,16.0,14.0,15.0,12.0,9.0,15.0,15.0,10.0,9.0,15.0,16.0,16.0,15.0,12.0,9.0,12.0,13.0,13.0,11.0,13.0,15.0,15.0,16.0,15.0,13.0,16.0,12.0,15.0,0.0,0.0,12.0,12.0,15.0,13.0,15.0,9.0,3.0,4.0,7.0,12.0,16.0,15.0,16.0,15.0,12.0,17.0,12.0,11.0,11.0,0.0,12.0,14.0,1.0,15.0,12.0,15.0,9.0,15.0,13.0,15.0,9.0,12.0,9.0,15.0,12.0,12.0,15.0,9.0,15.0,12.0,12.0,15.0,14.0,13.0,12.0,16.0,16.0,13.0,12.0,12.0,15.0,8.0,10.0,13.0,15.0,9.0,9.0,15.0,15.0,7.0,13.0,16.0,15.0,15.0,14.0,12.0,16.0,13.0,5.0,12.0,12.0,16.0,12.0,11.0,15.0,11.0,11.0,15.0,12.0,14.0,12.0,9.0,15.0,16.0,12.0,16.0,11.0,3.0,12.0,17.0,15.0,15.0,13.0,12.0,12.0,12.0,16.0,13.0,15.0,13.0,12.0,11.0,11.0,12.0,15.0,13.0,13.0,6.0,9.0,16.0,16.0,14.0,15.0,14.0,9.0,13.0,11.0,15.0,16.0,15.0,15.0,12.0,6.0,15.0,13.0,12.0,9.0,15.0,7.0,13.0,11.0,15.0,12.0,11.0,12.0,14.0,13.0,17.0,15.0,6.0,12.0,16.0,15.0,7.0,9.0,14.0,15.0,16.0,9.0,16.0,13.0,14.0,16.0,11.0,6.0,12.0,16.0,9.0,12.0,13.0,15.0,15.0,13.0,14.0,9.0,15.0,16.0,15.0,12.0,15.0,15.0,16.0,17.0,16.0,15.0,14.0,12.0,15.0,14.0,11.0,12.0,15.0,15.0,15.0,9.0,14.0,15.0,12.0,8.0,16.0,15.0,15.0,14.0,6.0,9.0,15.0,12.0,13.0,3.0,12.0,0.0,15.0,11.0,12.0,14.0,14.0,15.0,6.0,15.0,16.0,16.0,12.0,16.0,15.0,15.0,15.0,14.0,12.0,11.0,12.0,7.0,15.0,15.0,16.0,15.0,12.0,15.0,11.0,9.0,16.0,9.0,12.0,12.0,9.0,12.0,15.0,14.0,15.0,16.0,12.0,14.0,9.0,15.0,13.0,10.0,16.0,15.0,7.0,12.0,11.0,9.0,13.0,15.0,15.0,15.0,15.0,9.0,12.0,12.0,19.0,14.0,18.0,15.0,12.0,12.0,13.0,12.0,16.0,16.0,13.0,15.0,13.0,7.0,9.0,12.0,6.0,12.0,10.0,16.0,16.0,18.0,10.0,15.0,12.0,12.0,15.0,15.0,6.0,18.0,13.0,16.0,16.0,16.0,13.0,11.0,9.0,15.0,15.0,3.0,6.0,12.0,13.0,16.0,12.0,12.0,12.0,13.0,12.0,14.0,13.0,9.0,16.0,12.0,15.0,11.0,12.0,12.0,6.0,9.0,16.0,14.0,15.0,13.0,12.0,9.0,7.0,14.0,15.0,13.0,12.0,16.0,16.0,16.0,15.0,15.0,15.0,12.0,7.0,13.0,12.0,15.0,11.0,16.0,15.0,10.0,13.0,6.0,16.0,17.0,12.0,6.0,17.0,12.0,10.0,15.0,15.0,3.0,16.0,8.0,9.0,7.0,15.0,12.0,16.0,11.0,16.0,9.0,14.0,15.0,12.0,15.0,0.0,16.0,15.0,6.0,12.0,14.0,5.0,13.0,15.0,12.0,12.0,15.0,15.0,16.0,13.0,14.0,3.0,15.0,14.0,13.0,13.0,11.0,15.0,12.0,12.0,15.0,13.0,15.0,12.0,16.0,9.0,16.0,5.0,16.0,16.0,12.0,15.0,15.0,12.0,15.0,13.0,16.0,11.0,13.0,6.0,9.0,9.0,15.0,12.0,9.0,15.0,11.0,14.0,16.0,0.0,15.0,12.0,6.0,18.0,12.0,14.0,4.0,13.0,12.0,16.0,6.0,12.0,4.0,15.0,14.0,15.0,13.0,15.0,9.0,15.0,11.0,12.0,13.0,9.0,11.0,13.0,9.0,15.0,12.0,12.0,15.0,15.0,16.0,16.0,16.0,19.0,15.0,9.0,3.0,14.0,16.0,8.0,7.0,16.0,11.0,15.0,11.0,9.0,13.0,6.0,15.0,12.0,10.0,15.0,5.0,13.0,16.0,5.0,12.0,9.0,12.0,12.0,12.0,13.0,16.0,13.0,16.0,3.0,12.0,13.0,7.0,6.0,15.0,3.0,15.0,6.0,15.0,14.0,15.0,9.0,9.0,15.0,12.0,8.0,15.0,13.0,11.0,9.0,16.0,12.0,9.0,12.0,12.0,13.0,15.0,11.0,4.0,15.0,15.0,15.0,3.0,15.0,12.0,12.0,14.0,11.0,12.0,14.0,11.0,15.0,15.0,15.0,15.0,14.0,9.0,12.0,15.0,11.0,15.0,6.0,12.0,6.0,7.0,13.0,12.0,16.0,9.0,11.0,3.0,16.0,13.0,6.0,15.0,15.0,9.0,6.0,15.0,15.0,15.0,3.0,15.0,9.0,11.0,11.0,15.0,15.0,16.0,15.0,16.0,16.0,12.0,16.0,12.0,12.0,4.0,16.0,8.0,7.0,8.0,16.0,15.0,3.0,12.0,6.0,15.0,15.0,12.0,15.0,13.0,16.0,12.0,17.0,12.0,14.0,11.0,15.0,13.0,5.0,15.0,12.0,8.0,3.0,9.0,9.0,15.0,14.0,14.0,15.0,9.0,14.0,14.0,9.0,13.0,10.0,14.0,6.0,15.0,14.0,14.0,12.0,9.0,14.0,13.0,4.0,12.0,7.0,16.0,15.0,14.0,17.0,16.0,12.0,16.0,11.0,6.0,12.0,15.0,18.0,12.0,9.0,12.0,13.0,16.0,8.0,11.0,12.0,15.0,12.0,15.0,12.0,6.0,12.0,15.0,15.0,12.0,15.0,15.0,12.0,15.0,9.0,13.0,16.0,16.0,12.0,13.0,16.0,9.0,12.0,12.0,15.0,12.0,12.0,13.0,12.0,16.0,7.0,12.0,12.0,9.0,12.0,15.0,12.0,13.0,9.0,16.0,16.0,16.0,16.0,15.0,12.0,15.0,9.0,12.0,13.0,15.0,15.0,6.0,6.0,16.0,12.0,14.0,15.0,6.0,12.0,15.0,15.0,15.0,13.0,15.0,3.0,9.0,13.0,15.0,15.0,15.0,15.0,17.0,13.0,16.0,10.0,15.0,12.0,15.0,12.0,15.0,15.0,12.0,12.0,17.0,16.0,15.0,15.0,17.0,12.0,7.0,16.0,12.0,13.0,9.0,13.0,10.0,12.0,13.0,3.0,12.0,12.0,15.0,13.0,12.0,12.0,12.0,14.0,14.0,6.0,11.0,11.0,16.0,15.0,12.0,13.0,16.0,6.0,12.0,12.0,12.0,16.0,17.0,13.0,12.0,13.0,12.0,15.0,15.0,17.0,13.0,12.0,13.0,10.0,12.0,2.0,6.0,12.0,12.0,7.0,12.0,8.0,16.0,18.0,15.0,12.0,12.0,15.0,13.0,12.0,15.0,15.0,11.0,3.0,12.0,15.0,15.0,12.0,3.0,10.0,15.0,7.0,13.0,6.0,12.0,11.0,16.0,6.0,12.0,13.0,15.0,9.0,12.0,10.0,16.0,10.0,15.0,13.0,11.0,12.0,12.0,14.0,15.0,16.0,13.0,13.0,12.0,0.0,9.0,16.0,15.0,17.0,6.0,14.0,15.0,14.0,9.0,12.0,6.0,12.0,13.0,9.0,12.0,15.0,11.0,11.0,12.0,9.0,16.0,11.0,11.0,17.0,13.0,15.0,15.0,14.0,6.0,8.0,14.0,16.0,9.0,16.0,3.0,15.0,15.0,14.0,16.0,9.0,11.0,13.0,3.0,12.0,12.0,14.0,13.0,15.0,10.0,9.0,9.0,9.0,4.0,15.0,9.0,16.0,6.0,15.0,14.0,15.0,12.0,12.0,12.0,13.0,12.0,15.0,12.0,13.0,9.0,15.0,14.0,15.0,7.0,6.0,14.0,12.0,11.0,15.0,11.0,6.0,9.0,15.0,14.0,15.0,13.0,13.0,13.0,15.0,17.0,3.0,16.0,13.0,9.0,13.0,13.0,12.0,1.0,9.0,10.0,16.0,6.0,12.0,9.0,17.0,15.0,9.0,16.0,12.0,15.0,12.0,11.0,14.0,15.0,16.0,0.0,12.0,12.0,13.0,12.0,13.0,15.0,13.0,9.0,1.0,3.0,12.0,14.0,14.0,16.0,15.0,15.0,13.0,15.0,15.0,15.0,9.0,14.0,5.0,17.0,4.0,15.0,16.0,17.0,9.0,13.0,15.0,11.0,13.0,16.0,15.0,15.0,16.0,15.0,16.0,15.0,15.0,15.0,13.0,14.0,12.0,14.0,13.0,12.0,15.0,17.0,15.0,10.0,7.0,16.0,15.0,9.0,15.0,16.0,11.0,16.0,8.0,14.0,12.0,9.0,12.0,16.0,15.0,15.0,12.0,12.0,9.0,16.0,13.0,15.0,16.0,13.0,14.0,10.0,16.0,12.0,14.0,12.0,12.0,12.0,6.0,15.0,16.0,18.0,12.0,15.0,13.0,0.0,15.0,15.0,15.0,16.0,15.0,8.0,7.0,12.0,14.0,12.0,12.0,12.0,9.0,15.0,6.0,12.0,16.0,15.0,13.0,16.0,15.0,9.0,12.0,13.0,15.0,12.0,13.0,13.0,6.0,12.0,15.0,13.0,9.0,11.0,14.0,9.0,12.0,6.0,15.0,0.0,13.0,15.0,12.0,6.0,14.0,15.0,15.0,3.0,11.0,12.0,12.0,14.0,15.0,15.0,12.0,12.0,12.0,13.0,9.0,15.0,11.0,12.0,15.0,11.0,14.0,12.0,15.0,9.0,9.0,13.0,14.0,9.0,15.0,12.0,16.0,12.0,13.0,15.0,13.0,14.0,14.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,9.0,16.0,9.0,11.0,14.0,14.0,13.0,14.0,18.0,16.0,6.0,16.0,16.0,15.0,15.0,9.0,12.0,17.0,12.0,13.0,16.0,12.0,15.0,9.0,12.0,14.0,12.0,12.0,17.0,12.0,12.0,14.0,15.0,13.0,3.0,15.0,14.0,13.0,12.0,12.0,9.0,14.0,12.0,6.0,12.0,12.0,11.0,15.0,6.0,12.0,12.0,3.0,15.0,12.0,16.0,17.0,6.0,15.0,13.0,6.0,12.0,13.0,15.0,15.0,6.0,15.0,12.0,9.0,12.0,12.0,12.0,15.0,12.0,16.0,11.0,9.0,14.0,11.0,14.0,13.0,9.0,15.0,6.0,6.0,9.0,3.0,3.0,9.0,16.0,12.0,14.0,12.0,10.0,9.0,11.0,12.0,12.0,9.0,15.0,15.0,15.0,15.0,13.0,12.0,15.0,12.0,15.0,6.0,10.0,14.0,12.0,6.0,15.0,17.0,12.0,3.0,15.0,12.0,12.0,16.0,6.0,15.0,12.0,9.0,11.0,6.0,9.0,13.0,14.0,15.0,6.0,15.0,16.0,15.0,9.0,12.0,6.0,15.0,15.0,13.0,12.0,15.0,15.0,16.0,4.0,12.0,15.0,9.0,7.0,15.0,15.0,3.0,14.0,15.0,2.0,9.0,8.0,13.0,13.0,15.0,10.0,11.0,9.0,6.0,11.0,14.0,16.0,7.0,12.0,13.0,17.0,15.0,16.0,16.0,9.0,12.0,8.0,12.0,0.0,16.0,4.0,14.0,0.0,12.0,13.0,15.0,13.0,12.0,15.0,15.0,9.0,15.0,12.0,13.0,12.0,13.0,12.0,14.0,11.0,9.0,12.0,15.0,16.0,12.0,15.0,10.0,12.0,11.0,7.0,11.0,12.0,11.0,11.0,11.0,6.0,9.0,14.0,9.0,9.0,13.0,11.0,13.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,3.0,10.0,14.0,15.0,15.0,9.0,16.0,11.0,15.0,6.0,12.0,13.0,6.0,13.0,8.0,12.0,15.0,11.0,12.0,6.0,12.0,13.0,15.0,13.0,15.0,6.0,16.0,16.0,15.0,6.0,9.0,9.0,15.0,13.0,0.0,9.0,15.0,15.0,15.0,0.0,10.0,12.0,13.0,12.0,13.0,13.0,9.0,15.0,15.0,11.0,15.0,15.0,9.0,0.0,15.0,15.0,11.0,12.0,18.0,6.0,12.0,16.0,13.0,15.0,15.0,13.0,9.0,15.0,0.0,15.0,16.0,6.0,12.0,15.0,11.0,15.0,12.0,15.0,13.0,9.0,15.0,12.0,14.0,6.0,11.0,13.0,6.0,15.0,6.0,10.0,15.0,13.0,14.0,15.0,14.0,12.0,13.0,15.0,15.0,6.0,13.0,7.0,13.0,12.0,12.0,15.0,13.0,15.0,12.0,9.0,15.0,6.0,16.0,13.0,13.0,15.0,15.0,14.0,12.0,12.0,13.0,16.0,8.0,14.0,7.0,15.0,7.0,10.0,15.0,13.0,14.0,15.0,15.0,10.0,12.0,16.0,16.0,13.0,15.0,14.0,12.0,9.0,12.0,14.0,15.0,11.0,12.0,15.0,18.0,12.0,12.0,9.0,11.0,11.0,7.0,15.0,12.0,16.0,15.0,10.0,9.0,0.0,12.0,8.0,10.0,12.0,15.0,13.0,12.0,16.0,13.0,15.0,0.0,12.0,16.0,6.0,16.0,13.0,11.0,15.0,15.0,16.0,16.0,12.0,3.0,12.0,10.0,4.0,12.0,15.0,14.0,12.0,7.0,13.0,12.0,8.0,0.0,10.0,15.0,15.0,12.0,12.0,16.0,9.0,3.0,12.0,6.0,9.0,13.0,13.0,15.0,9.0,6.0,14.0,16.0,16.0,13.0,12.0,16.0,5.0,3.0,17.0,14.0,13.0,16.0,9.0,15.0,3.0,15.0,12.0,7.0,13.0,12.0,15.0,17.0,11.0,12.0,15.0,14.0,12.0,13.0,11.0,13.0,6.0,9.0,9.0,8.0,16.0,16.0,13.0,14.0,3.0,9.0,11.0,10.0,10.0,9.0,12.0,9.0,15.0,17.0,15.0,16.0,12.0,9.0,12.0,12.0,11.0,12.0,17.0,15.0,15.0,12.0,15.0,11.0,13.0,16.0,11.0,15.0,16.0,16.0,17.0,18.0,14.0,15.0,15.0,12.0,15.0,10.0,12.0,15.0,9.0,11.0,15.0,13.0,9.0,13.0,6.0,12.0,14.0,15.0,16.0,5.0,3.0,13.0,9.0,16.0,16.0,9.0,6.0,9.0,13.0,13.0,0.0,16.0,9.0,12.0,15.0,11.0,13.0,9.0,12.0,11.0,6.0,13.0,7.0,12.0,15.0,13.0,12.0,12.0,15.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,0.0,14.0,15.0,9.0,14.0,13.0,11.0,12.0,17.0,13.0,12.0,10.0,15.0,10.0,13.0,15.0,15.0,0.0,15.0,12.0,9.0,12.0,14.0,9.0,9.0,14.0,7.0,13.0,14.0,14.0,13.0,6.0,3.0,9.0,5.0,12.0,17.0,15.0,3.0,17.0,9.0,12.0,14.0,15.0,12.0,15.0,12.0,12.0,14.0,11.0,9.0,11.0,16.0,11.0,15.0,12.0,14.0,13.0,5.0,12.0,14.0,3.0,16.0,15.0,16.0,15.0,11.0,12.0,13.0,15.0,13.0,13.0,12.0,13.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,7.0,13.0,11.0,15.0,10.0,13.0,12.0,9.0,16.0,10.0,16.0,16.0,7.0,12.0,3.0,13.0,6.0,14.0,12.0,6.0,16.0,13.0,15.0,15.0,18.0,13.0,15.0,13.0,12.0,15.0,14.0,15.0,13.0,15.0,7.0,9.0,13.0,12.0,15.0,13.0,15.0,9.0,14.0,10.0,6.0,15.0,14.0,9.0,3.0,13.0,16.0,14.0,4.0,14.0,12.0,12.0,15.0,13.0,14.0,15.0,15.0,15.0,12.0,3.0,3.0,16.0,16.0,12.0,3.0,15.0,13.0,12.0,14.0,14.0,15.0,18.0,12.0,15.0,12.0,12.0,12.0,13.0,15.0,12.0,12.0,12.0,15.0,12.0,14.0,13.0,9.0,4.0,15.0,10.0,15.0,13.0,13.0,12.0,7.0,11.0,6.0,9.0,12.0,13.0,8.0,13.0,15.0,12.0,3.0,12.0,12.0,12.0,14.0,12.0,7.0,7.0,12.0,12.0,16.0,9.0,10.0,15.0,18.0,10.0,13.0,13.0,15.0,9.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>UNITS_COMPLETED_2=%{x}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"notched\":false,\"offsetgroup\":\"1\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[18.0,0.0,3.0,6.0,0.0,3.0,0.0,3.0,6.0,3.0,0.0,6.0,14.0,0.0,6.0,9.0,4.0,13.0,13.0,3.0,0.0,0.0,6.0,6.0,6.0,12.0,12.0,0.0,0.0,7.0,11.0,6.0,3.0,12.0,9.0,0.0,3.0,0.0,0.0,13.0,0.0,3.0,9.0,16.0,3.0,6.0,0.0,0.0,13.0,13.0,0.0,3.0,2.0,6.0,0.0,0.0,15.0,0.0,6.0,0.0,0.0,3.0,4.0,0.0,9.0,3.0,0.0,1.0,3.0,0.0,13.0,1.0,3.0,4.0,9.0,10.0,12.0,9.0,0.0,9.0,12.0,6.0,12.0,9.0,0.0,3.0,0.0,3.0,6.0,3.0,1.0,16.0,6.0,16.0,15.0,3.0,0.0,3.0,6.0,0.0,6.0,9.0,9.0,3.0,0.0,0.0,16.0,0.0,0.0,0.0,0.0,6.0,6.0,1.0,0.0,12.0,0.0,0.0,12.0,15.0,3.0,3.0,0.0,0.0,9.0,0.0,9.0,17.0,9.0,3.0,0.0,6.0,3.0,8.0,0.0,3.0,0.0,18.0,3.0,1.0,5.0,0.0,3.0,17.0,0.0,6.0,12.0,7.0,4.0,0.0,16.0,12.0,0.0,15.0,9.0,13.0,15.0,12.0,0.0,6.0,14.0,0.0,12.0,3.0,0.0,3.0,6.0,9.0,3.0,0.0,3.0,12.0,16.0,12.0,6.0,0.0,0.0,15.0,15.0,0.0,1.0,0.0,12.0,0.0,6.0,12.0,12.0,3.0,6.0,0.0,3.0,0.0,5.0,3.0,9.0,0.0,13.0,2.0,16.0,3.0,6.0,7.0,13.0,3.0,18.0,0.0,3.0,13.0,12.0,12.0,0.0,3.0,12.0,4.0,3.0,0.0,13.0,6.0,3.0,17.0,6.0,0.0,9.0,9.0,12.0,13.0,6.0,2.0,0.0,0.0,0.0,3.0,1.0,12.0,5.0,3.0,11.0,0.0,0.0,12.0,9.0,1.0,3.0,3.0,12.0,15.0,17.0,0.0,6.0,15.0,0.0,3.0,0.0,3.0,14.0,3.0,0.0,13.0,3.0,9.0,0.0,16.0,14.0,0.0,4.0,12.0,10.0,11.0,1.0,8.0,3.0,0.0,15.0,6.0,0.0,0.0,4.0,11.0,0.0,0.0,11.0,0.0,15.0,0.0,0.0,9.0,1.0,13.0,0.0,6.0,6.0,3.0,0.0,12.0,3.0,12.0,6.0,14.0,12.0,12.0,9.0,3.0,12.0,11.0,1.0,15.0,6.0,0.0,9.0,0.0,9.0,0.0,0.0,0.0,0.0,6.0,6.0,15.0,2.0,10.0,0.0,0.0,0.0,4.0,3.0,1.0,6.0,14.0,6.0,4.0,11.0,17.0,3.0,3.0,5.0,6.0,0.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UNITS_COMPLETED_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"SEM_3_STATUS\"},\"categoryorder\":\"array\",\"categoryarray\":[1,0]},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"6b08582f-b83b-4f4f-8b3b-4f1e40252259\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6b08582f-b83b-4f4f-8b3b-4f1e40252259\")) {                    Plotly.newPlot(                        \"6b08582f-b83b-4f4f-8b3b-4f1e40252259\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>UNITS_COMPLETED_2=%{x}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\"},\"name\":\"0\",\"notched\":false,\"offsetgroup\":\"0\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[4.0,16.0,6.0,9.0,10.0,12.0,10.0,13.0,12.0,17.0,9.0,9.0,11.0,10.0,13.0,12.0,12.0,17.0,15.0,9.0,15.0,13.0,9.0,11.0,11.0,12.0,13.0,12.0,15.0,9.0,16.0,8.0,3.0,15.0,15.0,12.0,15.0,16.0,13.0,15.0,13.0,12.0,12.0,6.0,15.0,16.0,15.0,15.0,14.0,16.0,14.0,12.0,10.0,14.0,12.0,15.0,13.0,15.0,15.0,12.0,15.0,15.0,13.0,12.0,12.0,15.0,12.0,6.0,13.0,12.0,12.0,15.0,12.0,13.0,5.0,6.0,14.0,14.0,15.0,6.0,12.0,15.0,14.0,13.0,15.0,16.0,13.0,5.0,15.0,1.0,15.0,7.0,12.0,16.0,9.0,9.0,9.0,16.0,14.0,12.0,13.0,12.0,16.0,12.0,12.0,13.0,11.0,15.0,15.0,15.0,9.0,12.0,11.0,19.0,9.0,12.0,9.0,7.0,15.0,16.0,15.0,11.0,9.0,15.0,16.0,16.0,6.0,17.0,12.0,15.0,12.0,13.0,9.0,6.0,16.0,15.0,16.0,9.0,13.0,3.0,12.0,12.0,13.0,11.0,15.0,13.0,12.0,10.0,6.0,12.0,17.0,6.0,15.0,15.0,10.0,13.0,9.0,12.0,15.0,13.0,15.0,15.0,14.0,13.0,16.0,13.0,15.0,18.0,16.0,1.0,12.0,13.0,15.0,4.0,9.0,13.0,12.0,12.0,15.0,16.0,15.0,9.0,15.0,12.0,10.0,15.0,15.0,13.0,0.0,9.0,3.0,9.0,12.0,12.0,9.0,16.0,9.0,12.0,15.0,16.0,12.0,15.0,7.0,13.0,12.0,12.0,13.0,13.0,13.0,13.0,16.0,15.0,15.0,3.0,12.0,15.0,11.0,12.0,15.0,13.0,14.0,14.0,9.0,14.0,11.0,5.0,6.0,15.0,15.0,13.0,9.0,9.0,14.0,12.0,15.0,13.0,11.0,11.0,12.0,13.0,12.0,14.0,12.0,0.0,13.0,15.0,15.0,17.0,16.0,15.0,13.0,12.0,11.0,13.0,12.0,15.0,9.0,9.0,15.0,13.0,16.0,14.0,15.0,13.0,13.0,12.0,12.0,15.0,0.0,8.0,9.0,9.0,12.0,14.0,12.0,12.0,13.0,16.0,9.0,13.0,15.0,15.0,9.0,16.0,9.0,18.0,13.0,16.0,9.0,10.0,17.0,15.0,6.0,15.0,13.0,12.0,13.0,8.0,0.0,16.0,10.0,13.0,13.0,9.0,12.0,15.0,3.0,12.0,12.0,15.0,12.0,0.0,8.0,13.0,13.0,13.0,13.0,15.0,11.0,15.0,15.0,14.0,12.0,15.0,12.0,16.0,6.0,15.0,12.0,15.0,12.0,17.0,12.0,13.0,6.0,14.0,16.0,12.0,16.0,15.0,14.0,15.0,9.0,11.0,6.0,11.0,9.0,6.0,15.0,13.0,15.0,12.0,14.0,15.0,9.0,15.0,12.0,15.0,7.0,10.0,12.0,14.0,15.0,12.0,15.0,0.0,11.0,16.0,14.0,12.0,13.0,12.0,3.0,12.0,15.0,12.0,16.0,13.0,13.0,6.0,15.0,16.0,12.0,0.0,12.0,15.0,16.0,13.0,12.0,16.0,14.0,15.0,15.0,15.0,15.0,12.0,9.0,13.0,6.0,15.0,16.0,9.0,14.0,15.0,12.0,12.0,13.0,15.0,12.0,18.0,15.0,12.0,13.0,12.0,9.0,11.0,15.0,13.0,11.0,16.0,13.0,13.0,16.0,0.0,13.0,11.0,16.0,14.0,15.0,13.0,12.0,16.0,6.0,12.0,14.0,12.0,14.0,12.0,16.0,9.0,13.0,15.0,12.0,12.0,6.0,13.0,13.0,15.0,13.0,11.0,6.0,12.0,3.0,15.0,6.0,11.0,16.0,15.0,18.0,13.0,6.0,12.0,9.0,12.0,12.0,15.0,6.0,15.0,12.0,11.0,15.0,16.0,13.0,15.0,14.0,12.0,16.0,16.0,6.0,15.0,11.0,7.0,3.0,13.0,15.0,15.0,16.0,12.0,12.0,12.0,14.0,15.0,15.0,11.0,13.0,12.0,8.0,12.0,15.0,11.0,15.0,15.0,9.0,13.0,12.0,9.0,15.0,15.0,13.0,15.0,13.0,12.0,15.0,6.0,15.0,16.0,12.0,12.0,12.0,15.0,14.0,12.0,15.0,8.0,15.0,13.0,9.0,12.0,12.0,15.0,12.0,15.0,6.0,5.0,15.0,15.0,18.0,10.0,14.0,17.0,13.0,0.0,15.0,6.0,15.0,10.0,0.0,11.0,5.0,13.0,16.0,15.0,13.0,15.0,16.0,9.0,13.0,3.0,12.0,16.0,14.0,15.0,6.0,16.0,15.0,15.0,8.0,9.0,7.0,16.0,13.0,3.0,13.0,5.0,12.0,12.0,12.0,12.0,15.0,13.0,13.0,12.0,9.0,15.0,15.0,3.0,3.0,13.0,12.0,12.0,13.0,15.0,13.0,9.0,6.0,13.0,9.0,15.0,9.0,15.0,13.0,15.0,3.0,12.0,3.0,13.0,15.0,12.0,15.0,12.0,9.0,15.0,14.0,11.0,15.0,14.0,3.0,6.0,14.0,12.0,15.0,15.0,15.0,15.0,18.0,15.0,11.0,13.0,12.0,12.0,15.0,12.0,6.0,15.0,12.0,12.0,15.0,15.0,15.0,12.0,15.0,0.0,15.0,3.0,15.0,17.0,3.0,12.0,16.0,12.0,11.0,15.0,18.0,12.0,7.0,16.0,15.0,16.0,9.0,6.0,9.0,6.0,3.0,16.0,12.0,12.0,13.0,0.0,16.0,13.0,13.0,13.0,6.0,9.0,12.0,12.0,15.0,13.0,5.0,15.0,16.0,12.0,15.0,15.0,12.0,12.0,12.0,16.0,15.0,9.0,12.0,15.0,12.0,15.0,0.0,15.0,7.0,13.0,12.0,15.0,9.0,16.0,13.0,16.0,6.0,16.0,15.0,11.0,9.0,16.0,15.0,14.0,9.0,14.0,9.0,9.0,13.0,17.0,15.0,12.0,3.0,12.0,18.0,13.0,13.0,13.0,9.0,12.0,15.0,12.0,18.0,15.0,15.0,15.0,14.0,12.0,13.0,15.0,8.0,9.0,16.0,15.0,9.0,16.0,6.0,13.0,12.0,15.0,15.0,16.0,13.0,15.0,15.0,16.0,15.0,12.0,6.0,12.0,15.0,11.0,15.0,12.0,17.0,12.0,13.0,9.0,12.0,12.0,8.0,15.0,16.0,15.0,12.0,12.0,14.0,13.0,15.0,16.0,12.0,12.0,14.0,14.0,15.0,10.0,14.0,3.0,9.0,14.0,15.0,13.0,11.0,12.0,15.0,14.0,15.0,9.0,7.0,12.0,16.0,18.0,14.0,13.0,12.0,9.0,15.0,15.0,12.0,9.0,14.0,12.0,16.0,13.0,10.0,14.0,16.0,12.0,15.0,12.0,15.0,15.0,15.0,12.0,16.0,16.0,15.0,16.0,14.0,4.0,9.0,15.0,12.0,6.0,14.0,12.0,15.0,14.0,13.0,13.0,12.0,12.0,14.0,9.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,13.0,0.0,12.0,16.0,12.0,12.0,10.0,15.0,3.0,6.0,6.0,6.0,9.0,15.0,12.0,15.0,0.0,15.0,8.0,12.0,13.0,0.0,12.0,14.0,13.0,15.0,15.0,12.0,12.0,12.0,15.0,17.0,12.0,15.0,9.0,12.0,12.0,6.0,12.0,12.0,16.0,6.0,14.0,15.0,16.0,15.0,6.0,13.0,11.0,14.0,9.0,15.0,15.0,6.0,14.0,11.0,8.0,15.0,6.0,15.0,12.0,12.0,12.0,13.0,10.0,12.0,15.0,15.0,11.0,12.0,15.0,15.0,12.0,15.0,15.0,15.0,14.0,13.0,4.0,9.0,9.0,9.0,16.0,15.0,16.0,5.0,12.0,16.0,12.0,16.0,14.0,12.0,13.0,13.0,12.0,10.0,12.0,12.0,17.0,17.0,12.0,12.0,15.0,14.0,12.0,17.0,12.0,12.0,6.0,12.0,10.0,16.0,15.0,10.0,11.0,16.0,15.0,1.0,16.0,16.0,9.0,10.0,12.0,10.0,0.0,15.0,12.0,14.0,13.0,16.0,13.0,13.0,11.0,14.0,13.0,13.0,11.0,12.0,16.0,12.0,9.0,12.0,12.0,7.0,13.0,16.0,9.0,14.0,12.0,9.0,0.0,10.0,16.0,14.0,11.0,9.0,14.0,9.0,15.0,15.0,16.0,13.0,12.0,12.0,15.0,13.0,6.0,6.0,13.0,13.0,11.0,13.0,17.0,10.0,9.0,11.0,16.0,18.0,15.0,12.0,14.0,12.0,4.0,13.0,15.0,16.0,9.0,15.0,11.0,11.0,10.0,13.0,15.0,13.0,9.0,14.0,14.0,16.0,12.0,13.0,16.0,15.0,3.0,14.0,12.0,14.0,15.0,13.0,3.0,13.0,15.0,16.0,15.0,12.0,16.0,9.0,9.0,15.0,15.0,17.0,13.0,13.0,16.0,13.0,12.0,7.0,9.0,13.0,15.0,6.0,12.0,13.0,9.0,0.0,15.0,9.0,13.0,12.0,11.0,12.0,11.0,14.0,15.0,16.0,15.0,11.0,15.0,10.0,16.0,17.0,13.0,18.0,13.0,9.0,9.0,12.0,14.0,13.0,15.0,12.0,16.0,10.0,12.0,12.0,15.0,12.0,9.0,16.0,16.0,15.0,15.0,15.0,13.0,7.0,15.0,15.0,15.0,10.0,11.0,10.0,9.0,9.0,12.0,12.0,14.0,3.0,13.0,3.0,15.0,11.0,12.0,9.0,16.0,9.0,3.0,15.0,14.0,12.0,15.0,15.0,13.0,14.0,13.0,15.0,13.0,15.0,15.0,10.0,4.0,12.0,15.0,15.0,1.0,12.0,9.0,12.0,14.0,15.0,16.0,15.0,18.0,16.0,3.0,12.0,7.0,12.0,15.0,15.0,12.0,16.0,7.0,14.0,9.0,15.0,12.0,15.0,15.0,15.0,15.0,11.0,13.0,13.0,12.0,15.0,9.0,12.0,16.0,16.0,16.0,16.0,15.0,6.0,9.0,16.0,15.0,15.0,12.0,14.0,15.0,13.0,13.0,12.0,15.0,13.0,11.0,14.0,15.0,15.0,16.0,15.0,13.0,6.0,13.0,16.0,9.0,12.0,9.0,13.0,12.0,14.0,14.0,15.0,15.0,15.0,3.0,18.0,13.0,12.0,7.0,2.0,13.0,18.0,16.0,17.0,12.0,9.0,15.0,13.0,15.0,6.0,13.0,16.0,16.0,13.0,16.0,11.0,6.0,12.0,12.0,15.0,9.0,5.0,11.0,12.0,16.0,13.0,13.0,12.0,9.0,12.0,15.0,15.0,14.0,6.0,16.0,14.0,3.0,18.0,7.0,12.0,12.0,15.0,15.0,14.0,1.0,11.0,12.0,18.0,16.0,7.0,13.0,12.0,13.0,12.0,16.0,14.0,15.0,12.0,9.0,15.0,15.0,10.0,9.0,15.0,16.0,16.0,15.0,12.0,9.0,12.0,13.0,13.0,11.0,13.0,15.0,15.0,16.0,15.0,13.0,16.0,12.0,15.0,0.0,0.0,12.0,12.0,15.0,13.0,15.0,9.0,3.0,4.0,7.0,12.0,16.0,15.0,16.0,15.0,12.0,17.0,12.0,11.0,11.0,0.0,12.0,14.0,1.0,15.0,12.0,15.0,9.0,15.0,13.0,15.0,9.0,12.0,9.0,15.0,12.0,12.0,15.0,9.0,15.0,12.0,12.0,15.0,14.0,13.0,12.0,16.0,16.0,13.0,12.0,12.0,15.0,8.0,10.0,13.0,15.0,9.0,9.0,15.0,15.0,7.0,13.0,16.0,15.0,15.0,14.0,12.0,16.0,13.0,5.0,12.0,12.0,16.0,12.0,11.0,15.0,11.0,11.0,15.0,12.0,14.0,12.0,9.0,15.0,16.0,12.0,16.0,11.0,3.0,12.0,17.0,15.0,15.0,13.0,12.0,12.0,12.0,16.0,13.0,15.0,13.0,12.0,11.0,11.0,12.0,15.0,13.0,13.0,6.0,9.0,16.0,16.0,14.0,15.0,14.0,9.0,13.0,11.0,15.0,16.0,15.0,15.0,12.0,6.0,15.0,13.0,12.0,9.0,15.0,7.0,13.0,11.0,15.0,12.0,11.0,12.0,14.0,13.0,17.0,15.0,6.0,12.0,16.0,15.0,7.0,9.0,14.0,15.0,16.0,9.0,16.0,13.0,14.0,16.0,11.0,6.0,12.0,16.0,9.0,12.0,13.0,15.0,15.0,13.0,14.0,9.0,15.0,16.0,15.0,12.0,15.0,15.0,16.0,17.0,16.0,15.0,14.0,12.0,15.0,14.0,11.0,12.0,15.0,15.0,15.0,9.0,14.0,15.0,12.0,8.0,16.0,15.0,15.0,14.0,6.0,9.0,15.0,12.0,13.0,3.0,12.0,0.0,15.0,11.0,12.0,14.0,14.0,15.0,6.0,15.0,16.0,16.0,12.0,16.0,15.0,15.0,15.0,14.0,12.0,11.0,12.0,7.0,15.0,15.0,16.0,15.0,12.0,15.0,11.0,9.0,16.0,9.0,12.0,12.0,9.0,12.0,15.0,14.0,15.0,16.0,12.0,14.0,9.0,15.0,13.0,10.0,16.0,15.0,7.0,12.0,11.0,9.0,13.0,15.0,15.0,15.0,15.0,9.0,12.0,12.0,19.0,14.0,18.0,15.0,12.0,12.0,13.0,12.0,16.0,16.0,13.0,15.0,13.0,7.0,9.0,12.0,6.0,12.0,10.0,16.0,16.0,18.0,10.0,15.0,12.0,12.0,15.0,15.0,6.0,18.0,13.0,16.0,16.0,16.0,13.0,11.0,9.0,15.0,15.0,3.0,6.0,12.0,13.0,16.0,12.0,12.0,12.0,13.0,12.0,14.0,13.0,9.0,16.0,12.0,15.0,11.0,12.0,12.0,6.0,9.0,16.0,14.0,15.0,13.0,12.0,9.0,7.0,14.0,15.0,13.0,12.0,16.0,16.0,16.0,15.0,15.0,15.0,12.0,7.0,13.0,12.0,15.0,11.0,16.0,15.0,10.0,13.0,6.0,16.0,17.0,12.0,6.0,17.0,12.0,10.0,15.0,15.0,3.0,16.0,8.0,9.0,7.0,15.0,12.0,16.0,11.0,16.0,9.0,14.0,15.0,12.0,15.0,0.0,16.0,15.0,6.0,12.0,14.0,5.0,13.0,15.0,12.0,12.0,15.0,15.0,16.0,13.0,14.0,3.0,15.0,14.0,13.0,13.0,11.0,15.0,12.0,12.0,15.0,13.0,15.0,12.0,16.0,9.0,16.0,5.0,16.0,16.0,12.0,15.0,15.0,12.0,15.0,13.0,16.0,11.0,13.0,6.0,9.0,9.0,15.0,12.0,9.0,15.0,11.0,14.0,16.0,0.0,15.0,12.0,6.0,18.0,12.0,14.0,4.0,13.0,12.0,16.0,6.0,12.0,4.0,15.0,14.0,15.0,13.0,15.0,9.0,15.0,11.0,12.0,13.0,9.0,11.0,13.0,9.0,15.0,12.0,12.0,15.0,15.0,16.0,16.0,16.0,19.0,15.0,9.0,3.0,14.0,16.0,8.0,7.0,16.0,11.0,15.0,11.0,9.0,13.0,6.0,15.0,12.0,10.0,15.0,5.0,13.0,16.0,5.0,12.0,9.0,12.0,12.0,12.0,13.0,16.0,13.0,16.0,3.0,12.0,13.0,7.0,6.0,15.0,3.0,15.0,6.0,15.0,14.0,15.0,9.0,9.0,15.0,12.0,8.0,15.0,13.0,11.0,9.0,16.0,12.0,9.0,12.0,12.0,13.0,15.0,11.0,4.0,15.0,15.0,15.0,3.0,15.0,12.0,12.0,14.0,11.0,12.0,14.0,11.0,15.0,15.0,15.0,15.0,14.0,9.0,12.0,15.0,11.0,15.0,6.0,12.0,6.0,7.0,13.0,12.0,16.0,9.0,11.0,3.0,16.0,13.0,6.0,15.0,15.0,9.0,6.0,15.0,15.0,15.0,3.0,15.0,9.0,11.0,11.0,15.0,15.0,16.0,15.0,16.0,16.0,12.0,16.0,12.0,12.0,4.0,16.0,8.0,7.0,8.0,16.0,15.0,3.0,12.0,6.0,15.0,15.0,12.0,15.0,13.0,16.0,12.0,17.0,12.0,14.0,11.0,15.0,13.0,5.0,15.0,12.0,8.0,3.0,9.0,9.0,15.0,14.0,14.0,15.0,9.0,14.0,14.0,9.0,13.0,10.0,14.0,6.0,15.0,14.0,14.0,12.0,9.0,14.0,13.0,4.0,12.0,7.0,16.0,15.0,14.0,17.0,16.0,12.0,16.0,11.0,6.0,12.0,15.0,18.0,12.0,9.0,12.0,13.0,16.0,8.0,11.0,12.0,15.0,12.0,15.0,12.0,6.0,12.0,15.0,15.0,12.0,15.0,15.0,12.0,15.0,9.0,13.0,16.0,16.0,12.0,13.0,16.0,9.0,12.0,12.0,15.0,12.0,12.0,13.0,12.0,16.0,7.0,12.0,12.0,9.0,12.0,15.0,12.0,13.0,9.0,16.0,16.0,16.0,16.0,15.0,12.0,15.0,9.0,12.0,13.0,15.0,15.0,6.0,6.0,16.0,12.0,14.0,15.0,6.0,12.0,15.0,15.0,15.0,13.0,15.0,3.0,9.0,13.0,15.0,15.0,15.0,15.0,17.0,13.0,16.0,10.0,15.0,12.0,15.0,12.0,15.0,15.0,12.0,12.0,17.0,16.0,15.0,15.0,17.0,12.0,7.0,16.0,12.0,13.0,9.0,13.0,10.0,12.0,13.0,3.0,12.0,12.0,15.0,13.0,12.0,12.0,12.0,14.0,14.0,6.0,11.0,11.0,16.0,15.0,12.0,13.0,16.0,6.0,12.0,12.0,12.0,16.0,17.0,13.0,12.0,13.0,12.0,15.0,15.0,17.0,13.0,12.0,13.0,10.0,12.0,2.0,6.0,12.0,12.0,7.0,12.0,8.0,16.0,18.0,15.0,12.0,12.0,15.0,13.0,12.0,15.0,15.0,11.0,3.0,12.0,15.0,15.0,12.0,3.0,10.0,15.0,7.0,13.0,6.0,12.0,11.0,16.0,6.0,12.0,13.0,15.0,9.0,12.0,10.0,16.0,10.0,15.0,13.0,11.0,12.0,12.0,14.0,15.0,16.0,13.0,13.0,12.0,0.0,9.0,16.0,15.0,17.0,6.0,14.0,15.0,14.0,9.0,12.0,6.0,12.0,13.0,9.0,12.0,15.0,11.0,11.0,12.0,9.0,16.0,11.0,11.0,17.0,13.0,15.0,15.0,14.0,6.0,8.0,14.0,16.0,9.0,16.0,3.0,15.0,15.0,14.0,16.0,9.0,11.0,13.0,3.0,12.0,12.0,14.0,13.0,15.0,10.0,9.0,9.0,9.0,4.0,15.0,9.0,16.0,6.0,15.0,14.0,15.0,12.0,12.0,12.0,13.0,12.0,15.0,12.0,13.0,9.0,15.0,14.0,15.0,7.0,6.0,14.0,12.0,11.0,15.0,11.0,6.0,9.0,15.0,14.0,15.0,13.0,13.0,13.0,15.0,17.0,3.0,16.0,13.0,9.0,13.0,13.0,12.0,1.0,9.0,10.0,16.0,6.0,12.0,9.0,17.0,15.0,9.0,16.0,12.0,15.0,12.0,11.0,14.0,15.0,16.0,0.0,12.0,12.0,13.0,12.0,13.0,15.0,13.0,9.0,1.0,3.0,12.0,14.0,14.0,16.0,15.0,15.0,13.0,15.0,15.0,15.0,9.0,14.0,5.0,17.0,4.0,15.0,16.0,17.0,9.0,13.0,15.0,11.0,13.0,16.0,15.0,15.0,16.0,15.0,16.0,15.0,15.0,15.0,13.0,14.0,12.0,14.0,13.0,12.0,15.0,17.0,15.0,10.0,7.0,16.0,15.0,9.0,15.0,16.0,11.0,16.0,8.0,14.0,12.0,9.0,12.0,16.0,15.0,15.0,12.0,12.0,9.0,16.0,13.0,15.0,16.0,13.0,14.0,10.0,16.0,12.0,14.0,12.0,12.0,12.0,6.0,15.0,16.0,18.0,12.0,15.0,13.0,0.0,15.0,15.0,15.0,16.0,15.0,8.0,7.0,12.0,14.0,12.0,12.0,12.0,9.0,15.0,6.0,12.0,16.0,15.0,13.0,16.0,15.0,9.0,12.0,13.0,15.0,12.0,13.0,13.0,6.0,12.0,15.0,13.0,9.0,11.0,14.0,9.0,12.0,6.0,15.0,0.0,13.0,15.0,12.0,6.0,14.0,15.0,15.0,3.0,11.0,12.0,12.0,14.0,15.0,15.0,12.0,12.0,12.0,13.0,9.0,15.0,11.0,12.0,15.0,11.0,14.0,12.0,15.0,9.0,9.0,13.0,14.0,9.0,15.0,12.0,16.0,12.0,13.0,15.0,13.0,14.0,14.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,9.0,16.0,9.0,11.0,14.0,14.0,13.0,14.0,18.0,16.0,6.0,16.0,16.0,15.0,15.0,9.0,12.0,17.0,12.0,13.0,16.0,12.0,15.0,9.0,12.0,14.0,12.0,12.0,17.0,12.0,12.0,14.0,15.0,13.0,3.0,15.0,14.0,13.0,12.0,12.0,9.0,14.0,12.0,6.0,12.0,12.0,11.0,15.0,6.0,12.0,12.0,3.0,15.0,12.0,16.0,17.0,6.0,15.0,13.0,6.0,12.0,13.0,15.0,15.0,6.0,15.0,12.0,9.0,12.0,12.0,12.0,15.0,12.0,16.0,11.0,9.0,14.0,11.0,14.0,13.0,9.0,15.0,6.0,6.0,9.0,3.0,3.0,9.0,16.0,12.0,14.0,12.0,10.0,9.0,11.0,12.0,12.0,9.0,15.0,15.0,15.0,15.0,13.0,12.0,15.0,12.0,15.0,6.0,10.0,14.0,12.0,6.0,15.0,17.0,12.0,3.0,15.0,12.0,12.0,16.0,6.0,15.0,12.0,9.0,11.0,6.0,9.0,13.0,14.0,15.0,6.0,15.0,16.0,15.0,9.0,12.0,6.0,15.0,15.0,13.0,12.0,15.0,15.0,16.0,4.0,12.0,15.0,9.0,7.0,15.0,15.0,3.0,14.0,15.0,2.0,9.0,8.0,13.0,13.0,15.0,10.0,11.0,9.0,6.0,11.0,14.0,16.0,7.0,12.0,13.0,17.0,15.0,16.0,16.0,9.0,12.0,8.0,12.0,0.0,16.0,4.0,14.0,0.0,12.0,13.0,15.0,13.0,12.0,15.0,15.0,9.0,15.0,12.0,13.0,12.0,13.0,12.0,14.0,11.0,9.0,12.0,15.0,16.0,12.0,15.0,10.0,12.0,11.0,7.0,11.0,12.0,11.0,11.0,11.0,6.0,9.0,14.0,9.0,9.0,13.0,11.0,13.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,3.0,10.0,14.0,15.0,15.0,9.0,16.0,11.0,15.0,6.0,12.0,13.0,6.0,13.0,8.0,12.0,15.0,11.0,12.0,6.0,12.0,13.0,15.0,13.0,15.0,6.0,16.0,16.0,15.0,6.0,9.0,9.0,15.0,13.0,0.0,9.0,15.0,15.0,15.0,0.0,10.0,12.0,13.0,12.0,13.0,13.0,9.0,15.0,15.0,11.0,15.0,15.0,9.0,0.0,15.0,15.0,11.0,12.0,18.0,6.0,12.0,16.0,13.0,15.0,15.0,13.0,9.0,15.0,0.0,15.0,16.0,6.0,12.0,15.0,11.0,15.0,12.0,15.0,13.0,9.0,15.0,12.0,14.0,6.0,11.0,13.0,6.0,15.0,6.0,10.0,15.0,13.0,14.0,15.0,14.0,12.0,13.0,15.0,15.0,6.0,13.0,7.0,13.0,12.0,12.0,15.0,13.0,15.0,12.0,9.0,15.0,6.0,16.0,13.0,13.0,15.0,15.0,14.0,12.0,12.0,13.0,16.0,8.0,14.0,7.0,15.0,7.0,10.0,15.0,13.0,14.0,15.0,15.0,10.0,12.0,16.0,16.0,13.0,15.0,14.0,12.0,9.0,12.0,14.0,15.0,11.0,12.0,15.0,18.0,12.0,12.0,9.0,11.0,11.0,7.0,15.0,12.0,16.0,15.0,10.0,9.0,0.0,12.0,8.0,10.0,12.0,15.0,13.0,12.0,16.0,13.0,15.0,0.0,12.0,16.0,6.0,16.0,13.0,11.0,15.0,15.0,16.0,16.0,12.0,3.0,12.0,10.0,4.0,12.0,15.0,14.0,12.0,7.0,13.0,12.0,8.0,0.0,10.0,15.0,15.0,12.0,12.0,16.0,9.0,3.0,12.0,6.0,9.0,13.0,13.0,15.0,9.0,6.0,14.0,16.0,16.0,13.0,12.0,16.0,5.0,3.0,17.0,14.0,13.0,16.0,9.0,15.0,3.0,15.0,12.0,7.0,13.0,12.0,15.0,17.0,11.0,12.0,15.0,14.0,12.0,13.0,11.0,13.0,6.0,9.0,9.0,8.0,16.0,16.0,13.0,14.0,3.0,9.0,11.0,10.0,10.0,9.0,12.0,9.0,15.0,17.0,15.0,16.0,12.0,9.0,12.0,12.0,11.0,12.0,17.0,15.0,15.0,12.0,15.0,11.0,13.0,16.0,11.0,15.0,16.0,16.0,17.0,18.0,14.0,15.0,15.0,12.0,15.0,10.0,12.0,15.0,9.0,11.0,15.0,13.0,9.0,13.0,6.0,12.0,14.0,15.0,16.0,5.0,3.0,13.0,9.0,16.0,16.0,9.0,6.0,9.0,13.0,13.0,0.0,16.0,9.0,12.0,15.0,11.0,13.0,9.0,12.0,11.0,6.0,13.0,7.0,12.0,15.0,13.0,12.0,12.0,15.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,0.0,14.0,15.0,9.0,14.0,13.0,11.0,12.0,17.0,13.0,12.0,10.0,15.0,10.0,13.0,15.0,15.0,0.0,15.0,12.0,9.0,12.0,14.0,9.0,9.0,14.0,7.0,13.0,14.0,14.0,13.0,6.0,3.0,9.0,5.0,12.0,17.0,15.0,3.0,17.0,9.0,12.0,14.0,15.0,12.0,15.0,12.0,12.0,14.0,11.0,9.0,11.0,16.0,11.0,15.0,12.0,14.0,13.0,5.0,12.0,14.0,3.0,16.0,15.0,16.0,15.0,11.0,12.0,13.0,15.0,13.0,13.0,12.0,13.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,7.0,13.0,11.0,15.0,10.0,13.0,12.0,9.0,16.0,10.0,16.0,16.0,7.0,12.0,3.0,13.0,6.0,14.0,12.0,6.0,16.0,13.0,15.0,15.0,18.0,13.0,15.0,13.0,12.0,15.0,14.0,15.0,13.0,15.0,7.0,9.0,13.0,12.0,15.0,13.0,15.0,9.0,14.0,10.0,6.0,15.0,14.0,9.0,3.0,13.0,16.0,14.0,4.0,14.0,12.0,12.0,15.0,13.0,14.0,15.0,15.0,15.0,12.0,3.0,3.0,16.0,16.0,12.0,3.0,15.0,13.0,12.0,14.0,14.0,15.0,18.0,12.0,15.0,12.0,12.0,12.0,13.0,15.0,12.0,12.0,12.0,15.0,12.0,14.0,13.0,9.0,4.0,15.0,10.0,15.0,13.0,13.0,12.0,7.0,11.0,6.0,9.0,12.0,13.0,8.0,13.0,15.0,12.0,3.0,12.0,12.0,12.0,14.0,12.0,7.0,7.0,12.0,12.0,16.0,9.0,10.0,15.0,18.0,10.0,13.0,13.0,15.0,9.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"},{\"alignmentgroup\":\"True\",\"hovertemplate\":\"SEM_3_STATUS=%{y}<br>UNITS_COMPLETED_2=%{x}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\"},\"name\":\"1\",\"notched\":false,\"offsetgroup\":\"1\",\"orientation\":\"h\",\"showlegend\":true,\"x\":[18.0,0.0,3.0,6.0,0.0,3.0,0.0,3.0,6.0,3.0,0.0,6.0,14.0,0.0,6.0,9.0,4.0,13.0,13.0,3.0,0.0,0.0,6.0,6.0,6.0,12.0,12.0,0.0,0.0,7.0,11.0,6.0,3.0,12.0,9.0,0.0,3.0,0.0,0.0,13.0,0.0,3.0,9.0,16.0,3.0,6.0,0.0,0.0,13.0,13.0,0.0,3.0,2.0,6.0,0.0,0.0,15.0,0.0,6.0,0.0,0.0,3.0,4.0,0.0,9.0,3.0,0.0,1.0,3.0,0.0,13.0,1.0,3.0,4.0,9.0,10.0,12.0,9.0,0.0,9.0,12.0,6.0,12.0,9.0,0.0,3.0,0.0,3.0,6.0,3.0,1.0,16.0,6.0,16.0,15.0,3.0,0.0,3.0,6.0,0.0,6.0,9.0,9.0,3.0,0.0,0.0,16.0,0.0,0.0,0.0,0.0,6.0,6.0,1.0,0.0,12.0,0.0,0.0,12.0,15.0,3.0,3.0,0.0,0.0,9.0,0.0,9.0,17.0,9.0,3.0,0.0,6.0,3.0,8.0,0.0,3.0,0.0,18.0,3.0,1.0,5.0,0.0,3.0,17.0,0.0,6.0,12.0,7.0,4.0,0.0,16.0,12.0,0.0,15.0,9.0,13.0,15.0,12.0,0.0,6.0,14.0,0.0,12.0,3.0,0.0,3.0,6.0,9.0,3.0,0.0,3.0,12.0,16.0,12.0,6.0,0.0,0.0,15.0,15.0,0.0,1.0,0.0,12.0,0.0,6.0,12.0,12.0,3.0,6.0,0.0,3.0,0.0,5.0,3.0,9.0,0.0,13.0,2.0,16.0,3.0,6.0,7.0,13.0,3.0,18.0,0.0,3.0,13.0,12.0,12.0,0.0,3.0,12.0,4.0,3.0,0.0,13.0,6.0,3.0,17.0,6.0,0.0,9.0,9.0,12.0,13.0,6.0,2.0,0.0,0.0,0.0,3.0,1.0,12.0,5.0,3.0,11.0,0.0,0.0,12.0,9.0,1.0,3.0,3.0,12.0,15.0,17.0,0.0,6.0,15.0,0.0,3.0,0.0,3.0,14.0,3.0,0.0,13.0,3.0,9.0,0.0,16.0,14.0,0.0,4.0,12.0,10.0,11.0,1.0,8.0,3.0,0.0,15.0,6.0,0.0,0.0,4.0,11.0,0.0,0.0,11.0,0.0,15.0,0.0,0.0,9.0,1.0,13.0,0.0,6.0,6.0,3.0,0.0,12.0,3.0,12.0,6.0,14.0,12.0,12.0,9.0,3.0,12.0,11.0,1.0,15.0,6.0,0.0,9.0,0.0,9.0,0.0,0.0,0.0,0.0,6.0,6.0,15.0,2.0,10.0,0.0,0.0,0.0,4.0,3.0,1.0,6.0,14.0,6.0,4.0,11.0,17.0,3.0,3.0,5.0,6.0,0.0],\"x0\":\" \",\"xaxis\":\"x\",\"y\":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\"y0\":\" \",\"yaxis\":\"y\",\"type\":\"box\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UNITS_COMPLETED_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"SEM_3_STATUS\"},\"categoryorder\":\"array\",\"categoryarray\":[1,0]},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60},\"boxmode\":\"group\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(Xy_build_c, x='UNITS_COMPLETED_2', y='SEM_3_STATUS', color='SEM_3_STATUS', boxmode=\"overlay\")\n",
    "fig.update_layout(boxmode='group')  # To group the box plots by category\n",
    "fig.update_traces(orientation='h') # horizontal box plots\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67273a12-efd8-4e5f-a8a4-4c1de8f083b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "These plots tell the same story as the numerical statistics: dropout in tem 3 sems to be strongly asociated with poor academic performance leading up to that term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5c7db82-7b6b-423c-9d42-1385effd135c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "In spite of the above, the following scatterplot can give us some insight as to how challenging it might be to distinguish between classes when implementing a classification model. The red points indicate students who leave in semester 3, wheras the purple ones are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09fc42f0-8ca0-4911-a9ab-8f2988336ee1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\")) {                    Plotly.newPlot(                        \"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\",                        [{\"hovertemplate\":\"SEM_3_STATUS=0<br>GPA_2=%{x}<br>UNITS_COMPLETED_2=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"showlegend\":true,\"x\":[1.6666666666666667,3.6875,1.6923076923076923,4.0,1.5,2.75,2.071428571428572,4.0,2.25,4.0,2.25,2.75,4.0,3.1,3.5384615384615383,3.0,3.25,4.0,4.0,2.4,2.6,3.5384615384615383,3.333333333333333,4.0,2.4375,3.0,2.6923076923076925,3.5,3.8,3.333333333333333,3.5625,2.625,1.0,3.8,2.933333333333333,2.6666666666666665,2.6,4.0,3.5384615384615383,3.6,3.769230769230769,4.0,2.1333333333333333,1.5454545454545454,2.8,3.125,3.0,4.0,3.7142857142857135,4.0,3.4285714285714284,3.75,2.1333333333333333,2.7142857142857144,3.0,3.8,3.5384615384615383,4.0,3.4,3.5,4.0,4.0,2.4615384615384617,3.75,4.0,2.6,2.6,2.125,3.769230769230769,1.8,4.0,3.8,3.5,2.6923076923076925,2.0,2.0,4.0,3.5,3.733333333333333,3.5,4.0,4.0,4.0,4.0,3.733333333333333,3.3125,3.076923076923077,1.0,3.4,0.3333333333333333,2.4,4.0,2.9166666666666665,3.8125,2.25,4.0,2.3846153846153846,3.5,4.0,3.0,3.230769230769231,3.25,4.0,3.0,4.0,2.6875,3.272727272727273,4.0,4.0,2.6666666666666665,2.5,3.5,2.5454545454545454,3.1578947368421053,2.6666666666666665,3.1666666666666665,3.0,4.0,3.8,3.8125,3.533333333333333,3.1818181818181817,2.0,3.466666666666667,4.0,3.1875,4.0,3.647058823529412,2.5,3.4,3.333333333333333,3.692307692307693,2.0,4.0,3.8125,3.2,3.625,3.0,3.3076923076923075,1.0,4.0,3.0,2.923076923076923,2.363636363636364,4.0,2.8125,2.4,2.466666666666667,3.5,2.75,4.0,1.25,3.0,3.4,3.7,3.769230769230769,2.333333333333333,3.5,2.8,3.5384615384615383,3.4,3.0,4.0,4.0,3.375,3.4615384615384617,3.2,3.333333333333333,2.3125,0.2857142857142857,3.25,3.4615384615384617,3.2,1.1666666666666667,2.4166666666666665,3.5384615384615383,2.75,3.25,3.733333333333333,4.0,3.533333333333333,2.0,2.2,2.5,4.0,3.4,3.6,2.6923076923076925,0.0,3.6666666666666665,2.0,3.6666666666666665,3.75,3.2,2.6666666666666665,3.625,1.8571428571428568,3.25,4.0,3.5625,3.75,3.6,2.0,2.8461538461538463,2.75,3.25,3.0,2.6923076923076925,3.5384615384615383,3.0625,3.4375,3.4,2.6,1.6923076923076923,2.25,3.4,3.272727272727273,3.25,2.8,3.5384615384615383,2.7857142857142856,3.2857142857142856,2.1538461538461537,3.7142857142857135,3.5454545454545454,1.5555555555555556,1.5,3.4,3.6,4.0,2.25,3.6666666666666665,3.2857142857142856,2.75,4.0,4.0,4.0,3.727272727272727,3.75,3.769230769230769,3.25,3.7142857142857135,3.0,0.0,3.615384615384616,3.8,3.2,3.117647058823529,4.0,2.8,4.0,2.75,4.0,3.769230769230769,2.5,3.933333333333333,2.25,1.8,4.0,2.9285714285714284,3.8125,4.0,3.6,3.5384615384615383,3.230769230769231,4.0,1.8,3.066666666666667,0.5,3.0,2.1538461538461537,2.0,3.75,3.071428571428572,3.5,2.833333333333333,3.4615384615384617,3.9375,3.6666666666666665,3.1538461538461537,3.8,3.2,2.5,3.625,2.090909090909091,4.0,3.3076923076923075,4.0,2.0,2.0,3.588235294117647,3.6,3.0,3.0,3.3846153846153846,3.25,4.0,4.0,0.0,3.5625,2.4615384615384617,3.692307692307693,3.769230769230769,3.333333333333333,2.6,3.6,0.6428571428571429,3.583333333333333,3.6666666666666665,3.066666666666667,3.75,0.5,3.5,2.6923076923076925,3.1538461538461537,2.8461538461538463,3.1538461538461537,4.0,3.5454545454545454,3.733333333333333,3.2,4.0,2.5,4.0,2.5,3.625,2.0,3.8,3.25,3.6,3.75,4.0,4.0,3.4615384615384617,1.181818181818182,3.0,3.3125,3.0,3.375,3.0,2.642857142857143,3.0,2.0,4.0,2.5,2.909090909090909,3.333333333333333,2.0,4.0,4.0,3.0,2.75,3.357142857142857,3.8,2.2,2.6,4.0,3.0,1.5833333333333333,2.571428571428572,3.75,2.857142857142857,3.4,2.4,3.066666666666667,0.0,3.727272727272727,2.25,4.0,3.4166666666666665,3.769230769230769,4.0,1.3333333333333333,3.333333333333333,4.0,2.6,2.9375,3.5384615384615383,3.4615384615384617,1.6666666666666667,3.6,4.0,2.4,0.0,4.0,3.2,2.625,3.1538461538461537,2.2,3.8125,2.5,4.0,3.333333333333333,4.0,3.0,3.0625,3.0,4.0,1.3846153846153846,3.8,3.4375,2.5,3.0,3.8,3.0,3.0,3.3846153846153846,4.0,2.583333333333333,4.0,4.0,2.5,4.0,3.0,3.333333333333333,2.4285714285714284,3.2666666666666666,2.230769230769231,3.5454545454545454,4.0,4.0,3.3846153846153846,4.0,0.25,3.076923076923077,4.0,4.0,2.7142857142857144,3.533333333333333,3.3846153846153846,3.0,3.625,1.5625,3.5,3.357142857142857,3.25,2.857142857142857,3.75,3.0625,3.0,3.692307692307693,3.6,2.75,2.2,2.0,4.0,4.0,3.0,3.692307692307693,4.0,2.0,3.75,1.0,3.6,2.6666666666666665,3.5454545454545454,3.25,2.8,3.6666666666666665,2.5384615384615383,2.0,2.75,3.0,3.25,2.2,3.2,1.6,3.0,2.0,3.272727272727273,3.066666666666667,3.6875,3.1538461538461537,3.6,2.2142857142857144,3.1666666666666665,3.375,3.5625,1.4285714285714286,3.2666666666666666,4.0,2.0,1.0,4.0,3.1333333333333333,3.4,3.25,3.75,3.5,3.25,2.7857142857142856,3.8,3.6,3.727272727272727,2.4615384615384617,4.0,1.9166666666666667,2.5,3.0,2.8181818181818183,3.4,3.2,3.0,2.230769230769231,3.5,4.0,3.6,3.4,3.3076923076923075,3.2,2.923076923076923,2.75,4.0,1.5,3.0,3.625,3.5,4.0,3.0,4.0,3.5,4.0,2.8,1.4285714285714286,4.0,3.692307692307693,2.5,2.8,3.25,3.0,2.8,4.0,2.0,2.0,3.4,3.8,3.8333333333333335,1.9230769230769231,2.7058823529411766,3.117647058823529,3.3076923076923075,0.5384615384615384,4.0,1.4285714285714286,3.4,2.0,0.2,4.0,3.2,4.0,3.8125,3.6,4.0,3.8,4.0,1.8,3.076923076923077,1.0,3.0,3.8125,2.5,3.8,3.5,3.375,3.6,3.0,1.9090909090909087,1.6,3.2857142857142856,3.625,3.2666666666666666,3.0,3.4615384615384617,2.0,2.5,2.0,4.0,2.4,3.0,2.4615384615384617,3.4615384615384617,3.5,3.0,3.4,2.8666666666666667,0.6,1.3333333333333333,3.4615384615384617,3.1666666666666665,3.5,3.0,3.333333333333333,2.8461538461538463,3.0,3.5,4.0,2.0,3.8,2.5,3.2,2.4615384615384617,3.8,4.0,3.25,1.3333333333333333,3.3076923076923075,3.0,3.6666666666666665,3.8,3.25,3.0,3.8,3.7857142857142856,2.8181818181818183,3.8,3.071428571428572,3.0,1.9,3.0,3.25,2.6,4.0,3.533333333333333,3.2,3.8333333333333335,3.733333333333333,2.0625,3.5384615384615383,2.75,3.5,3.8,3.5,1.25,3.8,3.75,2.9166666666666665,4.0,3.8,3.2,2.6,3.0,0.1875,4.0,2.0,3.2,3.588235294117647,1.6666666666666667,4.0,4.0,3.5,2.272727272727273,3.4,3.7777777777777777,3.083333333333333,1.6153846153846154,3.8125,3.6,3.8125,3.333333333333333,2.333333333333333,2.25,1.0666666666666669,0.8,3.1875,3.75,3.5,3.615384615384616,0.0,3.75,3.1538461538461537,3.692307692307693,3.3846153846153846,1.9230769230769231,2.5,2.4,3.6666666666666665,3.0,3.692307692307693,2.25,2.6,2.8125,3.1666666666666665,3.066666666666667,3.0,3.75,3.75,4.0,3.8125,4.0,2.8461538461538463,2.4,2.6,3.5,4.0,0.0,3.2,1.6666666666666667,3.692307692307693,3.75,3.8,4.0,3.75,2.4615384615384617,3.1875,2.333333333333333,3.625,3.8,3.727272727272727,1.9285714285714288,3.1666666666666665,3.4,4.0,2.75,3.0,2.076923076923077,2.6666666666666665,3.230769230769231,2.647058823529412,4.0,3.25,1.5,3.333333333333333,3.2222222222222223,3.1538461538461537,3.923076923076923,4.0,2.25,2.1333333333333333,4.0,3.75,3.333333333333333,3.0,3.6,3.0,4.0,3.25,2.4375,3.0,3.75,2.5,3.5625,3.4,2.5,3.0625,1.6666666666666667,3.230769230769231,3.75,4.0,3.0,4.0,3.0,3.6,2.4,3.1875,4.0,3.75,1.6,2.75,3.8,4.0,3.2,3.5,3.4705882352941178,3.25,3.230769230769231,1.8,2.4,2.75,1.7272727272727273,4.0,3.1875,2.4,2.75,3.75,3.071428571428572,2.5,3.4,3.375,3.5,4.0,2.176470588235294,3.2142857142857144,4.0,3.6,4.0,1.4615384615384617,2.25,3.7857142857142856,3.0,3.769230769230769,4.0,1.9333333333333331,3.2,4.0,4.0,4.0,1.9166666666666667,3.5,2.5625,3.6666666666666665,3.571428571428572,3.0625,4.0,2.071428571428572,3.8,3.0,2.9166666666666665,2.8461538461538463,3.7142857142857135,2.5,4.0,2.6153846153846154,2.0,4.0,3.1875,2.5,3.2666666666666666,3.75,4.0,3.0,2.6,3.5,4.0,3.4375,3.4,3.5625,2.357142857142857,1.3076923076923077,3.6666666666666665,3.2,3.75,1.6666666666666667,2.0,2.75,3.6,4.0,2.923076923076923,3.4615384615384617,2.2,2.8,2.571428571428572,2.0,3.0,3.333333333333333,2.8666666666666667,1.8,3.8,3.8,3.6,3.0,0.0,3.4166666666666665,3.8125,3.25,4.0,2.571428571428572,3.0,3.0,2.125,1.6363636363636365,2.0,2.0,3.0,2.066666666666667,3.6,0.0,3.333333333333333,1.4,2.75,4.0,0.0,2.8,4.0,2.230769230769231,3.6,3.6666666666666665,3.25,3.0,2.0,2.8,3.764705882352941,4.0,3.2,3.0,3.0,3.0,2.0,3.75,2.75,4.0,1.6,3.571428571428572,3.6,4.0,3.6,2.5,2.4615384615384617,3.727272727272727,4.0,2.25,3.8,4.0,3.5,4.0,4.0,2.230769230769231,3.8,4.0,3.8,2.933333333333333,3.75,3.4166666666666665,2.923076923076923,3.6,2.6666666666666665,3.6,4.0,2.357142857142857,4.0,3.2,2.8,4.0,2.7333333333333334,3.2,2.8,4.0,3.230769230769231,3.25,2.5,2.0,1.6153846153846154,4.0,3.1333333333333333,4.0,1.4545454545454546,3.75,3.625,2.75,4.0,3.2142857142857144,2.4,3.692307692307693,3.230769230769231,3.0,4.0,2.75,3.5,3.7058823529411766,4.0,2.1666666666666665,3.0,3.6666666666666665,4.0,3.0,3.4705882352941178,3.0,3.75,1.75,4.0,2.230769230769231,3.75,3.4,2.0,3.272727272727273,3.5625,2.8,0.1666666666666666,3.8125,3.8125,1.8,3.1,2.75,3.0,0.0,3.8,2.4,3.142857142857143,2.923076923076923,2.875,2.769230769230769,3.692307692307693,3.4545454545454546,3.0,3.1538461538461537,3.692307692307693,2.8181818181818183,2.75,3.625,3.25,3.6666666666666665,1.9411764705882355,4.0,1.9090909090909087,3.692307692307693,3.625,2.75,3.571428571428572,2.75,2.75,1.0,2.0,3.75,4.0,2.272727272727273,2.75,3.2142857142857144,3.6666666666666665,3.6,3.4,4.0,2.769230769230769,3.25,3.5,3.0,2.6153846153846154,1.75,1.6666666666666667,3.4615384615384617,3.5384615384615383,3.272727272727273,3.5384615384615383,3.3529411764705883,2.6,1.3888888888888888,4.0,3.625,3.7777777777777777,4.0,3.0,3.571428571428572,3.25,2.0,4.0,3.0,4.0,3.0,4.0,3.272727272727273,3.5454545454545454,2.357142857142857,4.0,4.0,3.230769230769231,3.555555555555556,3.7857142857142856,4.0,4.0,3.333333333333333,4.0,3.3125,2.6,1.2857142857142858,2.2142857142857144,2.5,2.4285714285714284,3.6,3.1538461538461537,1.25,2.4615384615384617,3.6666666666666665,3.625,3.6,3.5,3.25,2.5,3.333333333333333,2.8,3.8,4.0,4.0,2.8461538461538463,3.8125,3.230769230769231,3.75,3.571428571428572,3.6666666666666665,3.5384615384615383,3.8,1.2352941176470589,3.2,2.75,3.6666666666666665,0.0,3.4,3.6666666666666665,3.769230769230769,3.75,4.0,3.75,2.8181818181818183,3.2142857142857144,3.0,3.75,3.8,2.272727272727273,4.0,2.7142857142857144,3.25,3.176470588235294,3.769230769230769,4.0,3.230769230769231,3.333333333333333,2.5,3.5,3.357142857142857,3.692307692307693,3.0,3.5,3.1875,2.7,3.0,3.75,3.2,3.6666666666666665,2.25,3.4375,3.5,3.6666666666666665,3.6,2.6,2.4615384615384617,3.571428571428572,2.8,3.2,2.8,3.0,2.2142857142857144,2.0,2.1818181818181817,2.25,3.2,4.0,4.0,0.4615384615384615,4.0,1.6666666666666667,3.6,3.5454545454545454,3.1666666666666665,2.25,3.75,1.5,0.4615384615384615,3.2,3.642857142857143,4.0,2.6,3.4,2.4615384615384617,3.2857142857142856,3.076923076923077,2.8,2.4615384615384617,3.2,3.333333333333333,2.3125,2.2857142857142856,3.75,3.4,3.6,0.6153846153846154,3.0,3.6666666666666665,4.0,3.2857142857142856,4.0,3.625,3.4,3.2777777777777777,4.0,1.5,4.0,1.3076923076923077,4.0,3.2,3.8,4.0,4.0,3.0,4.0,2.7777777777777777,3.6,3.5,3.8,2.8,3.2,3.066666666666667,2.1333333333333333,4.0,2.4615384615384617,3.75,4.0,1.75,3.5,2.375,2.875,3.0,3.0,3.2,0.9375,3.6666666666666665,4.0,3.6,3.2,3.0,3.642857142857143,4.0,2.4615384615384617,3.5384615384615383,4.0,4.0,3.1538461538461537,3.0,4.0,4.0,2.533333333333333,3.75,4.0,3.3076923076923075,0.8,3.230769230769231,3.4375,4.0,2.6,2.0,4.0,3.0,3.2142857142857144,3.071428571428572,3.6,3.4,3.6,0.6666666666666666,4.0,3.1538461538461537,2.4,1.4,0.375,3.769230769230769,4.0,3.5625,4.0,2.4,2.25,3.6,4.0,2.8,2.363636363636364,4.0,4.0,3.8125,3.769230769230769,3.8125,2.7333333333333334,1.8,3.5,2.7333333333333334,2.7333333333333334,2.5384615384615383,1.3636363636363635,3.4545454545454546,2.8,3.25,4.0,2.6153846153846154,3.5,1.8,3.25,2.8,4.0,3.357142857142857,3.0,3.5625,3.357142857142857,1.25,3.6666666666666665,1.5,2.75,4.0,4.0,3.8,4.0,1.3,2.5454545454545454,2.0,4.0,3.75,1.6153846153846154,3.5384615384615383,3.2,3.769230769230769,3.0,3.8125,4.0,4.0,3.25,3.6666666666666665,3.8,3.0,2.6153846153846154,1.8,3.8,2.75,3.75,3.6,2.0,1.6,3.5,3.923076923076923,3.230769230769231,3.909090909090909,4.0,3.8,4.0,3.0,3.4,3.230769230769231,3.5625,4.0,3.2,0.0,0.2,4.0,4.0,3.2,2.4615384615384617,3.2,1.9230769230769231,0.4285714285714285,2.0,2.1666666666666665,3.0,3.8125,3.4,3.25,3.6666666666666665,3.5,4.0,3.5,2.727272727272727,2.727272727272727,0.3333333333333333,4.0,3.571428571428572,0.6153846153846154,3.6,3.0,2.8,3.0,3.0,3.0,3.533333333333333,2.75,3.5,1.75,3.0,4.0,3.5,3.533333333333333,1.6,3.8,4.0,3.5,3.4,3.642857142857143,2.6153846153846154,4.0,3.625,3.0625,2.6923076923076925,3.5,3.75,3.6,4.0,2.769230769230769,3.692307692307693,2.8,2.5,2.5,3.8,2.8,2.25,3.615384615384616,3.5,3.8,3.066666666666667,3.642857142857143,2.0,3.25,2.8461538461538463,1.9230769230769231,4.0,3.5,3.5625,2.25,3.5454545454545454,3.6,2.466666666666667,3.636363636363636,3.4,3.0,3.571428571428572,3.0,2.1538461538461537,3.8,3.625,2.75,3.75,2.2142857142857144,0.8,3.0,3.235294117647059,2.6,3.2,4.0,4.0,2.75,3.25,3.75,2.4615384615384617,3.4,4.0,3.75,2.5454545454545454,3.5454545454545454,3.5,3.2,2.1875,3.230769230769231,4.0,3.6666666666666665,4.0,2.625,2.2857142857142856,3.6,2.7857142857142856,3.0,3.692307692307693,4.0,3.4,3.0625,3.4,3.6,3.25,1.75,3.4,2.6923076923076925,3.25,2.6153846153846154,4.0,1.2142857142857142,2.230769230769231,3.090909090909091,3.2,4.0,4.0,2.75,3.642857142857143,2.5625,3.117647058823529,3.2,4.0,3.5,2.9375,4.0,1.0666666666666669,2.8,3.7142857142857135,4.0,3.0625,2.555555555555556,4.0,3.230769230769231,2.2142857142857144,3.4375,4.0,1.5,2.6,3.8125,3.0,3.0,3.0,3.4,2.8,2.8461538461538463,3.2857142857142856,1.75,3.2,2.6875,3.8,2.4285714285714284,3.6,3.4,3.5,3.823529411764706,3.5625,2.6,3.642857142857143,3.4166666666666665,3.0,3.5,3.090909090909091,2.5,3.066666666666667,3.0,3.466666666666667,2.1538461538461537,2.9285714285714284,4.0,1.8,3.0,3.375,3.2,2.8,4.0,1.4,2.0,4.0,3.75,2.8461538461538463,1.6666666666666667,2.5,0.0,3.466666666666667,3.636363636363636,3.25,3.7142857142857135,4.0,3.0,3.333333333333333,3.2,3.8125,3.6875,1.8,4.0,3.2666666666666666,3.8,3.6,2.857142857142857,4.0,4.0,3.75,1.4545454545454546,3.8,3.6,3.8125,3.6,2.5,3.4,2.8181818181818183,1.6,3.75,2.333333333333333,3.75,3.6666666666666665,2.0,2.4166666666666665,3.6,4.0,4.0,2.875,4.0,3.142857142857143,2.75,2.6,2.375,3.3,3.8125,3.6,2.571428571428572,3.0625,3.636363636363636,2.5,4.0,3.2666666666666666,3.8,3.2,3.8,2.0,3.5,3.25,4.0,2.7857142857142856,4.0,3.8,2.9166666666666665,2.75,3.4615384615384617,2.5,4.0,2.9375,4.0,3.0,4.0,2.3846153846153846,1.8461538461538465,2.0625,2.5,3.0,2.7,3.25,3.625,3.6666666666666665,2.0625,3.4,3.25,3.1666666666666665,3.6,3.0,1.5,4.0,3.4615384615384617,3.125,3.375,3.8125,2.6153846153846154,2.0625,3.6666666666666665,3.4,4.0,1.0,1.75,4.0,4.0,4.0,3.5,2.75,4.0,4.0,3.0,4.0,2.923076923076923,3.333333333333333,3.625,3.5,4.0,2.4,4.0,4.0,3.0,1.6875,3.5625,3.642857142857143,3.4,4.0,2.5,1.6,1.3076923076923077,4.0,3.733333333333333,3.4615384615384617,2.4,3.8125,3.5625,3.375,3.4,3.733333333333333,4.0,3.25,3.142857142857143,4.0,4.0,3.8,3.4545454545454546,3.25,2.4,2.7,3.5384615384615383,3.5,3.8125,3.235294117647059,3.75,1.2,3.647058823529412,3.5,2.3076923076923075,2.8666666666666667,3.6,0.75,3.0625,2.75,2.2222222222222223,4.0,3.6,3.0,3.625,4.0,3.0625,1.5,3.2142857142857144,4.0,2.4,3.2,0.0,3.5,3.0,1.1538461538461535,2.75,3.2142857142857144,2.4,3.3846153846153846,3.2,2.75,1.8,3.6,3.2,3.8125,2.5625,3.7857142857142856,0.9166666666666666,3.0,3.2142857142857144,2.6153846153846154,3.692307692307693,4.0,3.0,3.333333333333333,3.25,4.0,2.3076923076923075,3.8,3.25,3.125,2.75,2.9375,2.5,3.5,3.8125,3.0,4.0,2.4,3.75,3.4,4.0,3.3125,3.727272727272727,4.0,1.6666666666666667,3.333333333333333,2.75,3.8,2.75,2.0,3.2,3.0,2.857142857142857,3.8125,1.0,4.0,2.25,2.363636363636364,4.0,3.25,3.357142857142857,0.9333333333333332,2.769230769230769,3.75,4.0,1.4166666666666667,3.75,1.0,3.6,3.7142857142857135,4.0,3.615384615384616,3.8,2.333333333333333,3.4,3.090909090909091,3.75,2.6923076923076925,2.25,4.0,3.769230769230769,1.75,3.2,2.2,2.75,3.2,3.0,3.75,3.375,3.8125,3.526315789473684,3.533333333333333,4.0,2.0,3.7857142857142856,3.0,2.6666666666666665,2.0,4.0,3.272727272727273,2.888888888888889,3.090909090909091,3.0,4.0,1.25,3.8,3.0,2.8,4.0,2.2222222222222223,3.0,4.0,1.6923076923076923,4.0,3.0,3.5,3.75,2.75,4.0,4.0,3.615384615384616,3.0625,1.25,3.0,3.0,1.25,3.5,3.8,0.375,3.8,0.9333333333333332,3.6666666666666665,2.2142857142857144,3.2,2.8461538461538463,1.8,3.2,3.25,2.5,3.8,3.769230769230769,2.7142857142857144,1.75,4.0,2.75,3.0,3.75,3.25,3.4615384615384617,3.4,2.4285714285714284,1.5384615384615383,3.2,4.0,2.8,1.0,3.733333333333333,3.25,2.5,3.4285714285714284,3.0,3.4166666666666665,3.571428571428572,2.125,3.0,3.0,4.0,3.0,2.857142857142857,1.5,3.0,4.0,2.8181818181818183,3.8,2.1538461538461537,3.083333333333333,1.5,2.0,4.0,2.2,3.4375,2.5,3.5454545454545454,1.3333333333333333,3.75,4.0,1.6666666666666667,4.0,3.6,1.5,2.5,3.4,3.0,3.0,1.5,4.0,2.0,4.0,4.0,3.533333333333333,3.4,2.9375,3.4,4.0,4.0,4.0,3.8125,2.1333333333333333,3.0,1.2,2.9375,2.1818181818181817,2.25,2.375,3.0,3.533333333333333,1.0,2.75,1.25,3.6,3.2,2.75,4.0,2.1538461538461537,2.75,3.5,4.0,4.0,4.0,3.272727272727273,3.0,4.0,1.1333333333333333,3.0,3.75,2.8181818181818183,1.0,2.833333333333333,2.6666666666666665,3.4,3.4285714285714284,3.7142857142857135,3.8,4.0,2.9285714285714284,3.7142857142857135,2.75,4.0,2.923076923076923,2.4285714285714284,1.4,3.0,3.2857142857142856,3.142857142857143,2.25,3.6666666666666665,4.0,3.769230769230769,2.0,3.5,1.0769230769230769,4.0,4.0,2.7142857142857144,3.882352941176471,4.0,3.75,3.25,4.0,3.5,3.25,3.2,3.1666666666666665,3.5,2.6666666666666665,3.25,3.230769230769231,2.8125,3.5,3.090909090909091,3.25,3.0,3.5,3.6,2.5,2.2,3.75,3.6,3.0,3.5,3.4,2.8,2.75,3.2,2.333333333333333,3.1538461538461537,3.4375,3.1875,2.25,3.692307692307693,3.5,2.7142857142857144,3.0,3.5,3.4,2.25,4.0,3.076923076923077,2.833333333333333,3.4375,1.6153846153846154,2.9166666666666665,2.2,4.0,3.0,3.2,3.5,3.230769230769231,2.4444444444444446,4.0,4.0,3.5625,3.625,4.0,3.5,3.733333333333333,1.3846153846153846,3.083333333333333,3.3076923076923075,3.8,4.0,1.25,1.3333333333333333,2.5625,3.25,2.857142857142857,3.4,3.5,3.25,2.8,3.0,3.8,2.3076923076923075,4.0,0.8571428571428571,3.6666666666666665,3.076923076923077,3.4,4.0,2.533333333333333,2.6,3.0,3.769230769230769,3.375,3.6,4.0,2.75,2.2,4.0,3.6,3.8,2.6,3.5,3.3529411764705883,3.6875,3.6,4.0,4.0,3.5,1.6875,3.6875,2.5,3.923076923076923,4.0,3.769230769230769,3.7,4.0,2.8461538461538463,0.5,3.75,2.5,3.2,3.692307692307693,2.75,3.0,3.75,3.357142857142857,3.571428571428572,0.8,3.727272727272727,3.363636363636364,3.75,4.0,3.6666666666666665,4.0,3.3125,2.0,4.0,3.75,2.0,2.9375,2.764705882352941,3.1538461538461537,3.0,2.923076923076923,4.0,2.8,3.6,3.5294117647058822,4.0,1.9375,3.0,2.0,3.75,0.8235294117647058,2.0,3.0,4.0,3.4285714285714284,2.75,2.1666666666666665,2.5625,3.4444444444444446,3.1333333333333333,3.0,3.333333333333333,2.4,3.230769230769231,3.75,4.0,3.4,4.0,0.75,3.0,4.0,3.4,2.5,1.1666666666666667,2.2,2.7333333333333334,1.5384615384615383,4.0,1.4,3.4166666666666665,4.0,3.75,1.5,3.25,3.769230769230769,3.4,3.0,2.6,2.3076923076923075,3.5625,3.3,3.8,3.3076923076923075,3.5454545454545454,2.75,2.25,3.2142857142857144,3.6,3.8125,3.692307692307693,3.769230769230769,3.75,0.0,2.25,3.3125,3.6,4.0,2.5,3.5,3.4,3.642857142857143,2.6666666666666665,3.75,3.0,3.75,3.769230769230769,2.6666666666666665,2.4166666666666665,3.6,3.1818181818181817,3.5454545454545454,2.75,2.0,3.8125,4.0,3.727272727272727,3.0,3.5384615384615383,4.0,3.4,3.142857142857143,1.8,2.25,2.857142857142857,3.0625,2.083333333333333,3.375,1.5,3.6,3.2,3.0,3.625,1.75,3.090909090909091,3.769230769230769,3.0,2.1666666666666665,3.25,2.642857142857143,3.4615384615384617,3.8,2.3,3.333333333333333,2.1538461538461537,2.5,1.5,3.6,3.333333333333333,4.0,1.6666666666666667,4.0,3.571428571428572,4.0,3.0,3.25,3.583333333333333,3.615384615384616,3.5,2.8,3.5,3.230769230769231,2.75,3.6,2.5294117647058822,3.8,2.4166666666666665,1.5,3.2857142857142856,3.0,4.0,3.8,3.090909090909091,1.0,2.25,3.8,3.1875,3.6,2.923076923076923,3.692307692307693,3.4615384615384617,3.466666666666667,3.764705882352941,4.0,3.375,3.692307692307693,1.75,3.5384615384615383,3.5384615384615383,3.5,4.0,2.6666666666666665,4.0,4.0,1.0714285714285714,4.0,2.2142857142857144,3.823529411764706,3.4,2.5,3.0625,2.75,3.4,3.5,4.0,3.2142857142857144,2.6,4.0,0.0,3.25,3.5,3.769230769230769,3.5,3.1538461538461537,3.6,2.8461538461538463,1.8,0.6666666666666666,1.0,3.0,3.071428571428572,3.7857142857142856,3.375,2.2,3.8,4.0,4.0,3.4,3.8,2.3846153846153846,4.0,1.0,2.5294117647058822,2.5,4.0,4.0,4.0,2.333333333333333,2.75,3.2,3.5454545454545454,2.8461538461538463,3.3125,2.8,4.0,3.625,4.0,4.0,3.533333333333333,4.0,3.8,3.0,4.0,3.1666666666666665,2.7857142857142856,4.0,2.125,3.0,3.3529411764705883,3.8,2.2857142857142856,2.071428571428572,2.9375,4.0,3.6666666666666665,2.8,2.75,2.7142857142857144,2.9375,1.5714285714285714,3.2142857142857144,3.5,2.6153846153846154,2.5,2.5,4.0,3.066666666666667,3.333333333333333,2.3125,2.25,3.8125,2.6923076923076925,3.4,3.5625,2.8461538461538463,2.642857142857143,2.769230769230769,3.625,3.2,2.9285714285714284,3.333333333333333,2.5,2.6,2.333333333333333,3.0,4.0,3.6666666666666665,3.0,2.8,4.0,0.4,3.2,3.2,2.0,3.75,3.8,2.8461538461538463,4.0,3.75,3.7142857142857135,2.25,3.75,3.25,3.0,2.6,2.5,3.6666666666666665,3.375,2.8,3.230769230769231,3.4375,4.0,2.6666666666666665,2.0,2.6923076923076925,3.4,3.9166666666666665,3.769230769230769,3.4615384615384617,2.833333333333333,3.25,3.4,2.923076923076923,3.0,2.8181818181818183,3.2857142857142856,1.5,4.0,1.5,4.0,0.0,2.5625,2.8,2.25,2.6666666666666665,3.7857142857142856,3.8,3.6666666666666665,0.6,4.0,3.75,3.5,3.2857142857142856,3.2,3.0,3.25,3.583333333333333,3.0,2.923076923076923,2.6666666666666665,3.0,4.0,3.0,3.0,2.5454545454545454,2.823529411764706,2.066666666666667,3.4,3.333333333333333,2.0,3.692307692307693,3.142857142857143,1.5,3.4,2.25,4.0,3.0,4.0,3.4,2.6923076923076925,2.9285714285714284,2.9285714285714284,3.0,2.4,3.2,4.0,3.2,3.0,3.0,3.0,4.0,1.8,2.357142857142857,2.4285714285714284,3.071428571428572,4.0,2.7142857142857144,4.0,3.3125,1.5,3.75,3.375,3.6,3.4,2.5,4.0,3.411764705882353,3.0,3.230769230769231,3.8125,3.5,3.8,4.0,4.0,2.857142857142857,3.75,3.25,2.3529411764705883,3.5,4.0,3.071428571428572,2.4,3.4615384615384617,4.0,3.0,3.2142857142857144,2.6923076923076925,4.0,3.6666666666666665,2.571428571428572,3.642857142857143,2.5,1.3333333333333333,3.75,2.4166666666666665,3.5454545454545454,4.0,2.090909090909091,3.25,4.0,1.25,3.4,4.0,4.0,3.647058823529412,1.2,3.4,3.3076923076923075,3.5,2.75,3.769230769230769,3.6,3.8,2.333333333333333,3.6,3.75,2.6666666666666665,4.0,2.833333333333333,3.25,3.8,2.75,4.0,3.5454545454545454,2.0,4.0,4.0,3.7142857142857135,2.230769230769231,1.5,2.4,1.2,1.125,2.2,1.2307692307692308,1.0,2.75,3.8125,4.0,2.642857142857143,3.6666666666666665,3.2,3.333333333333333,3.909090909090909,3.75,3.75,3.0,3.6,4.0,3.2,3.4,3.1538461538461537,3.0,2.8,3.25,2.6,2.5,2.2,3.2857142857142856,3.0,2.0,4.0,4.0,2.75,0.4615384615384615,3.4,3.25,3.0,4.0,2.0,3.8,2.75,2.0,3.090909090909091,4.0,3.6666666666666665,2.8461538461538463,3.642857142857143,3.8,2.6666666666666665,4.0,3.1875,3.6,2.25,2.75,1.25,4.0,4.0,3.076923076923077,3.0,3.8,3.6,3.5625,1.2307692307692308,2.2,3.333333333333333,2.25,1.375,2.8,3.733333333333333,1.5,4.0,3.466666666666667,2.0,2.5,3.375,3.769230769230769,2.6923076923076925,3.2,2.272727272727273,2.857142857142857,1.5,1.6,3.272727272727273,2.9285714285714284,3.8125,4.0,3.0,2.230769230769231,3.294117647058824,2.6,2.5625,3.375,3.0,4.0,1.5625,2.5,1.0,4.0,0.8888888888888888,4.0,0.5,4.0,4.0,3.0,3.615384615384616,3.0,3.2,3.2,1.8,3.8,3.0,2.8461538461538463,3.5,2.923076923076923,3.75,3.4285714285714284,4.0,3.0,3.75,3.4,3.5625,4.0,3.2,2.076923076923077,2.75,1.8571428571428568,3.2857142857142856,3.272727272727273,2.9166666666666665,3.5454545454545454,3.636363636363636,2.909090909090909,1.9090909090909087,2.0,2.571428571428572,2.2142857142857144,2.6666666666666665,2.8461538461538463,4.0,4.0,4.0,3.0,2.333333333333333,3.75,4.0,4.0,3.0,1.4285714285714286,2.8461538461538463,2.357142857142857,3.6,2.6,1.75,3.0625,4.0,3.8,1.5,2.25,2.3076923076923075,1.6666666666666667,3.769230769230769,2.75,3.5,3.2,4.0,3.0,2.0,3.25,3.4615384615384617,4.0,3.0,4.0,2.5,2.4375,3.625,3.8,2.5,3.6666666666666665,3.0,3.2,3.4615384615384617,0.0,3.4444444444444446,3.2,2.466666666666667,3.8,0.0,4.0,3.5,3.1538461538461537,3.75,4.0,2.0,2.25,3.2,3.6,2.4285714285714284,3.6,4.0,3.0,0.0,4.0,3.6,2.8181818181818183,3.5,2.833333333333333,3.0,3.75,3.4375,3.5384615384615383,4.0,3.466666666666667,4.0,1.3125,4.0,0.2,3.6666666666666665,3.375,1.4,3.5,2.933333333333333,3.090909090909091,2.8,3.0,3.4,3.230769230769231,2.5384615384615383,4.0,3.0,2.0,2.0,3.5454545454545454,3.076923076923077,2.0,4.0,1.5,1.9285714285714288,4.0,3.5384615384615383,3.7142857142857135,3.6,3.857142857142857,3.75,3.0,3.8,2.6,1.2,4.0,1.7,3.5384615384615383,3.0,2.75,3.2,2.9411764705882355,3.8,3.2,4.0,3.6,1.5,3.0625,3.3846153846153846,3.4615384615384617,3.0,3.2,3.5,4.0,3.0,3.769230769230769,2.5625,3.625,3.7142857142857135,1.9,3.6,1.4,2.1538461538461537,3.4,3.0,2.857142857142857,4.0,4.0,2.0,3.5,3.6875,3.75,2.4615384615384617,3.2,3.357142857142857,2.0,2.3846153846153846,3.4166666666666665,4.0,3.8,3.636363636363636,1.9375,2.6,3.8333333333333335,3.1666666666666665,2.2,1.8,4.0,3.363636363636364,3.142857142857143,4.0,3.0,3.5625,3.6,2.0,2.6666666666666665,0.0,2.5,1.5,3.4,2.25,3.6666666666666665,2.142857142857143,3.75,3.375,4.0,3.4,0.0,3.25,2.9375,1.5,3.75,2.647058823529412,3.272727272727273,4.0,3.4,3.25,2.5,4.0,3.0,3.0,2.9,1.6428571428571428,2.1666666666666665,3.2,2.642857142857143,3.5,1.9230769230769231,3.1538461538461537,2.933333333333333,2.636363636363636,0.3846153846153846,2.0,2.333333333333333,3.6666666666666665,4.0,4.0,3.625,2.0,2.5,4.0,2.6666666666666665,2.25,4.0,3.1538461538461537,4.0,2.3846153846153846,2.0,2.9285714285714284,3.8125,3.8125,4.0,3.5,3.8125,1.2307692307692308,1.3333333333333333,3.3529411764705883,3.2142857142857144,3.5384615384615383,4.0,1.8,3.4,1.0,4.0,3.75,1.3333333333333333,2.0,3.75,3.4,2.0,4.0,4.0,4.0,3.142857142857143,3.5,2.6923076923076925,3.0,3.769230769230769,3.5,3.0,3.0,1.9090909090909087,3.3125,3.75,3.0,3.2142857142857144,4.0,2.75,4.0,2.076923076923077,2.0,2.0,3.25,3.333333333333333,3.4,3.647058823529412,3.2666666666666666,3.375,2.4,2.0,3.5,2.75,2.071428571428572,3.5,3.823529411764706,4.0,3.0,3.0,2.4,4.0,2.6923076923076925,3.125,3.0,3.0,2.75,4.0,3.764705882352941,4.0,3.7857142857142856,3.333333333333333,2.8,2.6875,3.2,3.3,3.25,3.066666666666667,4.0,4.0,3.4,3.5384615384615383,3.6666666666666665,3.0,2.333333333333333,3.0,2.4285714285714284,4.0,3.8125,2.083333333333333,4.0,3.0,2.4,3.625,3.8125,2.5,2.0,2.75,4.0,3.769230769230769,0.0,3.8125,2.333333333333333,2.75,4.0,4.0,2.8461538461538463,4.0,2.5,2.2666666666666666,4.0,2.5,2.0,2.75,3.0,3.8461538461538463,4.0,3.5,3.4,2.933333333333333,3.25,4.0,3.25,3.6,3.8,2.4375,0.0,3.4285714285714284,4.0,1.9285714285714288,3.7857142857142856,3.692307692307693,2.7333333333333334,3.5,3.823529411764706,3.769230769230769,3.5,2.0625,3.533333333333333,4.0,3.0,3.6,3.8,0.0,3.333333333333333,2.75,3.4444444444444446,3.25,2.857142857142857,4.0,3.333333333333333,3.4285714285714284,2.8,4.0,3.357142857142857,3.2857142857142856,3.769230769230769,0.8571428571428571,0.6428571428571429,1.6,1.4545454545454546,3.5,2.9411764705882355,2.8,0.6666666666666666,4.0,2.0,2.75,3.2857142857142856,2.4,2.5,3.2,2.75,3.25,4.0,2.909090909090909,4.0,4.0,3.8125,4.0,3.2,2.75,4.0,2.8461538461538463,1.5384615384615383,3.5,3.571428571428572,1.0,4.0,2.2,3.625,3.8,3.363636363636364,4.0,3.3846153846153846,3.6,4.0,4.0,3.5,2.923076923076923,3.25,2.5,4.0,2.6,3.4,3.6,3.4615384615384617,3.8,3.75,3.4,2.0,4.0,4.0,3.0,3.4,3.3076923076923075,3.0,2.8461538461538463,2.5625,2.769230769230769,2.8125,3.5625,2.25,3.5,0.4285714285714285,3.3846153846153846,1.75,3.7857142857142856,2.5,3.0,4.0,3.3076923076923075,2.8,3.4,3.0,2.375,3.066666666666667,3.692307692307693,4.0,3.0,2.7857142857142856,4.0,4.0,3.8,2.272727272727273,2.0,2.4615384615384617,3.25,2.8,3.769230769230769,3.466666666666667,1.75,3.571428571428572,2.6,1.0,3.2,3.071428571428572,2.1538461538461537,1.5,2.6153846153846154,4.0,3.642857142857143,1.1428571428571428,4.0,3.0,4.0,3.6,3.4615384615384617,2.9285714285714284,3.4,4.0,3.466666666666667,3.076923076923077,1.5,2.5,3.4375,2.8125,2.25,0.75,3.4,3.769230769230769,3.75,4.0,2.7142857142857144,2.933333333333333,2.833333333333333,4.0,3.1333333333333333,3.25,2.5,2.75,2.375,3.2,3.0,3.0,3.75,2.8666666666666667,2.583333333333333,3.642857142857143,2.6923076923076925,3.0,2.7142857142857144,2.466666666666667,2.5,3.4,2.6923076923076925,2.375,2.2,2.076923076923077,4.0,2.0,3.333333333333333,3.25,2.923076923076923,2.5,3.4615384615384617,4.0,4.0,1.0,4.0,3.25,3.25,3.357142857142857,3.75,2.4545454545454546,3.571428571428572,3.0,3.25,3.0625,2.5,2.9,3.2,3.8333333333333335,3.076923076923077,3.769230769230769,4.0,3.6,2.6666666666666665],\"xaxis\":\"x\",\"y\":[4.0,16.0,6.0,9.0,10.0,12.0,10.0,13.0,12.0,17.0,9.0,9.0,11.0,10.0,13.0,12.0,12.0,17.0,15.0,9.0,15.0,13.0,9.0,11.0,11.0,12.0,13.0,12.0,15.0,9.0,16.0,8.0,3.0,15.0,15.0,12.0,15.0,16.0,13.0,15.0,13.0,12.0,12.0,6.0,15.0,16.0,15.0,15.0,14.0,16.0,14.0,12.0,10.0,14.0,12.0,15.0,13.0,15.0,15.0,12.0,15.0,15.0,13.0,12.0,12.0,15.0,12.0,6.0,13.0,12.0,12.0,15.0,12.0,13.0,5.0,6.0,14.0,14.0,15.0,6.0,12.0,15.0,14.0,13.0,15.0,16.0,13.0,5.0,15.0,1.0,15.0,7.0,12.0,16.0,9.0,9.0,9.0,16.0,14.0,12.0,13.0,12.0,16.0,12.0,12.0,13.0,11.0,15.0,15.0,15.0,9.0,12.0,11.0,19.0,9.0,12.0,9.0,7.0,15.0,16.0,15.0,11.0,9.0,15.0,16.0,16.0,6.0,17.0,12.0,15.0,12.0,13.0,9.0,6.0,16.0,15.0,16.0,9.0,13.0,3.0,12.0,12.0,13.0,11.0,15.0,13.0,12.0,10.0,6.0,12.0,17.0,6.0,15.0,15.0,10.0,13.0,9.0,12.0,15.0,13.0,15.0,15.0,14.0,13.0,16.0,13.0,15.0,18.0,16.0,1.0,12.0,13.0,15.0,4.0,9.0,13.0,12.0,12.0,15.0,16.0,15.0,9.0,15.0,12.0,10.0,15.0,15.0,13.0,0.0,9.0,3.0,9.0,12.0,12.0,9.0,16.0,9.0,12.0,15.0,16.0,12.0,15.0,7.0,13.0,12.0,12.0,13.0,13.0,13.0,13.0,16.0,15.0,15.0,3.0,12.0,15.0,11.0,12.0,15.0,13.0,14.0,14.0,9.0,14.0,11.0,5.0,6.0,15.0,15.0,13.0,9.0,9.0,14.0,12.0,15.0,13.0,11.0,11.0,12.0,13.0,12.0,14.0,12.0,0.0,13.0,15.0,15.0,17.0,16.0,15.0,13.0,12.0,11.0,13.0,12.0,15.0,9.0,9.0,15.0,13.0,16.0,14.0,15.0,13.0,13.0,12.0,12.0,15.0,0.0,8.0,9.0,9.0,12.0,14.0,12.0,12.0,13.0,16.0,9.0,13.0,15.0,15.0,9.0,16.0,9.0,18.0,13.0,16.0,9.0,10.0,17.0,15.0,6.0,15.0,13.0,12.0,13.0,8.0,0.0,16.0,10.0,13.0,13.0,9.0,12.0,15.0,3.0,12.0,12.0,15.0,12.0,0.0,8.0,13.0,13.0,13.0,13.0,15.0,11.0,15.0,15.0,14.0,12.0,15.0,12.0,16.0,6.0,15.0,12.0,15.0,12.0,17.0,12.0,13.0,6.0,14.0,16.0,12.0,16.0,15.0,14.0,15.0,9.0,11.0,6.0,11.0,9.0,6.0,15.0,13.0,15.0,12.0,14.0,15.0,9.0,15.0,12.0,15.0,7.0,10.0,12.0,14.0,15.0,12.0,15.0,0.0,11.0,16.0,14.0,12.0,13.0,12.0,3.0,12.0,15.0,12.0,16.0,13.0,13.0,6.0,15.0,16.0,12.0,0.0,12.0,15.0,16.0,13.0,12.0,16.0,14.0,15.0,15.0,15.0,15.0,12.0,9.0,13.0,6.0,15.0,16.0,9.0,14.0,15.0,12.0,12.0,13.0,15.0,12.0,18.0,15.0,12.0,13.0,12.0,9.0,11.0,15.0,13.0,11.0,16.0,13.0,13.0,16.0,0.0,13.0,11.0,16.0,14.0,15.0,13.0,12.0,16.0,6.0,12.0,14.0,12.0,14.0,12.0,16.0,9.0,13.0,15.0,12.0,12.0,6.0,13.0,13.0,15.0,13.0,11.0,6.0,12.0,3.0,15.0,6.0,11.0,16.0,15.0,18.0,13.0,6.0,12.0,9.0,12.0,12.0,15.0,6.0,15.0,12.0,11.0,15.0,16.0,13.0,15.0,14.0,12.0,16.0,16.0,6.0,15.0,11.0,7.0,3.0,13.0,15.0,15.0,16.0,12.0,12.0,12.0,14.0,15.0,15.0,11.0,13.0,12.0,8.0,12.0,15.0,11.0,15.0,15.0,9.0,13.0,12.0,9.0,15.0,15.0,13.0,15.0,13.0,12.0,15.0,6.0,15.0,16.0,12.0,12.0,12.0,15.0,14.0,12.0,15.0,8.0,15.0,13.0,9.0,12.0,12.0,15.0,12.0,15.0,6.0,5.0,15.0,15.0,18.0,10.0,14.0,17.0,13.0,0.0,15.0,6.0,15.0,10.0,0.0,11.0,5.0,13.0,16.0,15.0,13.0,15.0,16.0,9.0,13.0,3.0,12.0,16.0,14.0,15.0,6.0,16.0,15.0,15.0,8.0,9.0,7.0,16.0,13.0,3.0,13.0,5.0,12.0,12.0,12.0,12.0,15.0,13.0,13.0,12.0,9.0,15.0,15.0,3.0,3.0,13.0,12.0,12.0,13.0,15.0,13.0,9.0,6.0,13.0,9.0,15.0,9.0,15.0,13.0,15.0,3.0,12.0,3.0,13.0,15.0,12.0,15.0,12.0,9.0,15.0,14.0,11.0,15.0,14.0,3.0,6.0,14.0,12.0,15.0,15.0,15.0,15.0,18.0,15.0,11.0,13.0,12.0,12.0,15.0,12.0,6.0,15.0,12.0,12.0,15.0,15.0,15.0,12.0,15.0,0.0,15.0,3.0,15.0,17.0,3.0,12.0,16.0,12.0,11.0,15.0,18.0,12.0,7.0,16.0,15.0,16.0,9.0,6.0,9.0,6.0,3.0,16.0,12.0,12.0,13.0,0.0,16.0,13.0,13.0,13.0,6.0,9.0,12.0,12.0,15.0,13.0,5.0,15.0,16.0,12.0,15.0,15.0,12.0,12.0,12.0,16.0,15.0,9.0,12.0,15.0,12.0,15.0,0.0,15.0,7.0,13.0,12.0,15.0,9.0,16.0,13.0,16.0,6.0,16.0,15.0,11.0,9.0,16.0,15.0,14.0,9.0,14.0,9.0,9.0,13.0,17.0,15.0,12.0,3.0,12.0,18.0,13.0,13.0,13.0,9.0,12.0,15.0,12.0,18.0,15.0,15.0,15.0,14.0,12.0,13.0,15.0,8.0,9.0,16.0,15.0,9.0,16.0,6.0,13.0,12.0,15.0,15.0,16.0,13.0,15.0,15.0,16.0,15.0,12.0,6.0,12.0,15.0,11.0,15.0,12.0,17.0,12.0,13.0,9.0,12.0,12.0,8.0,15.0,16.0,15.0,12.0,12.0,14.0,13.0,15.0,16.0,12.0,12.0,14.0,14.0,15.0,10.0,14.0,3.0,9.0,14.0,15.0,13.0,11.0,12.0,15.0,14.0,15.0,9.0,7.0,12.0,16.0,18.0,14.0,13.0,12.0,9.0,15.0,15.0,12.0,9.0,14.0,12.0,16.0,13.0,10.0,14.0,16.0,12.0,15.0,12.0,15.0,15.0,15.0,12.0,16.0,16.0,15.0,16.0,14.0,4.0,9.0,15.0,12.0,6.0,14.0,12.0,15.0,14.0,13.0,13.0,12.0,12.0,14.0,9.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,13.0,0.0,12.0,16.0,12.0,12.0,10.0,15.0,3.0,6.0,6.0,6.0,9.0,15.0,12.0,15.0,0.0,15.0,8.0,12.0,13.0,0.0,12.0,14.0,13.0,15.0,15.0,12.0,12.0,12.0,15.0,17.0,12.0,15.0,9.0,12.0,12.0,6.0,12.0,12.0,16.0,6.0,14.0,15.0,16.0,15.0,6.0,13.0,11.0,14.0,9.0,15.0,15.0,6.0,14.0,11.0,8.0,15.0,6.0,15.0,12.0,12.0,12.0,13.0,10.0,12.0,15.0,15.0,11.0,12.0,15.0,15.0,12.0,15.0,15.0,15.0,14.0,13.0,4.0,9.0,9.0,9.0,16.0,15.0,16.0,5.0,12.0,16.0,12.0,16.0,14.0,12.0,13.0,13.0,12.0,10.0,12.0,12.0,17.0,17.0,12.0,12.0,15.0,14.0,12.0,17.0,12.0,12.0,6.0,12.0,10.0,16.0,15.0,10.0,11.0,16.0,15.0,1.0,16.0,16.0,9.0,10.0,12.0,10.0,0.0,15.0,12.0,14.0,13.0,16.0,13.0,13.0,11.0,14.0,13.0,13.0,11.0,12.0,16.0,12.0,9.0,12.0,12.0,7.0,13.0,16.0,9.0,14.0,12.0,9.0,0.0,10.0,16.0,14.0,11.0,9.0,14.0,9.0,15.0,15.0,16.0,13.0,12.0,12.0,15.0,13.0,6.0,6.0,13.0,13.0,11.0,13.0,17.0,10.0,9.0,11.0,16.0,18.0,15.0,12.0,14.0,12.0,4.0,13.0,15.0,16.0,9.0,15.0,11.0,11.0,10.0,13.0,15.0,13.0,9.0,14.0,14.0,16.0,12.0,13.0,16.0,15.0,3.0,14.0,12.0,14.0,15.0,13.0,3.0,13.0,15.0,16.0,15.0,12.0,16.0,9.0,9.0,15.0,15.0,17.0,13.0,13.0,16.0,13.0,12.0,7.0,9.0,13.0,15.0,6.0,12.0,13.0,9.0,0.0,15.0,9.0,13.0,12.0,11.0,12.0,11.0,14.0,15.0,16.0,15.0,11.0,15.0,10.0,16.0,17.0,13.0,18.0,13.0,9.0,9.0,12.0,14.0,13.0,15.0,12.0,16.0,10.0,12.0,12.0,15.0,12.0,9.0,16.0,16.0,15.0,15.0,15.0,13.0,7.0,15.0,15.0,15.0,10.0,11.0,10.0,9.0,9.0,12.0,12.0,14.0,3.0,13.0,3.0,15.0,11.0,12.0,9.0,16.0,9.0,3.0,15.0,14.0,12.0,15.0,15.0,13.0,14.0,13.0,15.0,13.0,15.0,15.0,10.0,4.0,12.0,15.0,15.0,1.0,12.0,9.0,12.0,14.0,15.0,16.0,15.0,18.0,16.0,3.0,12.0,7.0,12.0,15.0,15.0,12.0,16.0,7.0,14.0,9.0,15.0,12.0,15.0,15.0,15.0,15.0,11.0,13.0,13.0,12.0,15.0,9.0,12.0,16.0,16.0,16.0,16.0,15.0,6.0,9.0,16.0,15.0,15.0,12.0,14.0,15.0,13.0,13.0,12.0,15.0,13.0,11.0,14.0,15.0,15.0,16.0,15.0,13.0,6.0,13.0,16.0,9.0,12.0,9.0,13.0,12.0,14.0,14.0,15.0,15.0,15.0,3.0,18.0,13.0,12.0,7.0,2.0,13.0,18.0,16.0,17.0,12.0,9.0,15.0,13.0,15.0,6.0,13.0,16.0,16.0,13.0,16.0,11.0,6.0,12.0,12.0,15.0,9.0,5.0,11.0,12.0,16.0,13.0,13.0,12.0,9.0,12.0,15.0,15.0,14.0,6.0,16.0,14.0,3.0,18.0,7.0,12.0,12.0,15.0,15.0,14.0,1.0,11.0,12.0,18.0,16.0,7.0,13.0,12.0,13.0,12.0,16.0,14.0,15.0,12.0,9.0,15.0,15.0,10.0,9.0,15.0,16.0,16.0,15.0,12.0,9.0,12.0,13.0,13.0,11.0,13.0,15.0,15.0,16.0,15.0,13.0,16.0,12.0,15.0,0.0,0.0,12.0,12.0,15.0,13.0,15.0,9.0,3.0,4.0,7.0,12.0,16.0,15.0,16.0,15.0,12.0,17.0,12.0,11.0,11.0,0.0,12.0,14.0,1.0,15.0,12.0,15.0,9.0,15.0,13.0,15.0,9.0,12.0,9.0,15.0,12.0,12.0,15.0,9.0,15.0,12.0,12.0,15.0,14.0,13.0,12.0,16.0,16.0,13.0,12.0,12.0,15.0,8.0,10.0,13.0,15.0,9.0,9.0,15.0,15.0,7.0,13.0,16.0,15.0,15.0,14.0,12.0,16.0,13.0,5.0,12.0,12.0,16.0,12.0,11.0,15.0,11.0,11.0,15.0,12.0,14.0,12.0,9.0,15.0,16.0,12.0,16.0,11.0,3.0,12.0,17.0,15.0,15.0,13.0,12.0,12.0,12.0,16.0,13.0,15.0,13.0,12.0,11.0,11.0,12.0,15.0,13.0,13.0,6.0,9.0,16.0,16.0,14.0,15.0,14.0,9.0,13.0,11.0,15.0,16.0,15.0,15.0,12.0,6.0,15.0,13.0,12.0,9.0,15.0,7.0,13.0,11.0,15.0,12.0,11.0,12.0,14.0,13.0,17.0,15.0,6.0,12.0,16.0,15.0,7.0,9.0,14.0,15.0,16.0,9.0,16.0,13.0,14.0,16.0,11.0,6.0,12.0,16.0,9.0,12.0,13.0,15.0,15.0,13.0,14.0,9.0,15.0,16.0,15.0,12.0,15.0,15.0,16.0,17.0,16.0,15.0,14.0,12.0,15.0,14.0,11.0,12.0,15.0,15.0,15.0,9.0,14.0,15.0,12.0,8.0,16.0,15.0,15.0,14.0,6.0,9.0,15.0,12.0,13.0,3.0,12.0,0.0,15.0,11.0,12.0,14.0,14.0,15.0,6.0,15.0,16.0,16.0,12.0,16.0,15.0,15.0,15.0,14.0,12.0,11.0,12.0,7.0,15.0,15.0,16.0,15.0,12.0,15.0,11.0,9.0,16.0,9.0,12.0,12.0,9.0,12.0,15.0,14.0,15.0,16.0,12.0,14.0,9.0,15.0,13.0,10.0,16.0,15.0,7.0,12.0,11.0,9.0,13.0,15.0,15.0,15.0,15.0,9.0,12.0,12.0,19.0,14.0,18.0,15.0,12.0,12.0,13.0,12.0,16.0,16.0,13.0,15.0,13.0,7.0,9.0,12.0,6.0,12.0,10.0,16.0,16.0,18.0,10.0,15.0,12.0,12.0,15.0,15.0,6.0,18.0,13.0,16.0,16.0,16.0,13.0,11.0,9.0,15.0,15.0,3.0,6.0,12.0,13.0,16.0,12.0,12.0,12.0,13.0,12.0,14.0,13.0,9.0,16.0,12.0,15.0,11.0,12.0,12.0,6.0,9.0,16.0,14.0,15.0,13.0,12.0,9.0,7.0,14.0,15.0,13.0,12.0,16.0,16.0,16.0,15.0,15.0,15.0,12.0,7.0,13.0,12.0,15.0,11.0,16.0,15.0,10.0,13.0,6.0,16.0,17.0,12.0,6.0,17.0,12.0,10.0,15.0,15.0,3.0,16.0,8.0,9.0,7.0,15.0,12.0,16.0,11.0,16.0,9.0,14.0,15.0,12.0,15.0,0.0,16.0,15.0,6.0,12.0,14.0,5.0,13.0,15.0,12.0,12.0,15.0,15.0,16.0,13.0,14.0,3.0,15.0,14.0,13.0,13.0,11.0,15.0,12.0,12.0,15.0,13.0,15.0,12.0,16.0,9.0,16.0,5.0,16.0,16.0,12.0,15.0,15.0,12.0,15.0,13.0,16.0,11.0,13.0,6.0,9.0,9.0,15.0,12.0,9.0,15.0,11.0,14.0,16.0,0.0,15.0,12.0,6.0,18.0,12.0,14.0,4.0,13.0,12.0,16.0,6.0,12.0,4.0,15.0,14.0,15.0,13.0,15.0,9.0,15.0,11.0,12.0,13.0,9.0,11.0,13.0,9.0,15.0,12.0,12.0,15.0,15.0,16.0,16.0,16.0,19.0,15.0,9.0,3.0,14.0,16.0,8.0,7.0,16.0,11.0,15.0,11.0,9.0,13.0,6.0,15.0,12.0,10.0,15.0,5.0,13.0,16.0,5.0,12.0,9.0,12.0,12.0,12.0,13.0,16.0,13.0,16.0,3.0,12.0,13.0,7.0,6.0,15.0,3.0,15.0,6.0,15.0,14.0,15.0,9.0,9.0,15.0,12.0,8.0,15.0,13.0,11.0,9.0,16.0,12.0,9.0,12.0,12.0,13.0,15.0,11.0,4.0,15.0,15.0,15.0,3.0,15.0,12.0,12.0,14.0,11.0,12.0,14.0,11.0,15.0,15.0,15.0,15.0,14.0,9.0,12.0,15.0,11.0,15.0,6.0,12.0,6.0,7.0,13.0,12.0,16.0,9.0,11.0,3.0,16.0,13.0,6.0,15.0,15.0,9.0,6.0,15.0,15.0,15.0,3.0,15.0,9.0,11.0,11.0,15.0,15.0,16.0,15.0,16.0,16.0,12.0,16.0,12.0,12.0,4.0,16.0,8.0,7.0,8.0,16.0,15.0,3.0,12.0,6.0,15.0,15.0,12.0,15.0,13.0,16.0,12.0,17.0,12.0,14.0,11.0,15.0,13.0,5.0,15.0,12.0,8.0,3.0,9.0,9.0,15.0,14.0,14.0,15.0,9.0,14.0,14.0,9.0,13.0,10.0,14.0,6.0,15.0,14.0,14.0,12.0,9.0,14.0,13.0,4.0,12.0,7.0,16.0,15.0,14.0,17.0,16.0,12.0,16.0,11.0,6.0,12.0,15.0,18.0,12.0,9.0,12.0,13.0,16.0,8.0,11.0,12.0,15.0,12.0,15.0,12.0,6.0,12.0,15.0,15.0,12.0,15.0,15.0,12.0,15.0,9.0,13.0,16.0,16.0,12.0,13.0,16.0,9.0,12.0,12.0,15.0,12.0,12.0,13.0,12.0,16.0,7.0,12.0,12.0,9.0,12.0,15.0,12.0,13.0,9.0,16.0,16.0,16.0,16.0,15.0,12.0,15.0,9.0,12.0,13.0,15.0,15.0,6.0,6.0,16.0,12.0,14.0,15.0,6.0,12.0,15.0,15.0,15.0,13.0,15.0,3.0,9.0,13.0,15.0,15.0,15.0,15.0,17.0,13.0,16.0,10.0,15.0,12.0,15.0,12.0,15.0,15.0,12.0,12.0,17.0,16.0,15.0,15.0,17.0,12.0,7.0,16.0,12.0,13.0,9.0,13.0,10.0,12.0,13.0,3.0,12.0,12.0,15.0,13.0,12.0,12.0,12.0,14.0,14.0,6.0,11.0,11.0,16.0,15.0,12.0,13.0,16.0,6.0,12.0,12.0,12.0,16.0,17.0,13.0,12.0,13.0,12.0,15.0,15.0,17.0,13.0,12.0,13.0,10.0,12.0,2.0,6.0,12.0,12.0,7.0,12.0,8.0,16.0,18.0,15.0,12.0,12.0,15.0,13.0,12.0,15.0,15.0,11.0,3.0,12.0,15.0,15.0,12.0,3.0,10.0,15.0,7.0,13.0,6.0,12.0,11.0,16.0,6.0,12.0,13.0,15.0,9.0,12.0,10.0,16.0,10.0,15.0,13.0,11.0,12.0,12.0,14.0,15.0,16.0,13.0,13.0,12.0,0.0,9.0,16.0,15.0,17.0,6.0,14.0,15.0,14.0,9.0,12.0,6.0,12.0,13.0,9.0,12.0,15.0,11.0,11.0,12.0,9.0,16.0,11.0,11.0,17.0,13.0,15.0,15.0,14.0,6.0,8.0,14.0,16.0,9.0,16.0,3.0,15.0,15.0,14.0,16.0,9.0,11.0,13.0,3.0,12.0,12.0,14.0,13.0,15.0,10.0,9.0,9.0,9.0,4.0,15.0,9.0,16.0,6.0,15.0,14.0,15.0,12.0,12.0,12.0,13.0,12.0,15.0,12.0,13.0,9.0,15.0,14.0,15.0,7.0,6.0,14.0,12.0,11.0,15.0,11.0,6.0,9.0,15.0,14.0,15.0,13.0,13.0,13.0,15.0,17.0,3.0,16.0,13.0,9.0,13.0,13.0,12.0,1.0,9.0,10.0,16.0,6.0,12.0,9.0,17.0,15.0,9.0,16.0,12.0,15.0,12.0,11.0,14.0,15.0,16.0,0.0,12.0,12.0,13.0,12.0,13.0,15.0,13.0,9.0,1.0,3.0,12.0,14.0,14.0,16.0,15.0,15.0,13.0,15.0,15.0,15.0,9.0,14.0,5.0,17.0,4.0,15.0,16.0,17.0,9.0,13.0,15.0,11.0,13.0,16.0,15.0,15.0,16.0,15.0,16.0,15.0,15.0,15.0,13.0,14.0,12.0,14.0,13.0,12.0,15.0,17.0,15.0,10.0,7.0,16.0,15.0,9.0,15.0,16.0,11.0,16.0,8.0,14.0,12.0,9.0,12.0,16.0,15.0,15.0,12.0,12.0,9.0,16.0,13.0,15.0,16.0,13.0,14.0,10.0,16.0,12.0,14.0,12.0,12.0,12.0,6.0,15.0,16.0,18.0,12.0,15.0,13.0,0.0,15.0,15.0,15.0,16.0,15.0,8.0,7.0,12.0,14.0,12.0,12.0,12.0,9.0,15.0,6.0,12.0,16.0,15.0,13.0,16.0,15.0,9.0,12.0,13.0,15.0,12.0,13.0,13.0,6.0,12.0,15.0,13.0,9.0,11.0,14.0,9.0,12.0,6.0,15.0,0.0,13.0,15.0,12.0,6.0,14.0,15.0,15.0,3.0,11.0,12.0,12.0,14.0,15.0,15.0,12.0,12.0,12.0,13.0,9.0,15.0,11.0,12.0,15.0,11.0,14.0,12.0,15.0,9.0,9.0,13.0,14.0,9.0,15.0,12.0,16.0,12.0,13.0,15.0,13.0,14.0,14.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,9.0,16.0,9.0,11.0,14.0,14.0,13.0,14.0,18.0,16.0,6.0,16.0,16.0,15.0,15.0,9.0,12.0,17.0,12.0,13.0,16.0,12.0,15.0,9.0,12.0,14.0,12.0,12.0,17.0,12.0,12.0,14.0,15.0,13.0,3.0,15.0,14.0,13.0,12.0,12.0,9.0,14.0,12.0,6.0,12.0,12.0,11.0,15.0,6.0,12.0,12.0,3.0,15.0,12.0,16.0,17.0,6.0,15.0,13.0,6.0,12.0,13.0,15.0,15.0,6.0,15.0,12.0,9.0,12.0,12.0,12.0,15.0,12.0,16.0,11.0,9.0,14.0,11.0,14.0,13.0,9.0,15.0,6.0,6.0,9.0,3.0,3.0,9.0,16.0,12.0,14.0,12.0,10.0,9.0,11.0,12.0,12.0,9.0,15.0,15.0,15.0,15.0,13.0,12.0,15.0,12.0,15.0,6.0,10.0,14.0,12.0,6.0,15.0,17.0,12.0,3.0,15.0,12.0,12.0,16.0,6.0,15.0,12.0,9.0,11.0,6.0,9.0,13.0,14.0,15.0,6.0,15.0,16.0,15.0,9.0,12.0,6.0,15.0,15.0,13.0,12.0,15.0,15.0,16.0,4.0,12.0,15.0,9.0,7.0,15.0,15.0,3.0,14.0,15.0,2.0,9.0,8.0,13.0,13.0,15.0,10.0,11.0,9.0,6.0,11.0,14.0,16.0,7.0,12.0,13.0,17.0,15.0,16.0,16.0,9.0,12.0,8.0,12.0,0.0,16.0,4.0,14.0,0.0,12.0,13.0,15.0,13.0,12.0,15.0,15.0,9.0,15.0,12.0,13.0,12.0,13.0,12.0,14.0,11.0,9.0,12.0,15.0,16.0,12.0,15.0,10.0,12.0,11.0,7.0,11.0,12.0,11.0,11.0,11.0,6.0,9.0,14.0,9.0,9.0,13.0,11.0,13.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,3.0,10.0,14.0,15.0,15.0,9.0,16.0,11.0,15.0,6.0,12.0,13.0,6.0,13.0,8.0,12.0,15.0,11.0,12.0,6.0,12.0,13.0,15.0,13.0,15.0,6.0,16.0,16.0,15.0,6.0,9.0,9.0,15.0,13.0,0.0,9.0,15.0,15.0,15.0,0.0,10.0,12.0,13.0,12.0,13.0,13.0,9.0,15.0,15.0,11.0,15.0,15.0,9.0,0.0,15.0,15.0,11.0,12.0,18.0,6.0,12.0,16.0,13.0,15.0,15.0,13.0,9.0,15.0,0.0,15.0,16.0,6.0,12.0,15.0,11.0,15.0,12.0,15.0,13.0,9.0,15.0,12.0,14.0,6.0,11.0,13.0,6.0,15.0,6.0,10.0,15.0,13.0,14.0,15.0,14.0,12.0,13.0,15.0,15.0,6.0,13.0,7.0,13.0,12.0,12.0,15.0,13.0,15.0,12.0,9.0,15.0,6.0,16.0,13.0,13.0,15.0,15.0,14.0,12.0,12.0,13.0,16.0,8.0,14.0,7.0,15.0,7.0,10.0,15.0,13.0,14.0,15.0,15.0,10.0,12.0,16.0,16.0,13.0,15.0,14.0,12.0,9.0,12.0,14.0,15.0,11.0,12.0,15.0,18.0,12.0,12.0,9.0,11.0,11.0,7.0,15.0,12.0,16.0,15.0,10.0,9.0,0.0,12.0,8.0,10.0,12.0,15.0,13.0,12.0,16.0,13.0,15.0,0.0,12.0,16.0,6.0,16.0,13.0,11.0,15.0,15.0,16.0,16.0,12.0,3.0,12.0,10.0,4.0,12.0,15.0,14.0,12.0,7.0,13.0,12.0,8.0,0.0,10.0,15.0,15.0,12.0,12.0,16.0,9.0,3.0,12.0,6.0,9.0,13.0,13.0,15.0,9.0,6.0,14.0,16.0,16.0,13.0,12.0,16.0,5.0,3.0,17.0,14.0,13.0,16.0,9.0,15.0,3.0,15.0,12.0,7.0,13.0,12.0,15.0,17.0,11.0,12.0,15.0,14.0,12.0,13.0,11.0,13.0,6.0,9.0,9.0,8.0,16.0,16.0,13.0,14.0,3.0,9.0,11.0,10.0,10.0,9.0,12.0,9.0,15.0,17.0,15.0,16.0,12.0,9.0,12.0,12.0,11.0,12.0,17.0,15.0,15.0,12.0,15.0,11.0,13.0,16.0,11.0,15.0,16.0,16.0,17.0,18.0,14.0,15.0,15.0,12.0,15.0,10.0,12.0,15.0,9.0,11.0,15.0,13.0,9.0,13.0,6.0,12.0,14.0,15.0,16.0,5.0,3.0,13.0,9.0,16.0,16.0,9.0,6.0,9.0,13.0,13.0,0.0,16.0,9.0,12.0,15.0,11.0,13.0,9.0,12.0,11.0,6.0,13.0,7.0,12.0,15.0,13.0,12.0,12.0,15.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,0.0,14.0,15.0,9.0,14.0,13.0,11.0,12.0,17.0,13.0,12.0,10.0,15.0,10.0,13.0,15.0,15.0,0.0,15.0,12.0,9.0,12.0,14.0,9.0,9.0,14.0,7.0,13.0,14.0,14.0,13.0,6.0,3.0,9.0,5.0,12.0,17.0,15.0,3.0,17.0,9.0,12.0,14.0,15.0,12.0,15.0,12.0,12.0,14.0,11.0,9.0,11.0,16.0,11.0,15.0,12.0,14.0,13.0,5.0,12.0,14.0,3.0,16.0,15.0,16.0,15.0,11.0,12.0,13.0,15.0,13.0,13.0,12.0,13.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,7.0,13.0,11.0,15.0,10.0,13.0,12.0,9.0,16.0,10.0,16.0,16.0,7.0,12.0,3.0,13.0,6.0,14.0,12.0,6.0,16.0,13.0,15.0,15.0,18.0,13.0,15.0,13.0,12.0,15.0,14.0,15.0,13.0,15.0,7.0,9.0,13.0,12.0,15.0,13.0,15.0,9.0,14.0,10.0,6.0,15.0,14.0,9.0,3.0,13.0,16.0,14.0,4.0,14.0,12.0,12.0,15.0,13.0,14.0,15.0,15.0,15.0,12.0,3.0,3.0,16.0,16.0,12.0,3.0,15.0,13.0,12.0,14.0,14.0,15.0,18.0,12.0,15.0,12.0,12.0,12.0,13.0,15.0,12.0,12.0,12.0,15.0,12.0,14.0,13.0,9.0,4.0,15.0,10.0,15.0,13.0,13.0,12.0,7.0,11.0,6.0,9.0,12.0,13.0,8.0,13.0,15.0,12.0,3.0,12.0,12.0,12.0,14.0,12.0,7.0,7.0,12.0,12.0,16.0,9.0,10.0,15.0,18.0,10.0,13.0,13.0,15.0,9.0],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"SEM_3_STATUS=1<br>GPA_2=%{x}<br>UNITS_COMPLETED_2=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"showlegend\":true,\"x\":[3.333333333333333,0.0,1.0,1.3333333333333333,0.0,0.5,0.0,0.6,1.4,0.75,0.0,3.0,3.571428571428572,0.2666666666666666,1.5,2.333333333333333,1.0,2.6875,3.3846153846153846,0.4615384615384615,0.0,0.0,1.5,3.0,2.363636363636364,4.0,2.75,0.0,0.0,1.2857142857142858,2.727272727272727,1.3333333333333333,1.5,3.5,3.333333333333333,0.0,1.0,0.0,0.0,3.5384615384615383,0.0,3.0,1.8,2.8125,1.0,1.25,0.2222222222222222,0.0,3.230769230769231,3.5384615384615383,0.0,1.2,0.625,1.3333333333333333,0.0,0.0,2.8,0.0,1.1538461538461535,0.25,0.0,0.6,1.0833333333333333,1.0,1.5,1.0,0.25,4.0,1.0,0.25,4.0,0.2857142857142857,0.75,0.9,2.5,2.7,3.5,3.0,0.0,1.8,3.5,3.5,3.0,2.071428571428572,0.0,0.75,0.0,1.0,2.0,2.0,0.3076923076923077,2.9375,1.2857142857142858,4.0,3.6,0.4,0.0,0.4,1.0,0.0,1.5,2.6666666666666665,3.6666666666666665,1.375,0.0,0.0,4.0,0.0,0.0,0.0,0.5,4.0,2.5,0.3,0.0,4.0,0.2,0.0,3.5,3.8,0.4,1.6666666666666667,0.0,0.3333333333333333,1.75,0.0,1.3333333333333333,3.176470588235294,2.333333333333333,2.0,0.0,3.0,1.0,2.5,0.0,0.75,0.375,3.6666666666666665,0.75,0.1538461538461538,1.5,0.0,2.0,3.235294117647059,0.0,2.5,2.8666666666666667,1.7,1.1,0.0,3.5,2.4,0.0,4.0,2.25,3.769230769230769,2.6,4.0,0.2,1.3333333333333333,3.142857142857143,0.0,2.5,1.3333333333333333,0.0,1.0,1.4285714285714286,2.7142857142857144,0.6666666666666666,0.25,1.5,4.0,2.75,2.5,0.9375,0.0,0.0,3.2,3.2,0.0,0.1428571428571428,0.0,2.75,0.0,1.6666666666666667,3.25,3.5,3.0,1.25,0.0,0.5,0.0,2.25,1.0,1.6,0.0,2.923076923076923,0.8571428571428571,4.0,0.75,3.0,2.4285714285714284,3.25,0.6666666666666666,2.1666666666666665,0.0,1.0,2.4615384615384617,3.75,4.0,0.0,0.4,2.6,0.8,1.0,1.0,2.4375,1.375,2.0,3.764705882352941,2.0,0.0,3.111111111111111,3.6666666666666665,3.5,2.8461538461538463,1.3333333333333333,0.75,0.0,0.0,0.0,1.0,1.25,2.75,2.0,1.3333333333333333,3.363636363636364,0.0,0.0,3.25,2.0,0.8888888888888888,0.8181818181818182,1.5,3.25,2.6,3.235294117647059,0.0,1.5,4.0,0.0,1.5,0.2142857142857142,0.75,3.071428571428572,0.5,0.0,3.1538461538461537,0.375,2.076923076923077,0.0,3.125,4.0,0.1875,0.6,3.25,3.230769230769231,4.0,0.2222222222222222,3.125,1.0,0.0,2.8,2.333333333333333,0.0,0.0,1.1111111111111112,2.0625,0.25,0.0,3.0,0.0,4.0,0.4,0.0,2.571428571428572,0.1333333333333333,3.769230769230769,0.0,3.0,1.0,2.0,0.0,4.0,0.8,4.0,1.5,4.0,3.75,1.9375,3.333333333333333,1.0,3.5,2.5454545454545454,2.0,3.6,2.5,0.0,3.0,0.3,3.333333333333333,0.0,0.0,0.0,0.0,1.25,1.5,3.4,0.5,2.2857142857142856,0.0,0.0,0.0,3.2,0.4615384615384615,0.3846153846153846,2.0,3.071428571428572,4.0,1.3333333333333333,2.8181818181818183,2.588235294117647,2.0,0.6,1.5714285714285714,1.6666666666666667,0.0],\"xaxis\":\"x\",\"y\":[18.0,0.0,3.0,6.0,0.0,3.0,0.0,3.0,6.0,3.0,0.0,6.0,14.0,0.0,6.0,9.0,4.0,13.0,13.0,3.0,0.0,0.0,6.0,6.0,6.0,12.0,12.0,0.0,0.0,7.0,11.0,6.0,3.0,12.0,9.0,0.0,3.0,0.0,0.0,13.0,0.0,3.0,9.0,16.0,3.0,6.0,0.0,0.0,13.0,13.0,0.0,3.0,2.0,6.0,0.0,0.0,15.0,0.0,6.0,0.0,0.0,3.0,4.0,0.0,9.0,3.0,0.0,1.0,3.0,0.0,13.0,1.0,3.0,4.0,9.0,10.0,12.0,9.0,0.0,9.0,12.0,6.0,12.0,9.0,0.0,3.0,0.0,3.0,6.0,3.0,1.0,16.0,6.0,16.0,15.0,3.0,0.0,3.0,6.0,0.0,6.0,9.0,9.0,3.0,0.0,0.0,16.0,0.0,0.0,0.0,0.0,6.0,6.0,1.0,0.0,12.0,0.0,0.0,12.0,15.0,3.0,3.0,0.0,0.0,9.0,0.0,9.0,17.0,9.0,3.0,0.0,6.0,3.0,8.0,0.0,3.0,0.0,18.0,3.0,1.0,5.0,0.0,3.0,17.0,0.0,6.0,12.0,7.0,4.0,0.0,16.0,12.0,0.0,15.0,9.0,13.0,15.0,12.0,0.0,6.0,14.0,0.0,12.0,3.0,0.0,3.0,6.0,9.0,3.0,0.0,3.0,12.0,16.0,12.0,6.0,0.0,0.0,15.0,15.0,0.0,1.0,0.0,12.0,0.0,6.0,12.0,12.0,3.0,6.0,0.0,3.0,0.0,5.0,3.0,9.0,0.0,13.0,2.0,16.0,3.0,6.0,7.0,13.0,3.0,18.0,0.0,3.0,13.0,12.0,12.0,0.0,3.0,12.0,4.0,3.0,0.0,13.0,6.0,3.0,17.0,6.0,0.0,9.0,9.0,12.0,13.0,6.0,2.0,0.0,0.0,0.0,3.0,1.0,12.0,5.0,3.0,11.0,0.0,0.0,12.0,9.0,1.0,3.0,3.0,12.0,15.0,17.0,0.0,6.0,15.0,0.0,3.0,0.0,3.0,14.0,3.0,0.0,13.0,3.0,9.0,0.0,16.0,14.0,0.0,4.0,12.0,10.0,11.0,1.0,8.0,3.0,0.0,15.0,6.0,0.0,0.0,4.0,11.0,0.0,0.0,11.0,0.0,15.0,0.0,0.0,9.0,1.0,13.0,0.0,6.0,6.0,3.0,0.0,12.0,3.0,12.0,6.0,14.0,12.0,12.0,9.0,3.0,12.0,11.0,1.0,15.0,6.0,0.0,9.0,0.0,9.0,0.0,0.0,0.0,0.0,6.0,6.0,15.0,2.0,10.0,0.0,0.0,0.0,4.0,3.0,1.0,6.0,14.0,6.0,4.0,11.0,17.0,3.0,3.0,5.0,6.0,0.0],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"GPA_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UNITS_COMPLETED_2\"}},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\")) {                    Plotly.newPlot(                        \"e5f8bcd3-b4f8-4ad9-8ddf-3be5afe6be74\",                        [{\"hovertemplate\":\"SEM_3_STATUS=0<br>GPA_2=%{x}<br>UNITS_COMPLETED_2=%{y}<extra></extra>\",\"legendgroup\":\"0\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"0\",\"showlegend\":true,\"x\":[1.6666666666666667,3.6875,1.6923076923076923,4.0,1.5,2.75,2.071428571428572,4.0,2.25,4.0,2.25,2.75,4.0,3.1,3.5384615384615383,3.0,3.25,4.0,4.0,2.4,2.6,3.5384615384615383,3.333333333333333,4.0,2.4375,3.0,2.6923076923076925,3.5,3.8,3.333333333333333,3.5625,2.625,1.0,3.8,2.933333333333333,2.6666666666666665,2.6,4.0,3.5384615384615383,3.6,3.769230769230769,4.0,2.1333333333333333,1.5454545454545454,2.8,3.125,3.0,4.0,3.7142857142857135,4.0,3.4285714285714284,3.75,2.1333333333333333,2.7142857142857144,3.0,3.8,3.5384615384615383,4.0,3.4,3.5,4.0,4.0,2.4615384615384617,3.75,4.0,2.6,2.6,2.125,3.769230769230769,1.8,4.0,3.8,3.5,2.6923076923076925,2.0,2.0,4.0,3.5,3.733333333333333,3.5,4.0,4.0,4.0,4.0,3.733333333333333,3.3125,3.076923076923077,1.0,3.4,0.3333333333333333,2.4,4.0,2.9166666666666665,3.8125,2.25,4.0,2.3846153846153846,3.5,4.0,3.0,3.230769230769231,3.25,4.0,3.0,4.0,2.6875,3.272727272727273,4.0,4.0,2.6666666666666665,2.5,3.5,2.5454545454545454,3.1578947368421053,2.6666666666666665,3.1666666666666665,3.0,4.0,3.8,3.8125,3.533333333333333,3.1818181818181817,2.0,3.466666666666667,4.0,3.1875,4.0,3.647058823529412,2.5,3.4,3.333333333333333,3.692307692307693,2.0,4.0,3.8125,3.2,3.625,3.0,3.3076923076923075,1.0,4.0,3.0,2.923076923076923,2.363636363636364,4.0,2.8125,2.4,2.466666666666667,3.5,2.75,4.0,1.25,3.0,3.4,3.7,3.769230769230769,2.333333333333333,3.5,2.8,3.5384615384615383,3.4,3.0,4.0,4.0,3.375,3.4615384615384617,3.2,3.333333333333333,2.3125,0.2857142857142857,3.25,3.4615384615384617,3.2,1.1666666666666667,2.4166666666666665,3.5384615384615383,2.75,3.25,3.733333333333333,4.0,3.533333333333333,2.0,2.2,2.5,4.0,3.4,3.6,2.6923076923076925,0.0,3.6666666666666665,2.0,3.6666666666666665,3.75,3.2,2.6666666666666665,3.625,1.8571428571428568,3.25,4.0,3.5625,3.75,3.6,2.0,2.8461538461538463,2.75,3.25,3.0,2.6923076923076925,3.5384615384615383,3.0625,3.4375,3.4,2.6,1.6923076923076923,2.25,3.4,3.272727272727273,3.25,2.8,3.5384615384615383,2.7857142857142856,3.2857142857142856,2.1538461538461537,3.7142857142857135,3.5454545454545454,1.5555555555555556,1.5,3.4,3.6,4.0,2.25,3.6666666666666665,3.2857142857142856,2.75,4.0,4.0,4.0,3.727272727272727,3.75,3.769230769230769,3.25,3.7142857142857135,3.0,0.0,3.615384615384616,3.8,3.2,3.117647058823529,4.0,2.8,4.0,2.75,4.0,3.769230769230769,2.5,3.933333333333333,2.25,1.8,4.0,2.9285714285714284,3.8125,4.0,3.6,3.5384615384615383,3.230769230769231,4.0,1.8,3.066666666666667,0.5,3.0,2.1538461538461537,2.0,3.75,3.071428571428572,3.5,2.833333333333333,3.4615384615384617,3.9375,3.6666666666666665,3.1538461538461537,3.8,3.2,2.5,3.625,2.090909090909091,4.0,3.3076923076923075,4.0,2.0,2.0,3.588235294117647,3.6,3.0,3.0,3.3846153846153846,3.25,4.0,4.0,0.0,3.5625,2.4615384615384617,3.692307692307693,3.769230769230769,3.333333333333333,2.6,3.6,0.6428571428571429,3.583333333333333,3.6666666666666665,3.066666666666667,3.75,0.5,3.5,2.6923076923076925,3.1538461538461537,2.8461538461538463,3.1538461538461537,4.0,3.5454545454545454,3.733333333333333,3.2,4.0,2.5,4.0,2.5,3.625,2.0,3.8,3.25,3.6,3.75,4.0,4.0,3.4615384615384617,1.181818181818182,3.0,3.3125,3.0,3.375,3.0,2.642857142857143,3.0,2.0,4.0,2.5,2.909090909090909,3.333333333333333,2.0,4.0,4.0,3.0,2.75,3.357142857142857,3.8,2.2,2.6,4.0,3.0,1.5833333333333333,2.571428571428572,3.75,2.857142857142857,3.4,2.4,3.066666666666667,0.0,3.727272727272727,2.25,4.0,3.4166666666666665,3.769230769230769,4.0,1.3333333333333333,3.333333333333333,4.0,2.6,2.9375,3.5384615384615383,3.4615384615384617,1.6666666666666667,3.6,4.0,2.4,0.0,4.0,3.2,2.625,3.1538461538461537,2.2,3.8125,2.5,4.0,3.333333333333333,4.0,3.0,3.0625,3.0,4.0,1.3846153846153846,3.8,3.4375,2.5,3.0,3.8,3.0,3.0,3.3846153846153846,4.0,2.583333333333333,4.0,4.0,2.5,4.0,3.0,3.333333333333333,2.4285714285714284,3.2666666666666666,2.230769230769231,3.5454545454545454,4.0,4.0,3.3846153846153846,4.0,0.25,3.076923076923077,4.0,4.0,2.7142857142857144,3.533333333333333,3.3846153846153846,3.0,3.625,1.5625,3.5,3.357142857142857,3.25,2.857142857142857,3.75,3.0625,3.0,3.692307692307693,3.6,2.75,2.2,2.0,4.0,4.0,3.0,3.692307692307693,4.0,2.0,3.75,1.0,3.6,2.6666666666666665,3.5454545454545454,3.25,2.8,3.6666666666666665,2.5384615384615383,2.0,2.75,3.0,3.25,2.2,3.2,1.6,3.0,2.0,3.272727272727273,3.066666666666667,3.6875,3.1538461538461537,3.6,2.2142857142857144,3.1666666666666665,3.375,3.5625,1.4285714285714286,3.2666666666666666,4.0,2.0,1.0,4.0,3.1333333333333333,3.4,3.25,3.75,3.5,3.25,2.7857142857142856,3.8,3.6,3.727272727272727,2.4615384615384617,4.0,1.9166666666666667,2.5,3.0,2.8181818181818183,3.4,3.2,3.0,2.230769230769231,3.5,4.0,3.6,3.4,3.3076923076923075,3.2,2.923076923076923,2.75,4.0,1.5,3.0,3.625,3.5,4.0,3.0,4.0,3.5,4.0,2.8,1.4285714285714286,4.0,3.692307692307693,2.5,2.8,3.25,3.0,2.8,4.0,2.0,2.0,3.4,3.8,3.8333333333333335,1.9230769230769231,2.7058823529411766,3.117647058823529,3.3076923076923075,0.5384615384615384,4.0,1.4285714285714286,3.4,2.0,0.2,4.0,3.2,4.0,3.8125,3.6,4.0,3.8,4.0,1.8,3.076923076923077,1.0,3.0,3.8125,2.5,3.8,3.5,3.375,3.6,3.0,1.9090909090909087,1.6,3.2857142857142856,3.625,3.2666666666666666,3.0,3.4615384615384617,2.0,2.5,2.0,4.0,2.4,3.0,2.4615384615384617,3.4615384615384617,3.5,3.0,3.4,2.8666666666666667,0.6,1.3333333333333333,3.4615384615384617,3.1666666666666665,3.5,3.0,3.333333333333333,2.8461538461538463,3.0,3.5,4.0,2.0,3.8,2.5,3.2,2.4615384615384617,3.8,4.0,3.25,1.3333333333333333,3.3076923076923075,3.0,3.6666666666666665,3.8,3.25,3.0,3.8,3.7857142857142856,2.8181818181818183,3.8,3.071428571428572,3.0,1.9,3.0,3.25,2.6,4.0,3.533333333333333,3.2,3.8333333333333335,3.733333333333333,2.0625,3.5384615384615383,2.75,3.5,3.8,3.5,1.25,3.8,3.75,2.9166666666666665,4.0,3.8,3.2,2.6,3.0,0.1875,4.0,2.0,3.2,3.588235294117647,1.6666666666666667,4.0,4.0,3.5,2.272727272727273,3.4,3.7777777777777777,3.083333333333333,1.6153846153846154,3.8125,3.6,3.8125,3.333333333333333,2.333333333333333,2.25,1.0666666666666669,0.8,3.1875,3.75,3.5,3.615384615384616,0.0,3.75,3.1538461538461537,3.692307692307693,3.3846153846153846,1.9230769230769231,2.5,2.4,3.6666666666666665,3.0,3.692307692307693,2.25,2.6,2.8125,3.1666666666666665,3.066666666666667,3.0,3.75,3.75,4.0,3.8125,4.0,2.8461538461538463,2.4,2.6,3.5,4.0,0.0,3.2,1.6666666666666667,3.692307692307693,3.75,3.8,4.0,3.75,2.4615384615384617,3.1875,2.333333333333333,3.625,3.8,3.727272727272727,1.9285714285714288,3.1666666666666665,3.4,4.0,2.75,3.0,2.076923076923077,2.6666666666666665,3.230769230769231,2.647058823529412,4.0,3.25,1.5,3.333333333333333,3.2222222222222223,3.1538461538461537,3.923076923076923,4.0,2.25,2.1333333333333333,4.0,3.75,3.333333333333333,3.0,3.6,3.0,4.0,3.25,2.4375,3.0,3.75,2.5,3.5625,3.4,2.5,3.0625,1.6666666666666667,3.230769230769231,3.75,4.0,3.0,4.0,3.0,3.6,2.4,3.1875,4.0,3.75,1.6,2.75,3.8,4.0,3.2,3.5,3.4705882352941178,3.25,3.230769230769231,1.8,2.4,2.75,1.7272727272727273,4.0,3.1875,2.4,2.75,3.75,3.071428571428572,2.5,3.4,3.375,3.5,4.0,2.176470588235294,3.2142857142857144,4.0,3.6,4.0,1.4615384615384617,2.25,3.7857142857142856,3.0,3.769230769230769,4.0,1.9333333333333331,3.2,4.0,4.0,4.0,1.9166666666666667,3.5,2.5625,3.6666666666666665,3.571428571428572,3.0625,4.0,2.071428571428572,3.8,3.0,2.9166666666666665,2.8461538461538463,3.7142857142857135,2.5,4.0,2.6153846153846154,2.0,4.0,3.1875,2.5,3.2666666666666666,3.75,4.0,3.0,2.6,3.5,4.0,3.4375,3.4,3.5625,2.357142857142857,1.3076923076923077,3.6666666666666665,3.2,3.75,1.6666666666666667,2.0,2.75,3.6,4.0,2.923076923076923,3.4615384615384617,2.2,2.8,2.571428571428572,2.0,3.0,3.333333333333333,2.8666666666666667,1.8,3.8,3.8,3.6,3.0,0.0,3.4166666666666665,3.8125,3.25,4.0,2.571428571428572,3.0,3.0,2.125,1.6363636363636365,2.0,2.0,3.0,2.066666666666667,3.6,0.0,3.333333333333333,1.4,2.75,4.0,0.0,2.8,4.0,2.230769230769231,3.6,3.6666666666666665,3.25,3.0,2.0,2.8,3.764705882352941,4.0,3.2,3.0,3.0,3.0,2.0,3.75,2.75,4.0,1.6,3.571428571428572,3.6,4.0,3.6,2.5,2.4615384615384617,3.727272727272727,4.0,2.25,3.8,4.0,3.5,4.0,4.0,2.230769230769231,3.8,4.0,3.8,2.933333333333333,3.75,3.4166666666666665,2.923076923076923,3.6,2.6666666666666665,3.6,4.0,2.357142857142857,4.0,3.2,2.8,4.0,2.7333333333333334,3.2,2.8,4.0,3.230769230769231,3.25,2.5,2.0,1.6153846153846154,4.0,3.1333333333333333,4.0,1.4545454545454546,3.75,3.625,2.75,4.0,3.2142857142857144,2.4,3.692307692307693,3.230769230769231,3.0,4.0,2.75,3.5,3.7058823529411766,4.0,2.1666666666666665,3.0,3.6666666666666665,4.0,3.0,3.4705882352941178,3.0,3.75,1.75,4.0,2.230769230769231,3.75,3.4,2.0,3.272727272727273,3.5625,2.8,0.1666666666666666,3.8125,3.8125,1.8,3.1,2.75,3.0,0.0,3.8,2.4,3.142857142857143,2.923076923076923,2.875,2.769230769230769,3.692307692307693,3.4545454545454546,3.0,3.1538461538461537,3.692307692307693,2.8181818181818183,2.75,3.625,3.25,3.6666666666666665,1.9411764705882355,4.0,1.9090909090909087,3.692307692307693,3.625,2.75,3.571428571428572,2.75,2.75,1.0,2.0,3.75,4.0,2.272727272727273,2.75,3.2142857142857144,3.6666666666666665,3.6,3.4,4.0,2.769230769230769,3.25,3.5,3.0,2.6153846153846154,1.75,1.6666666666666667,3.4615384615384617,3.5384615384615383,3.272727272727273,3.5384615384615383,3.3529411764705883,2.6,1.3888888888888888,4.0,3.625,3.7777777777777777,4.0,3.0,3.571428571428572,3.25,2.0,4.0,3.0,4.0,3.0,4.0,3.272727272727273,3.5454545454545454,2.357142857142857,4.0,4.0,3.230769230769231,3.555555555555556,3.7857142857142856,4.0,4.0,3.333333333333333,4.0,3.3125,2.6,1.2857142857142858,2.2142857142857144,2.5,2.4285714285714284,3.6,3.1538461538461537,1.25,2.4615384615384617,3.6666666666666665,3.625,3.6,3.5,3.25,2.5,3.333333333333333,2.8,3.8,4.0,4.0,2.8461538461538463,3.8125,3.230769230769231,3.75,3.571428571428572,3.6666666666666665,3.5384615384615383,3.8,1.2352941176470589,3.2,2.75,3.6666666666666665,0.0,3.4,3.6666666666666665,3.769230769230769,3.75,4.0,3.75,2.8181818181818183,3.2142857142857144,3.0,3.75,3.8,2.272727272727273,4.0,2.7142857142857144,3.25,3.176470588235294,3.769230769230769,4.0,3.230769230769231,3.333333333333333,2.5,3.5,3.357142857142857,3.692307692307693,3.0,3.5,3.1875,2.7,3.0,3.75,3.2,3.6666666666666665,2.25,3.4375,3.5,3.6666666666666665,3.6,2.6,2.4615384615384617,3.571428571428572,2.8,3.2,2.8,3.0,2.2142857142857144,2.0,2.1818181818181817,2.25,3.2,4.0,4.0,0.4615384615384615,4.0,1.6666666666666667,3.6,3.5454545454545454,3.1666666666666665,2.25,3.75,1.5,0.4615384615384615,3.2,3.642857142857143,4.0,2.6,3.4,2.4615384615384617,3.2857142857142856,3.076923076923077,2.8,2.4615384615384617,3.2,3.333333333333333,2.3125,2.2857142857142856,3.75,3.4,3.6,0.6153846153846154,3.0,3.6666666666666665,4.0,3.2857142857142856,4.0,3.625,3.4,3.2777777777777777,4.0,1.5,4.0,1.3076923076923077,4.0,3.2,3.8,4.0,4.0,3.0,4.0,2.7777777777777777,3.6,3.5,3.8,2.8,3.2,3.066666666666667,2.1333333333333333,4.0,2.4615384615384617,3.75,4.0,1.75,3.5,2.375,2.875,3.0,3.0,3.2,0.9375,3.6666666666666665,4.0,3.6,3.2,3.0,3.642857142857143,4.0,2.4615384615384617,3.5384615384615383,4.0,4.0,3.1538461538461537,3.0,4.0,4.0,2.533333333333333,3.75,4.0,3.3076923076923075,0.8,3.230769230769231,3.4375,4.0,2.6,2.0,4.0,3.0,3.2142857142857144,3.071428571428572,3.6,3.4,3.6,0.6666666666666666,4.0,3.1538461538461537,2.4,1.4,0.375,3.769230769230769,4.0,3.5625,4.0,2.4,2.25,3.6,4.0,2.8,2.363636363636364,4.0,4.0,3.8125,3.769230769230769,3.8125,2.7333333333333334,1.8,3.5,2.7333333333333334,2.7333333333333334,2.5384615384615383,1.3636363636363635,3.4545454545454546,2.8,3.25,4.0,2.6153846153846154,3.5,1.8,3.25,2.8,4.0,3.357142857142857,3.0,3.5625,3.357142857142857,1.25,3.6666666666666665,1.5,2.75,4.0,4.0,3.8,4.0,1.3,2.5454545454545454,2.0,4.0,3.75,1.6153846153846154,3.5384615384615383,3.2,3.769230769230769,3.0,3.8125,4.0,4.0,3.25,3.6666666666666665,3.8,3.0,2.6153846153846154,1.8,3.8,2.75,3.75,3.6,2.0,1.6,3.5,3.923076923076923,3.230769230769231,3.909090909090909,4.0,3.8,4.0,3.0,3.4,3.230769230769231,3.5625,4.0,3.2,0.0,0.2,4.0,4.0,3.2,2.4615384615384617,3.2,1.9230769230769231,0.4285714285714285,2.0,2.1666666666666665,3.0,3.8125,3.4,3.25,3.6666666666666665,3.5,4.0,3.5,2.727272727272727,2.727272727272727,0.3333333333333333,4.0,3.571428571428572,0.6153846153846154,3.6,3.0,2.8,3.0,3.0,3.0,3.533333333333333,2.75,3.5,1.75,3.0,4.0,3.5,3.533333333333333,1.6,3.8,4.0,3.5,3.4,3.642857142857143,2.6153846153846154,4.0,3.625,3.0625,2.6923076923076925,3.5,3.75,3.6,4.0,2.769230769230769,3.692307692307693,2.8,2.5,2.5,3.8,2.8,2.25,3.615384615384616,3.5,3.8,3.066666666666667,3.642857142857143,2.0,3.25,2.8461538461538463,1.9230769230769231,4.0,3.5,3.5625,2.25,3.5454545454545454,3.6,2.466666666666667,3.636363636363636,3.4,3.0,3.571428571428572,3.0,2.1538461538461537,3.8,3.625,2.75,3.75,2.2142857142857144,0.8,3.0,3.235294117647059,2.6,3.2,4.0,4.0,2.75,3.25,3.75,2.4615384615384617,3.4,4.0,3.75,2.5454545454545454,3.5454545454545454,3.5,3.2,2.1875,3.230769230769231,4.0,3.6666666666666665,4.0,2.625,2.2857142857142856,3.6,2.7857142857142856,3.0,3.692307692307693,4.0,3.4,3.0625,3.4,3.6,3.25,1.75,3.4,2.6923076923076925,3.25,2.6153846153846154,4.0,1.2142857142857142,2.230769230769231,3.090909090909091,3.2,4.0,4.0,2.75,3.642857142857143,2.5625,3.117647058823529,3.2,4.0,3.5,2.9375,4.0,1.0666666666666669,2.8,3.7142857142857135,4.0,3.0625,2.555555555555556,4.0,3.230769230769231,2.2142857142857144,3.4375,4.0,1.5,2.6,3.8125,3.0,3.0,3.0,3.4,2.8,2.8461538461538463,3.2857142857142856,1.75,3.2,2.6875,3.8,2.4285714285714284,3.6,3.4,3.5,3.823529411764706,3.5625,2.6,3.642857142857143,3.4166666666666665,3.0,3.5,3.090909090909091,2.5,3.066666666666667,3.0,3.466666666666667,2.1538461538461537,2.9285714285714284,4.0,1.8,3.0,3.375,3.2,2.8,4.0,1.4,2.0,4.0,3.75,2.8461538461538463,1.6666666666666667,2.5,0.0,3.466666666666667,3.636363636363636,3.25,3.7142857142857135,4.0,3.0,3.333333333333333,3.2,3.8125,3.6875,1.8,4.0,3.2666666666666666,3.8,3.6,2.857142857142857,4.0,4.0,3.75,1.4545454545454546,3.8,3.6,3.8125,3.6,2.5,3.4,2.8181818181818183,1.6,3.75,2.333333333333333,3.75,3.6666666666666665,2.0,2.4166666666666665,3.6,4.0,4.0,2.875,4.0,3.142857142857143,2.75,2.6,2.375,3.3,3.8125,3.6,2.571428571428572,3.0625,3.636363636363636,2.5,4.0,3.2666666666666666,3.8,3.2,3.8,2.0,3.5,3.25,4.0,2.7857142857142856,4.0,3.8,2.9166666666666665,2.75,3.4615384615384617,2.5,4.0,2.9375,4.0,3.0,4.0,2.3846153846153846,1.8461538461538465,2.0625,2.5,3.0,2.7,3.25,3.625,3.6666666666666665,2.0625,3.4,3.25,3.1666666666666665,3.6,3.0,1.5,4.0,3.4615384615384617,3.125,3.375,3.8125,2.6153846153846154,2.0625,3.6666666666666665,3.4,4.0,1.0,1.75,4.0,4.0,4.0,3.5,2.75,4.0,4.0,3.0,4.0,2.923076923076923,3.333333333333333,3.625,3.5,4.0,2.4,4.0,4.0,3.0,1.6875,3.5625,3.642857142857143,3.4,4.0,2.5,1.6,1.3076923076923077,4.0,3.733333333333333,3.4615384615384617,2.4,3.8125,3.5625,3.375,3.4,3.733333333333333,4.0,3.25,3.142857142857143,4.0,4.0,3.8,3.4545454545454546,3.25,2.4,2.7,3.5384615384615383,3.5,3.8125,3.235294117647059,3.75,1.2,3.647058823529412,3.5,2.3076923076923075,2.8666666666666667,3.6,0.75,3.0625,2.75,2.2222222222222223,4.0,3.6,3.0,3.625,4.0,3.0625,1.5,3.2142857142857144,4.0,2.4,3.2,0.0,3.5,3.0,1.1538461538461535,2.75,3.2142857142857144,2.4,3.3846153846153846,3.2,2.75,1.8,3.6,3.2,3.8125,2.5625,3.7857142857142856,0.9166666666666666,3.0,3.2142857142857144,2.6153846153846154,3.692307692307693,4.0,3.0,3.333333333333333,3.25,4.0,2.3076923076923075,3.8,3.25,3.125,2.75,2.9375,2.5,3.5,3.8125,3.0,4.0,2.4,3.75,3.4,4.0,3.3125,3.727272727272727,4.0,1.6666666666666667,3.333333333333333,2.75,3.8,2.75,2.0,3.2,3.0,2.857142857142857,3.8125,1.0,4.0,2.25,2.363636363636364,4.0,3.25,3.357142857142857,0.9333333333333332,2.769230769230769,3.75,4.0,1.4166666666666667,3.75,1.0,3.6,3.7142857142857135,4.0,3.615384615384616,3.8,2.333333333333333,3.4,3.090909090909091,3.75,2.6923076923076925,2.25,4.0,3.769230769230769,1.75,3.2,2.2,2.75,3.2,3.0,3.75,3.375,3.8125,3.526315789473684,3.533333333333333,4.0,2.0,3.7857142857142856,3.0,2.6666666666666665,2.0,4.0,3.272727272727273,2.888888888888889,3.090909090909091,3.0,4.0,1.25,3.8,3.0,2.8,4.0,2.2222222222222223,3.0,4.0,1.6923076923076923,4.0,3.0,3.5,3.75,2.75,4.0,4.0,3.615384615384616,3.0625,1.25,3.0,3.0,1.25,3.5,3.8,0.375,3.8,0.9333333333333332,3.6666666666666665,2.2142857142857144,3.2,2.8461538461538463,1.8,3.2,3.25,2.5,3.8,3.769230769230769,2.7142857142857144,1.75,4.0,2.75,3.0,3.75,3.25,3.4615384615384617,3.4,2.4285714285714284,1.5384615384615383,3.2,4.0,2.8,1.0,3.733333333333333,3.25,2.5,3.4285714285714284,3.0,3.4166666666666665,3.571428571428572,2.125,3.0,3.0,4.0,3.0,2.857142857142857,1.5,3.0,4.0,2.8181818181818183,3.8,2.1538461538461537,3.083333333333333,1.5,2.0,4.0,2.2,3.4375,2.5,3.5454545454545454,1.3333333333333333,3.75,4.0,1.6666666666666667,4.0,3.6,1.5,2.5,3.4,3.0,3.0,1.5,4.0,2.0,4.0,4.0,3.533333333333333,3.4,2.9375,3.4,4.0,4.0,4.0,3.8125,2.1333333333333333,3.0,1.2,2.9375,2.1818181818181817,2.25,2.375,3.0,3.533333333333333,1.0,2.75,1.25,3.6,3.2,2.75,4.0,2.1538461538461537,2.75,3.5,4.0,4.0,4.0,3.272727272727273,3.0,4.0,1.1333333333333333,3.0,3.75,2.8181818181818183,1.0,2.833333333333333,2.6666666666666665,3.4,3.4285714285714284,3.7142857142857135,3.8,4.0,2.9285714285714284,3.7142857142857135,2.75,4.0,2.923076923076923,2.4285714285714284,1.4,3.0,3.2857142857142856,3.142857142857143,2.25,3.6666666666666665,4.0,3.769230769230769,2.0,3.5,1.0769230769230769,4.0,4.0,2.7142857142857144,3.882352941176471,4.0,3.75,3.25,4.0,3.5,3.25,3.2,3.1666666666666665,3.5,2.6666666666666665,3.25,3.230769230769231,2.8125,3.5,3.090909090909091,3.25,3.0,3.5,3.6,2.5,2.2,3.75,3.6,3.0,3.5,3.4,2.8,2.75,3.2,2.333333333333333,3.1538461538461537,3.4375,3.1875,2.25,3.692307692307693,3.5,2.7142857142857144,3.0,3.5,3.4,2.25,4.0,3.076923076923077,2.833333333333333,3.4375,1.6153846153846154,2.9166666666666665,2.2,4.0,3.0,3.2,3.5,3.230769230769231,2.4444444444444446,4.0,4.0,3.5625,3.625,4.0,3.5,3.733333333333333,1.3846153846153846,3.083333333333333,3.3076923076923075,3.8,4.0,1.25,1.3333333333333333,2.5625,3.25,2.857142857142857,3.4,3.5,3.25,2.8,3.0,3.8,2.3076923076923075,4.0,0.8571428571428571,3.6666666666666665,3.076923076923077,3.4,4.0,2.533333333333333,2.6,3.0,3.769230769230769,3.375,3.6,4.0,2.75,2.2,4.0,3.6,3.8,2.6,3.5,3.3529411764705883,3.6875,3.6,4.0,4.0,3.5,1.6875,3.6875,2.5,3.923076923076923,4.0,3.769230769230769,3.7,4.0,2.8461538461538463,0.5,3.75,2.5,3.2,3.692307692307693,2.75,3.0,3.75,3.357142857142857,3.571428571428572,0.8,3.727272727272727,3.363636363636364,3.75,4.0,3.6666666666666665,4.0,3.3125,2.0,4.0,3.75,2.0,2.9375,2.764705882352941,3.1538461538461537,3.0,2.923076923076923,4.0,2.8,3.6,3.5294117647058822,4.0,1.9375,3.0,2.0,3.75,0.8235294117647058,2.0,3.0,4.0,3.4285714285714284,2.75,2.1666666666666665,2.5625,3.4444444444444446,3.1333333333333333,3.0,3.333333333333333,2.4,3.230769230769231,3.75,4.0,3.4,4.0,0.75,3.0,4.0,3.4,2.5,1.1666666666666667,2.2,2.7333333333333334,1.5384615384615383,4.0,1.4,3.4166666666666665,4.0,3.75,1.5,3.25,3.769230769230769,3.4,3.0,2.6,2.3076923076923075,3.5625,3.3,3.8,3.3076923076923075,3.5454545454545454,2.75,2.25,3.2142857142857144,3.6,3.8125,3.692307692307693,3.769230769230769,3.75,0.0,2.25,3.3125,3.6,4.0,2.5,3.5,3.4,3.642857142857143,2.6666666666666665,3.75,3.0,3.75,3.769230769230769,2.6666666666666665,2.4166666666666665,3.6,3.1818181818181817,3.5454545454545454,2.75,2.0,3.8125,4.0,3.727272727272727,3.0,3.5384615384615383,4.0,3.4,3.142857142857143,1.8,2.25,2.857142857142857,3.0625,2.083333333333333,3.375,1.5,3.6,3.2,3.0,3.625,1.75,3.090909090909091,3.769230769230769,3.0,2.1666666666666665,3.25,2.642857142857143,3.4615384615384617,3.8,2.3,3.333333333333333,2.1538461538461537,2.5,1.5,3.6,3.333333333333333,4.0,1.6666666666666667,4.0,3.571428571428572,4.0,3.0,3.25,3.583333333333333,3.615384615384616,3.5,2.8,3.5,3.230769230769231,2.75,3.6,2.5294117647058822,3.8,2.4166666666666665,1.5,3.2857142857142856,3.0,4.0,3.8,3.090909090909091,1.0,2.25,3.8,3.1875,3.6,2.923076923076923,3.692307692307693,3.4615384615384617,3.466666666666667,3.764705882352941,4.0,3.375,3.692307692307693,1.75,3.5384615384615383,3.5384615384615383,3.5,4.0,2.6666666666666665,4.0,4.0,1.0714285714285714,4.0,2.2142857142857144,3.823529411764706,3.4,2.5,3.0625,2.75,3.4,3.5,4.0,3.2142857142857144,2.6,4.0,0.0,3.25,3.5,3.769230769230769,3.5,3.1538461538461537,3.6,2.8461538461538463,1.8,0.6666666666666666,1.0,3.0,3.071428571428572,3.7857142857142856,3.375,2.2,3.8,4.0,4.0,3.4,3.8,2.3846153846153846,4.0,1.0,2.5294117647058822,2.5,4.0,4.0,4.0,2.333333333333333,2.75,3.2,3.5454545454545454,2.8461538461538463,3.3125,2.8,4.0,3.625,4.0,4.0,3.533333333333333,4.0,3.8,3.0,4.0,3.1666666666666665,2.7857142857142856,4.0,2.125,3.0,3.3529411764705883,3.8,2.2857142857142856,2.071428571428572,2.9375,4.0,3.6666666666666665,2.8,2.75,2.7142857142857144,2.9375,1.5714285714285714,3.2142857142857144,3.5,2.6153846153846154,2.5,2.5,4.0,3.066666666666667,3.333333333333333,2.3125,2.25,3.8125,2.6923076923076925,3.4,3.5625,2.8461538461538463,2.642857142857143,2.769230769230769,3.625,3.2,2.9285714285714284,3.333333333333333,2.5,2.6,2.333333333333333,3.0,4.0,3.6666666666666665,3.0,2.8,4.0,0.4,3.2,3.2,2.0,3.75,3.8,2.8461538461538463,4.0,3.75,3.7142857142857135,2.25,3.75,3.25,3.0,2.6,2.5,3.6666666666666665,3.375,2.8,3.230769230769231,3.4375,4.0,2.6666666666666665,2.0,2.6923076923076925,3.4,3.9166666666666665,3.769230769230769,3.4615384615384617,2.833333333333333,3.25,3.4,2.923076923076923,3.0,2.8181818181818183,3.2857142857142856,1.5,4.0,1.5,4.0,0.0,2.5625,2.8,2.25,2.6666666666666665,3.7857142857142856,3.8,3.6666666666666665,0.6,4.0,3.75,3.5,3.2857142857142856,3.2,3.0,3.25,3.583333333333333,3.0,2.923076923076923,2.6666666666666665,3.0,4.0,3.0,3.0,2.5454545454545454,2.823529411764706,2.066666666666667,3.4,3.333333333333333,2.0,3.692307692307693,3.142857142857143,1.5,3.4,2.25,4.0,3.0,4.0,3.4,2.6923076923076925,2.9285714285714284,2.9285714285714284,3.0,2.4,3.2,4.0,3.2,3.0,3.0,3.0,4.0,1.8,2.357142857142857,2.4285714285714284,3.071428571428572,4.0,2.7142857142857144,4.0,3.3125,1.5,3.75,3.375,3.6,3.4,2.5,4.0,3.411764705882353,3.0,3.230769230769231,3.8125,3.5,3.8,4.0,4.0,2.857142857142857,3.75,3.25,2.3529411764705883,3.5,4.0,3.071428571428572,2.4,3.4615384615384617,4.0,3.0,3.2142857142857144,2.6923076923076925,4.0,3.6666666666666665,2.571428571428572,3.642857142857143,2.5,1.3333333333333333,3.75,2.4166666666666665,3.5454545454545454,4.0,2.090909090909091,3.25,4.0,1.25,3.4,4.0,4.0,3.647058823529412,1.2,3.4,3.3076923076923075,3.5,2.75,3.769230769230769,3.6,3.8,2.333333333333333,3.6,3.75,2.6666666666666665,4.0,2.833333333333333,3.25,3.8,2.75,4.0,3.5454545454545454,2.0,4.0,4.0,3.7142857142857135,2.230769230769231,1.5,2.4,1.2,1.125,2.2,1.2307692307692308,1.0,2.75,3.8125,4.0,2.642857142857143,3.6666666666666665,3.2,3.333333333333333,3.909090909090909,3.75,3.75,3.0,3.6,4.0,3.2,3.4,3.1538461538461537,3.0,2.8,3.25,2.6,2.5,2.2,3.2857142857142856,3.0,2.0,4.0,4.0,2.75,0.4615384615384615,3.4,3.25,3.0,4.0,2.0,3.8,2.75,2.0,3.090909090909091,4.0,3.6666666666666665,2.8461538461538463,3.642857142857143,3.8,2.6666666666666665,4.0,3.1875,3.6,2.25,2.75,1.25,4.0,4.0,3.076923076923077,3.0,3.8,3.6,3.5625,1.2307692307692308,2.2,3.333333333333333,2.25,1.375,2.8,3.733333333333333,1.5,4.0,3.466666666666667,2.0,2.5,3.375,3.769230769230769,2.6923076923076925,3.2,2.272727272727273,2.857142857142857,1.5,1.6,3.272727272727273,2.9285714285714284,3.8125,4.0,3.0,2.230769230769231,3.294117647058824,2.6,2.5625,3.375,3.0,4.0,1.5625,2.5,1.0,4.0,0.8888888888888888,4.0,0.5,4.0,4.0,3.0,3.615384615384616,3.0,3.2,3.2,1.8,3.8,3.0,2.8461538461538463,3.5,2.923076923076923,3.75,3.4285714285714284,4.0,3.0,3.75,3.4,3.5625,4.0,3.2,2.076923076923077,2.75,1.8571428571428568,3.2857142857142856,3.272727272727273,2.9166666666666665,3.5454545454545454,3.636363636363636,2.909090909090909,1.9090909090909087,2.0,2.571428571428572,2.2142857142857144,2.6666666666666665,2.8461538461538463,4.0,4.0,4.0,3.0,2.333333333333333,3.75,4.0,4.0,3.0,1.4285714285714286,2.8461538461538463,2.357142857142857,3.6,2.6,1.75,3.0625,4.0,3.8,1.5,2.25,2.3076923076923075,1.6666666666666667,3.769230769230769,2.75,3.5,3.2,4.0,3.0,2.0,3.25,3.4615384615384617,4.0,3.0,4.0,2.5,2.4375,3.625,3.8,2.5,3.6666666666666665,3.0,3.2,3.4615384615384617,0.0,3.4444444444444446,3.2,2.466666666666667,3.8,0.0,4.0,3.5,3.1538461538461537,3.75,4.0,2.0,2.25,3.2,3.6,2.4285714285714284,3.6,4.0,3.0,0.0,4.0,3.6,2.8181818181818183,3.5,2.833333333333333,3.0,3.75,3.4375,3.5384615384615383,4.0,3.466666666666667,4.0,1.3125,4.0,0.2,3.6666666666666665,3.375,1.4,3.5,2.933333333333333,3.090909090909091,2.8,3.0,3.4,3.230769230769231,2.5384615384615383,4.0,3.0,2.0,2.0,3.5454545454545454,3.076923076923077,2.0,4.0,1.5,1.9285714285714288,4.0,3.5384615384615383,3.7142857142857135,3.6,3.857142857142857,3.75,3.0,3.8,2.6,1.2,4.0,1.7,3.5384615384615383,3.0,2.75,3.2,2.9411764705882355,3.8,3.2,4.0,3.6,1.5,3.0625,3.3846153846153846,3.4615384615384617,3.0,3.2,3.5,4.0,3.0,3.769230769230769,2.5625,3.625,3.7142857142857135,1.9,3.6,1.4,2.1538461538461537,3.4,3.0,2.857142857142857,4.0,4.0,2.0,3.5,3.6875,3.75,2.4615384615384617,3.2,3.357142857142857,2.0,2.3846153846153846,3.4166666666666665,4.0,3.8,3.636363636363636,1.9375,2.6,3.8333333333333335,3.1666666666666665,2.2,1.8,4.0,3.363636363636364,3.142857142857143,4.0,3.0,3.5625,3.6,2.0,2.6666666666666665,0.0,2.5,1.5,3.4,2.25,3.6666666666666665,2.142857142857143,3.75,3.375,4.0,3.4,0.0,3.25,2.9375,1.5,3.75,2.647058823529412,3.272727272727273,4.0,3.4,3.25,2.5,4.0,3.0,3.0,2.9,1.6428571428571428,2.1666666666666665,3.2,2.642857142857143,3.5,1.9230769230769231,3.1538461538461537,2.933333333333333,2.636363636363636,0.3846153846153846,2.0,2.333333333333333,3.6666666666666665,4.0,4.0,3.625,2.0,2.5,4.0,2.6666666666666665,2.25,4.0,3.1538461538461537,4.0,2.3846153846153846,2.0,2.9285714285714284,3.8125,3.8125,4.0,3.5,3.8125,1.2307692307692308,1.3333333333333333,3.3529411764705883,3.2142857142857144,3.5384615384615383,4.0,1.8,3.4,1.0,4.0,3.75,1.3333333333333333,2.0,3.75,3.4,2.0,4.0,4.0,4.0,3.142857142857143,3.5,2.6923076923076925,3.0,3.769230769230769,3.5,3.0,3.0,1.9090909090909087,3.3125,3.75,3.0,3.2142857142857144,4.0,2.75,4.0,2.076923076923077,2.0,2.0,3.25,3.333333333333333,3.4,3.647058823529412,3.2666666666666666,3.375,2.4,2.0,3.5,2.75,2.071428571428572,3.5,3.823529411764706,4.0,3.0,3.0,2.4,4.0,2.6923076923076925,3.125,3.0,3.0,2.75,4.0,3.764705882352941,4.0,3.7857142857142856,3.333333333333333,2.8,2.6875,3.2,3.3,3.25,3.066666666666667,4.0,4.0,3.4,3.5384615384615383,3.6666666666666665,3.0,2.333333333333333,3.0,2.4285714285714284,4.0,3.8125,2.083333333333333,4.0,3.0,2.4,3.625,3.8125,2.5,2.0,2.75,4.0,3.769230769230769,0.0,3.8125,2.333333333333333,2.75,4.0,4.0,2.8461538461538463,4.0,2.5,2.2666666666666666,4.0,2.5,2.0,2.75,3.0,3.8461538461538463,4.0,3.5,3.4,2.933333333333333,3.25,4.0,3.25,3.6,3.8,2.4375,0.0,3.4285714285714284,4.0,1.9285714285714288,3.7857142857142856,3.692307692307693,2.7333333333333334,3.5,3.823529411764706,3.769230769230769,3.5,2.0625,3.533333333333333,4.0,3.0,3.6,3.8,0.0,3.333333333333333,2.75,3.4444444444444446,3.25,2.857142857142857,4.0,3.333333333333333,3.4285714285714284,2.8,4.0,3.357142857142857,3.2857142857142856,3.769230769230769,0.8571428571428571,0.6428571428571429,1.6,1.4545454545454546,3.5,2.9411764705882355,2.8,0.6666666666666666,4.0,2.0,2.75,3.2857142857142856,2.4,2.5,3.2,2.75,3.25,4.0,2.909090909090909,4.0,4.0,3.8125,4.0,3.2,2.75,4.0,2.8461538461538463,1.5384615384615383,3.5,3.571428571428572,1.0,4.0,2.2,3.625,3.8,3.363636363636364,4.0,3.3846153846153846,3.6,4.0,4.0,3.5,2.923076923076923,3.25,2.5,4.0,2.6,3.4,3.6,3.4615384615384617,3.8,3.75,3.4,2.0,4.0,4.0,3.0,3.4,3.3076923076923075,3.0,2.8461538461538463,2.5625,2.769230769230769,2.8125,3.5625,2.25,3.5,0.4285714285714285,3.3846153846153846,1.75,3.7857142857142856,2.5,3.0,4.0,3.3076923076923075,2.8,3.4,3.0,2.375,3.066666666666667,3.692307692307693,4.0,3.0,2.7857142857142856,4.0,4.0,3.8,2.272727272727273,2.0,2.4615384615384617,3.25,2.8,3.769230769230769,3.466666666666667,1.75,3.571428571428572,2.6,1.0,3.2,3.071428571428572,2.1538461538461537,1.5,2.6153846153846154,4.0,3.642857142857143,1.1428571428571428,4.0,3.0,4.0,3.6,3.4615384615384617,2.9285714285714284,3.4,4.0,3.466666666666667,3.076923076923077,1.5,2.5,3.4375,2.8125,2.25,0.75,3.4,3.769230769230769,3.75,4.0,2.7142857142857144,2.933333333333333,2.833333333333333,4.0,3.1333333333333333,3.25,2.5,2.75,2.375,3.2,3.0,3.0,3.75,2.8666666666666667,2.583333333333333,3.642857142857143,2.6923076923076925,3.0,2.7142857142857144,2.466666666666667,2.5,3.4,2.6923076923076925,2.375,2.2,2.076923076923077,4.0,2.0,3.333333333333333,3.25,2.923076923076923,2.5,3.4615384615384617,4.0,4.0,1.0,4.0,3.25,3.25,3.357142857142857,3.75,2.4545454545454546,3.571428571428572,3.0,3.25,3.0625,2.5,2.9,3.2,3.8333333333333335,3.076923076923077,3.769230769230769,4.0,3.6,2.6666666666666665],\"xaxis\":\"x\",\"y\":[4.0,16.0,6.0,9.0,10.0,12.0,10.0,13.0,12.0,17.0,9.0,9.0,11.0,10.0,13.0,12.0,12.0,17.0,15.0,9.0,15.0,13.0,9.0,11.0,11.0,12.0,13.0,12.0,15.0,9.0,16.0,8.0,3.0,15.0,15.0,12.0,15.0,16.0,13.0,15.0,13.0,12.0,12.0,6.0,15.0,16.0,15.0,15.0,14.0,16.0,14.0,12.0,10.0,14.0,12.0,15.0,13.0,15.0,15.0,12.0,15.0,15.0,13.0,12.0,12.0,15.0,12.0,6.0,13.0,12.0,12.0,15.0,12.0,13.0,5.0,6.0,14.0,14.0,15.0,6.0,12.0,15.0,14.0,13.0,15.0,16.0,13.0,5.0,15.0,1.0,15.0,7.0,12.0,16.0,9.0,9.0,9.0,16.0,14.0,12.0,13.0,12.0,16.0,12.0,12.0,13.0,11.0,15.0,15.0,15.0,9.0,12.0,11.0,19.0,9.0,12.0,9.0,7.0,15.0,16.0,15.0,11.0,9.0,15.0,16.0,16.0,6.0,17.0,12.0,15.0,12.0,13.0,9.0,6.0,16.0,15.0,16.0,9.0,13.0,3.0,12.0,12.0,13.0,11.0,15.0,13.0,12.0,10.0,6.0,12.0,17.0,6.0,15.0,15.0,10.0,13.0,9.0,12.0,15.0,13.0,15.0,15.0,14.0,13.0,16.0,13.0,15.0,18.0,16.0,1.0,12.0,13.0,15.0,4.0,9.0,13.0,12.0,12.0,15.0,16.0,15.0,9.0,15.0,12.0,10.0,15.0,15.0,13.0,0.0,9.0,3.0,9.0,12.0,12.0,9.0,16.0,9.0,12.0,15.0,16.0,12.0,15.0,7.0,13.0,12.0,12.0,13.0,13.0,13.0,13.0,16.0,15.0,15.0,3.0,12.0,15.0,11.0,12.0,15.0,13.0,14.0,14.0,9.0,14.0,11.0,5.0,6.0,15.0,15.0,13.0,9.0,9.0,14.0,12.0,15.0,13.0,11.0,11.0,12.0,13.0,12.0,14.0,12.0,0.0,13.0,15.0,15.0,17.0,16.0,15.0,13.0,12.0,11.0,13.0,12.0,15.0,9.0,9.0,15.0,13.0,16.0,14.0,15.0,13.0,13.0,12.0,12.0,15.0,0.0,8.0,9.0,9.0,12.0,14.0,12.0,12.0,13.0,16.0,9.0,13.0,15.0,15.0,9.0,16.0,9.0,18.0,13.0,16.0,9.0,10.0,17.0,15.0,6.0,15.0,13.0,12.0,13.0,8.0,0.0,16.0,10.0,13.0,13.0,9.0,12.0,15.0,3.0,12.0,12.0,15.0,12.0,0.0,8.0,13.0,13.0,13.0,13.0,15.0,11.0,15.0,15.0,14.0,12.0,15.0,12.0,16.0,6.0,15.0,12.0,15.0,12.0,17.0,12.0,13.0,6.0,14.0,16.0,12.0,16.0,15.0,14.0,15.0,9.0,11.0,6.0,11.0,9.0,6.0,15.0,13.0,15.0,12.0,14.0,15.0,9.0,15.0,12.0,15.0,7.0,10.0,12.0,14.0,15.0,12.0,15.0,0.0,11.0,16.0,14.0,12.0,13.0,12.0,3.0,12.0,15.0,12.0,16.0,13.0,13.0,6.0,15.0,16.0,12.0,0.0,12.0,15.0,16.0,13.0,12.0,16.0,14.0,15.0,15.0,15.0,15.0,12.0,9.0,13.0,6.0,15.0,16.0,9.0,14.0,15.0,12.0,12.0,13.0,15.0,12.0,18.0,15.0,12.0,13.0,12.0,9.0,11.0,15.0,13.0,11.0,16.0,13.0,13.0,16.0,0.0,13.0,11.0,16.0,14.0,15.0,13.0,12.0,16.0,6.0,12.0,14.0,12.0,14.0,12.0,16.0,9.0,13.0,15.0,12.0,12.0,6.0,13.0,13.0,15.0,13.0,11.0,6.0,12.0,3.0,15.0,6.0,11.0,16.0,15.0,18.0,13.0,6.0,12.0,9.0,12.0,12.0,15.0,6.0,15.0,12.0,11.0,15.0,16.0,13.0,15.0,14.0,12.0,16.0,16.0,6.0,15.0,11.0,7.0,3.0,13.0,15.0,15.0,16.0,12.0,12.0,12.0,14.0,15.0,15.0,11.0,13.0,12.0,8.0,12.0,15.0,11.0,15.0,15.0,9.0,13.0,12.0,9.0,15.0,15.0,13.0,15.0,13.0,12.0,15.0,6.0,15.0,16.0,12.0,12.0,12.0,15.0,14.0,12.0,15.0,8.0,15.0,13.0,9.0,12.0,12.0,15.0,12.0,15.0,6.0,5.0,15.0,15.0,18.0,10.0,14.0,17.0,13.0,0.0,15.0,6.0,15.0,10.0,0.0,11.0,5.0,13.0,16.0,15.0,13.0,15.0,16.0,9.0,13.0,3.0,12.0,16.0,14.0,15.0,6.0,16.0,15.0,15.0,8.0,9.0,7.0,16.0,13.0,3.0,13.0,5.0,12.0,12.0,12.0,12.0,15.0,13.0,13.0,12.0,9.0,15.0,15.0,3.0,3.0,13.0,12.0,12.0,13.0,15.0,13.0,9.0,6.0,13.0,9.0,15.0,9.0,15.0,13.0,15.0,3.0,12.0,3.0,13.0,15.0,12.0,15.0,12.0,9.0,15.0,14.0,11.0,15.0,14.0,3.0,6.0,14.0,12.0,15.0,15.0,15.0,15.0,18.0,15.0,11.0,13.0,12.0,12.0,15.0,12.0,6.0,15.0,12.0,12.0,15.0,15.0,15.0,12.0,15.0,0.0,15.0,3.0,15.0,17.0,3.0,12.0,16.0,12.0,11.0,15.0,18.0,12.0,7.0,16.0,15.0,16.0,9.0,6.0,9.0,6.0,3.0,16.0,12.0,12.0,13.0,0.0,16.0,13.0,13.0,13.0,6.0,9.0,12.0,12.0,15.0,13.0,5.0,15.0,16.0,12.0,15.0,15.0,12.0,12.0,12.0,16.0,15.0,9.0,12.0,15.0,12.0,15.0,0.0,15.0,7.0,13.0,12.0,15.0,9.0,16.0,13.0,16.0,6.0,16.0,15.0,11.0,9.0,16.0,15.0,14.0,9.0,14.0,9.0,9.0,13.0,17.0,15.0,12.0,3.0,12.0,18.0,13.0,13.0,13.0,9.0,12.0,15.0,12.0,18.0,15.0,15.0,15.0,14.0,12.0,13.0,15.0,8.0,9.0,16.0,15.0,9.0,16.0,6.0,13.0,12.0,15.0,15.0,16.0,13.0,15.0,15.0,16.0,15.0,12.0,6.0,12.0,15.0,11.0,15.0,12.0,17.0,12.0,13.0,9.0,12.0,12.0,8.0,15.0,16.0,15.0,12.0,12.0,14.0,13.0,15.0,16.0,12.0,12.0,14.0,14.0,15.0,10.0,14.0,3.0,9.0,14.0,15.0,13.0,11.0,12.0,15.0,14.0,15.0,9.0,7.0,12.0,16.0,18.0,14.0,13.0,12.0,9.0,15.0,15.0,12.0,9.0,14.0,12.0,16.0,13.0,10.0,14.0,16.0,12.0,15.0,12.0,15.0,15.0,15.0,12.0,16.0,16.0,15.0,16.0,14.0,4.0,9.0,15.0,12.0,6.0,14.0,12.0,15.0,14.0,13.0,13.0,12.0,12.0,14.0,9.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,13.0,0.0,12.0,16.0,12.0,12.0,10.0,15.0,3.0,6.0,6.0,6.0,9.0,15.0,12.0,15.0,0.0,15.0,8.0,12.0,13.0,0.0,12.0,14.0,13.0,15.0,15.0,12.0,12.0,12.0,15.0,17.0,12.0,15.0,9.0,12.0,12.0,6.0,12.0,12.0,16.0,6.0,14.0,15.0,16.0,15.0,6.0,13.0,11.0,14.0,9.0,15.0,15.0,6.0,14.0,11.0,8.0,15.0,6.0,15.0,12.0,12.0,12.0,13.0,10.0,12.0,15.0,15.0,11.0,12.0,15.0,15.0,12.0,15.0,15.0,15.0,14.0,13.0,4.0,9.0,9.0,9.0,16.0,15.0,16.0,5.0,12.0,16.0,12.0,16.0,14.0,12.0,13.0,13.0,12.0,10.0,12.0,12.0,17.0,17.0,12.0,12.0,15.0,14.0,12.0,17.0,12.0,12.0,6.0,12.0,10.0,16.0,15.0,10.0,11.0,16.0,15.0,1.0,16.0,16.0,9.0,10.0,12.0,10.0,0.0,15.0,12.0,14.0,13.0,16.0,13.0,13.0,11.0,14.0,13.0,13.0,11.0,12.0,16.0,12.0,9.0,12.0,12.0,7.0,13.0,16.0,9.0,14.0,12.0,9.0,0.0,10.0,16.0,14.0,11.0,9.0,14.0,9.0,15.0,15.0,16.0,13.0,12.0,12.0,15.0,13.0,6.0,6.0,13.0,13.0,11.0,13.0,17.0,10.0,9.0,11.0,16.0,18.0,15.0,12.0,14.0,12.0,4.0,13.0,15.0,16.0,9.0,15.0,11.0,11.0,10.0,13.0,15.0,13.0,9.0,14.0,14.0,16.0,12.0,13.0,16.0,15.0,3.0,14.0,12.0,14.0,15.0,13.0,3.0,13.0,15.0,16.0,15.0,12.0,16.0,9.0,9.0,15.0,15.0,17.0,13.0,13.0,16.0,13.0,12.0,7.0,9.0,13.0,15.0,6.0,12.0,13.0,9.0,0.0,15.0,9.0,13.0,12.0,11.0,12.0,11.0,14.0,15.0,16.0,15.0,11.0,15.0,10.0,16.0,17.0,13.0,18.0,13.0,9.0,9.0,12.0,14.0,13.0,15.0,12.0,16.0,10.0,12.0,12.0,15.0,12.0,9.0,16.0,16.0,15.0,15.0,15.0,13.0,7.0,15.0,15.0,15.0,10.0,11.0,10.0,9.0,9.0,12.0,12.0,14.0,3.0,13.0,3.0,15.0,11.0,12.0,9.0,16.0,9.0,3.0,15.0,14.0,12.0,15.0,15.0,13.0,14.0,13.0,15.0,13.0,15.0,15.0,10.0,4.0,12.0,15.0,15.0,1.0,12.0,9.0,12.0,14.0,15.0,16.0,15.0,18.0,16.0,3.0,12.0,7.0,12.0,15.0,15.0,12.0,16.0,7.0,14.0,9.0,15.0,12.0,15.0,15.0,15.0,15.0,11.0,13.0,13.0,12.0,15.0,9.0,12.0,16.0,16.0,16.0,16.0,15.0,6.0,9.0,16.0,15.0,15.0,12.0,14.0,15.0,13.0,13.0,12.0,15.0,13.0,11.0,14.0,15.0,15.0,16.0,15.0,13.0,6.0,13.0,16.0,9.0,12.0,9.0,13.0,12.0,14.0,14.0,15.0,15.0,15.0,3.0,18.0,13.0,12.0,7.0,2.0,13.0,18.0,16.0,17.0,12.0,9.0,15.0,13.0,15.0,6.0,13.0,16.0,16.0,13.0,16.0,11.0,6.0,12.0,12.0,15.0,9.0,5.0,11.0,12.0,16.0,13.0,13.0,12.0,9.0,12.0,15.0,15.0,14.0,6.0,16.0,14.0,3.0,18.0,7.0,12.0,12.0,15.0,15.0,14.0,1.0,11.0,12.0,18.0,16.0,7.0,13.0,12.0,13.0,12.0,16.0,14.0,15.0,12.0,9.0,15.0,15.0,10.0,9.0,15.0,16.0,16.0,15.0,12.0,9.0,12.0,13.0,13.0,11.0,13.0,15.0,15.0,16.0,15.0,13.0,16.0,12.0,15.0,0.0,0.0,12.0,12.0,15.0,13.0,15.0,9.0,3.0,4.0,7.0,12.0,16.0,15.0,16.0,15.0,12.0,17.0,12.0,11.0,11.0,0.0,12.0,14.0,1.0,15.0,12.0,15.0,9.0,15.0,13.0,15.0,9.0,12.0,9.0,15.0,12.0,12.0,15.0,9.0,15.0,12.0,12.0,15.0,14.0,13.0,12.0,16.0,16.0,13.0,12.0,12.0,15.0,8.0,10.0,13.0,15.0,9.0,9.0,15.0,15.0,7.0,13.0,16.0,15.0,15.0,14.0,12.0,16.0,13.0,5.0,12.0,12.0,16.0,12.0,11.0,15.0,11.0,11.0,15.0,12.0,14.0,12.0,9.0,15.0,16.0,12.0,16.0,11.0,3.0,12.0,17.0,15.0,15.0,13.0,12.0,12.0,12.0,16.0,13.0,15.0,13.0,12.0,11.0,11.0,12.0,15.0,13.0,13.0,6.0,9.0,16.0,16.0,14.0,15.0,14.0,9.0,13.0,11.0,15.0,16.0,15.0,15.0,12.0,6.0,15.0,13.0,12.0,9.0,15.0,7.0,13.0,11.0,15.0,12.0,11.0,12.0,14.0,13.0,17.0,15.0,6.0,12.0,16.0,15.0,7.0,9.0,14.0,15.0,16.0,9.0,16.0,13.0,14.0,16.0,11.0,6.0,12.0,16.0,9.0,12.0,13.0,15.0,15.0,13.0,14.0,9.0,15.0,16.0,15.0,12.0,15.0,15.0,16.0,17.0,16.0,15.0,14.0,12.0,15.0,14.0,11.0,12.0,15.0,15.0,15.0,9.0,14.0,15.0,12.0,8.0,16.0,15.0,15.0,14.0,6.0,9.0,15.0,12.0,13.0,3.0,12.0,0.0,15.0,11.0,12.0,14.0,14.0,15.0,6.0,15.0,16.0,16.0,12.0,16.0,15.0,15.0,15.0,14.0,12.0,11.0,12.0,7.0,15.0,15.0,16.0,15.0,12.0,15.0,11.0,9.0,16.0,9.0,12.0,12.0,9.0,12.0,15.0,14.0,15.0,16.0,12.0,14.0,9.0,15.0,13.0,10.0,16.0,15.0,7.0,12.0,11.0,9.0,13.0,15.0,15.0,15.0,15.0,9.0,12.0,12.0,19.0,14.0,18.0,15.0,12.0,12.0,13.0,12.0,16.0,16.0,13.0,15.0,13.0,7.0,9.0,12.0,6.0,12.0,10.0,16.0,16.0,18.0,10.0,15.0,12.0,12.0,15.0,15.0,6.0,18.0,13.0,16.0,16.0,16.0,13.0,11.0,9.0,15.0,15.0,3.0,6.0,12.0,13.0,16.0,12.0,12.0,12.0,13.0,12.0,14.0,13.0,9.0,16.0,12.0,15.0,11.0,12.0,12.0,6.0,9.0,16.0,14.0,15.0,13.0,12.0,9.0,7.0,14.0,15.0,13.0,12.0,16.0,16.0,16.0,15.0,15.0,15.0,12.0,7.0,13.0,12.0,15.0,11.0,16.0,15.0,10.0,13.0,6.0,16.0,17.0,12.0,6.0,17.0,12.0,10.0,15.0,15.0,3.0,16.0,8.0,9.0,7.0,15.0,12.0,16.0,11.0,16.0,9.0,14.0,15.0,12.0,15.0,0.0,16.0,15.0,6.0,12.0,14.0,5.0,13.0,15.0,12.0,12.0,15.0,15.0,16.0,13.0,14.0,3.0,15.0,14.0,13.0,13.0,11.0,15.0,12.0,12.0,15.0,13.0,15.0,12.0,16.0,9.0,16.0,5.0,16.0,16.0,12.0,15.0,15.0,12.0,15.0,13.0,16.0,11.0,13.0,6.0,9.0,9.0,15.0,12.0,9.0,15.0,11.0,14.0,16.0,0.0,15.0,12.0,6.0,18.0,12.0,14.0,4.0,13.0,12.0,16.0,6.0,12.0,4.0,15.0,14.0,15.0,13.0,15.0,9.0,15.0,11.0,12.0,13.0,9.0,11.0,13.0,9.0,15.0,12.0,12.0,15.0,15.0,16.0,16.0,16.0,19.0,15.0,9.0,3.0,14.0,16.0,8.0,7.0,16.0,11.0,15.0,11.0,9.0,13.0,6.0,15.0,12.0,10.0,15.0,5.0,13.0,16.0,5.0,12.0,9.0,12.0,12.0,12.0,13.0,16.0,13.0,16.0,3.0,12.0,13.0,7.0,6.0,15.0,3.0,15.0,6.0,15.0,14.0,15.0,9.0,9.0,15.0,12.0,8.0,15.0,13.0,11.0,9.0,16.0,12.0,9.0,12.0,12.0,13.0,15.0,11.0,4.0,15.0,15.0,15.0,3.0,15.0,12.0,12.0,14.0,11.0,12.0,14.0,11.0,15.0,15.0,15.0,15.0,14.0,9.0,12.0,15.0,11.0,15.0,6.0,12.0,6.0,7.0,13.0,12.0,16.0,9.0,11.0,3.0,16.0,13.0,6.0,15.0,15.0,9.0,6.0,15.0,15.0,15.0,3.0,15.0,9.0,11.0,11.0,15.0,15.0,16.0,15.0,16.0,16.0,12.0,16.0,12.0,12.0,4.0,16.0,8.0,7.0,8.0,16.0,15.0,3.0,12.0,6.0,15.0,15.0,12.0,15.0,13.0,16.0,12.0,17.0,12.0,14.0,11.0,15.0,13.0,5.0,15.0,12.0,8.0,3.0,9.0,9.0,15.0,14.0,14.0,15.0,9.0,14.0,14.0,9.0,13.0,10.0,14.0,6.0,15.0,14.0,14.0,12.0,9.0,14.0,13.0,4.0,12.0,7.0,16.0,15.0,14.0,17.0,16.0,12.0,16.0,11.0,6.0,12.0,15.0,18.0,12.0,9.0,12.0,13.0,16.0,8.0,11.0,12.0,15.0,12.0,15.0,12.0,6.0,12.0,15.0,15.0,12.0,15.0,15.0,12.0,15.0,9.0,13.0,16.0,16.0,12.0,13.0,16.0,9.0,12.0,12.0,15.0,12.0,12.0,13.0,12.0,16.0,7.0,12.0,12.0,9.0,12.0,15.0,12.0,13.0,9.0,16.0,16.0,16.0,16.0,15.0,12.0,15.0,9.0,12.0,13.0,15.0,15.0,6.0,6.0,16.0,12.0,14.0,15.0,6.0,12.0,15.0,15.0,15.0,13.0,15.0,3.0,9.0,13.0,15.0,15.0,15.0,15.0,17.0,13.0,16.0,10.0,15.0,12.0,15.0,12.0,15.0,15.0,12.0,12.0,17.0,16.0,15.0,15.0,17.0,12.0,7.0,16.0,12.0,13.0,9.0,13.0,10.0,12.0,13.0,3.0,12.0,12.0,15.0,13.0,12.0,12.0,12.0,14.0,14.0,6.0,11.0,11.0,16.0,15.0,12.0,13.0,16.0,6.0,12.0,12.0,12.0,16.0,17.0,13.0,12.0,13.0,12.0,15.0,15.0,17.0,13.0,12.0,13.0,10.0,12.0,2.0,6.0,12.0,12.0,7.0,12.0,8.0,16.0,18.0,15.0,12.0,12.0,15.0,13.0,12.0,15.0,15.0,11.0,3.0,12.0,15.0,15.0,12.0,3.0,10.0,15.0,7.0,13.0,6.0,12.0,11.0,16.0,6.0,12.0,13.0,15.0,9.0,12.0,10.0,16.0,10.0,15.0,13.0,11.0,12.0,12.0,14.0,15.0,16.0,13.0,13.0,12.0,0.0,9.0,16.0,15.0,17.0,6.0,14.0,15.0,14.0,9.0,12.0,6.0,12.0,13.0,9.0,12.0,15.0,11.0,11.0,12.0,9.0,16.0,11.0,11.0,17.0,13.0,15.0,15.0,14.0,6.0,8.0,14.0,16.0,9.0,16.0,3.0,15.0,15.0,14.0,16.0,9.0,11.0,13.0,3.0,12.0,12.0,14.0,13.0,15.0,10.0,9.0,9.0,9.0,4.0,15.0,9.0,16.0,6.0,15.0,14.0,15.0,12.0,12.0,12.0,13.0,12.0,15.0,12.0,13.0,9.0,15.0,14.0,15.0,7.0,6.0,14.0,12.0,11.0,15.0,11.0,6.0,9.0,15.0,14.0,15.0,13.0,13.0,13.0,15.0,17.0,3.0,16.0,13.0,9.0,13.0,13.0,12.0,1.0,9.0,10.0,16.0,6.0,12.0,9.0,17.0,15.0,9.0,16.0,12.0,15.0,12.0,11.0,14.0,15.0,16.0,0.0,12.0,12.0,13.0,12.0,13.0,15.0,13.0,9.0,1.0,3.0,12.0,14.0,14.0,16.0,15.0,15.0,13.0,15.0,15.0,15.0,9.0,14.0,5.0,17.0,4.0,15.0,16.0,17.0,9.0,13.0,15.0,11.0,13.0,16.0,15.0,15.0,16.0,15.0,16.0,15.0,15.0,15.0,13.0,14.0,12.0,14.0,13.0,12.0,15.0,17.0,15.0,10.0,7.0,16.0,15.0,9.0,15.0,16.0,11.0,16.0,8.0,14.0,12.0,9.0,12.0,16.0,15.0,15.0,12.0,12.0,9.0,16.0,13.0,15.0,16.0,13.0,14.0,10.0,16.0,12.0,14.0,12.0,12.0,12.0,6.0,15.0,16.0,18.0,12.0,15.0,13.0,0.0,15.0,15.0,15.0,16.0,15.0,8.0,7.0,12.0,14.0,12.0,12.0,12.0,9.0,15.0,6.0,12.0,16.0,15.0,13.0,16.0,15.0,9.0,12.0,13.0,15.0,12.0,13.0,13.0,6.0,12.0,15.0,13.0,9.0,11.0,14.0,9.0,12.0,6.0,15.0,0.0,13.0,15.0,12.0,6.0,14.0,15.0,15.0,3.0,11.0,12.0,12.0,14.0,15.0,15.0,12.0,12.0,12.0,13.0,9.0,15.0,11.0,12.0,15.0,11.0,14.0,12.0,15.0,9.0,9.0,13.0,14.0,9.0,15.0,12.0,16.0,12.0,13.0,15.0,13.0,14.0,14.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,9.0,16.0,9.0,11.0,14.0,14.0,13.0,14.0,18.0,16.0,6.0,16.0,16.0,15.0,15.0,9.0,12.0,17.0,12.0,13.0,16.0,12.0,15.0,9.0,12.0,14.0,12.0,12.0,17.0,12.0,12.0,14.0,15.0,13.0,3.0,15.0,14.0,13.0,12.0,12.0,9.0,14.0,12.0,6.0,12.0,12.0,11.0,15.0,6.0,12.0,12.0,3.0,15.0,12.0,16.0,17.0,6.0,15.0,13.0,6.0,12.0,13.0,15.0,15.0,6.0,15.0,12.0,9.0,12.0,12.0,12.0,15.0,12.0,16.0,11.0,9.0,14.0,11.0,14.0,13.0,9.0,15.0,6.0,6.0,9.0,3.0,3.0,9.0,16.0,12.0,14.0,12.0,10.0,9.0,11.0,12.0,12.0,9.0,15.0,15.0,15.0,15.0,13.0,12.0,15.0,12.0,15.0,6.0,10.0,14.0,12.0,6.0,15.0,17.0,12.0,3.0,15.0,12.0,12.0,16.0,6.0,15.0,12.0,9.0,11.0,6.0,9.0,13.0,14.0,15.0,6.0,15.0,16.0,15.0,9.0,12.0,6.0,15.0,15.0,13.0,12.0,15.0,15.0,16.0,4.0,12.0,15.0,9.0,7.0,15.0,15.0,3.0,14.0,15.0,2.0,9.0,8.0,13.0,13.0,15.0,10.0,11.0,9.0,6.0,11.0,14.0,16.0,7.0,12.0,13.0,17.0,15.0,16.0,16.0,9.0,12.0,8.0,12.0,0.0,16.0,4.0,14.0,0.0,12.0,13.0,15.0,13.0,12.0,15.0,15.0,9.0,15.0,12.0,13.0,12.0,13.0,12.0,14.0,11.0,9.0,12.0,15.0,16.0,12.0,15.0,10.0,12.0,11.0,7.0,11.0,12.0,11.0,11.0,11.0,6.0,9.0,14.0,9.0,9.0,13.0,11.0,13.0,12.0,12.0,15.0,12.0,15.0,15.0,15.0,3.0,10.0,14.0,15.0,15.0,9.0,16.0,11.0,15.0,6.0,12.0,13.0,6.0,13.0,8.0,12.0,15.0,11.0,12.0,6.0,12.0,13.0,15.0,13.0,15.0,6.0,16.0,16.0,15.0,6.0,9.0,9.0,15.0,13.0,0.0,9.0,15.0,15.0,15.0,0.0,10.0,12.0,13.0,12.0,13.0,13.0,9.0,15.0,15.0,11.0,15.0,15.0,9.0,0.0,15.0,15.0,11.0,12.0,18.0,6.0,12.0,16.0,13.0,15.0,15.0,13.0,9.0,15.0,0.0,15.0,16.0,6.0,12.0,15.0,11.0,15.0,12.0,15.0,13.0,9.0,15.0,12.0,14.0,6.0,11.0,13.0,6.0,15.0,6.0,10.0,15.0,13.0,14.0,15.0,14.0,12.0,13.0,15.0,15.0,6.0,13.0,7.0,13.0,12.0,12.0,15.0,13.0,15.0,12.0,9.0,15.0,6.0,16.0,13.0,13.0,15.0,15.0,14.0,12.0,12.0,13.0,16.0,8.0,14.0,7.0,15.0,7.0,10.0,15.0,13.0,14.0,15.0,15.0,10.0,12.0,16.0,16.0,13.0,15.0,14.0,12.0,9.0,12.0,14.0,15.0,11.0,12.0,15.0,18.0,12.0,12.0,9.0,11.0,11.0,7.0,15.0,12.0,16.0,15.0,10.0,9.0,0.0,12.0,8.0,10.0,12.0,15.0,13.0,12.0,16.0,13.0,15.0,0.0,12.0,16.0,6.0,16.0,13.0,11.0,15.0,15.0,16.0,16.0,12.0,3.0,12.0,10.0,4.0,12.0,15.0,14.0,12.0,7.0,13.0,12.0,8.0,0.0,10.0,15.0,15.0,12.0,12.0,16.0,9.0,3.0,12.0,6.0,9.0,13.0,13.0,15.0,9.0,6.0,14.0,16.0,16.0,13.0,12.0,16.0,5.0,3.0,17.0,14.0,13.0,16.0,9.0,15.0,3.0,15.0,12.0,7.0,13.0,12.0,15.0,17.0,11.0,12.0,15.0,14.0,12.0,13.0,11.0,13.0,6.0,9.0,9.0,8.0,16.0,16.0,13.0,14.0,3.0,9.0,11.0,10.0,10.0,9.0,12.0,9.0,15.0,17.0,15.0,16.0,12.0,9.0,12.0,12.0,11.0,12.0,17.0,15.0,15.0,12.0,15.0,11.0,13.0,16.0,11.0,15.0,16.0,16.0,17.0,18.0,14.0,15.0,15.0,12.0,15.0,10.0,12.0,15.0,9.0,11.0,15.0,13.0,9.0,13.0,6.0,12.0,14.0,15.0,16.0,5.0,3.0,13.0,9.0,16.0,16.0,9.0,6.0,9.0,13.0,13.0,0.0,16.0,9.0,12.0,15.0,11.0,13.0,9.0,12.0,11.0,6.0,13.0,7.0,12.0,15.0,13.0,12.0,12.0,15.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,0.0,14.0,15.0,9.0,14.0,13.0,11.0,12.0,17.0,13.0,12.0,10.0,15.0,10.0,13.0,15.0,15.0,0.0,15.0,12.0,9.0,12.0,14.0,9.0,9.0,14.0,7.0,13.0,14.0,14.0,13.0,6.0,3.0,9.0,5.0,12.0,17.0,15.0,3.0,17.0,9.0,12.0,14.0,15.0,12.0,15.0,12.0,12.0,14.0,11.0,9.0,11.0,16.0,11.0,15.0,12.0,14.0,13.0,5.0,12.0,14.0,3.0,16.0,15.0,16.0,15.0,11.0,12.0,13.0,15.0,13.0,13.0,12.0,13.0,12.0,12.0,16.0,12.0,15.0,15.0,13.0,15.0,12.0,15.0,7.0,13.0,11.0,15.0,10.0,13.0,12.0,9.0,16.0,10.0,16.0,16.0,7.0,12.0,3.0,13.0,6.0,14.0,12.0,6.0,16.0,13.0,15.0,15.0,18.0,13.0,15.0,13.0,12.0,15.0,14.0,15.0,13.0,15.0,7.0,9.0,13.0,12.0,15.0,13.0,15.0,9.0,14.0,10.0,6.0,15.0,14.0,9.0,3.0,13.0,16.0,14.0,4.0,14.0,12.0,12.0,15.0,13.0,14.0,15.0,15.0,15.0,12.0,3.0,3.0,16.0,16.0,12.0,3.0,15.0,13.0,12.0,14.0,14.0,15.0,18.0,12.0,15.0,12.0,12.0,12.0,13.0,15.0,12.0,12.0,12.0,15.0,12.0,14.0,13.0,9.0,4.0,15.0,10.0,15.0,13.0,13.0,12.0,7.0,11.0,6.0,9.0,12.0,13.0,8.0,13.0,15.0,12.0,3.0,12.0,12.0,12.0,14.0,12.0,7.0,7.0,12.0,12.0,16.0,9.0,10.0,15.0,18.0,10.0,13.0,13.0,15.0,9.0],\"yaxis\":\"y\",\"type\":\"scattergl\"},{\"hovertemplate\":\"SEM_3_STATUS=1<br>GPA_2=%{x}<br>UNITS_COMPLETED_2=%{y}<extra></extra>\",\"legendgroup\":\"1\",\"marker\":{\"color\":\"#EF553B\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"1\",\"showlegend\":true,\"x\":[3.333333333333333,0.0,1.0,1.3333333333333333,0.0,0.5,0.0,0.6,1.4,0.75,0.0,3.0,3.571428571428572,0.2666666666666666,1.5,2.333333333333333,1.0,2.6875,3.3846153846153846,0.4615384615384615,0.0,0.0,1.5,3.0,2.363636363636364,4.0,2.75,0.0,0.0,1.2857142857142858,2.727272727272727,1.3333333333333333,1.5,3.5,3.333333333333333,0.0,1.0,0.0,0.0,3.5384615384615383,0.0,3.0,1.8,2.8125,1.0,1.25,0.2222222222222222,0.0,3.230769230769231,3.5384615384615383,0.0,1.2,0.625,1.3333333333333333,0.0,0.0,2.8,0.0,1.1538461538461535,0.25,0.0,0.6,1.0833333333333333,1.0,1.5,1.0,0.25,4.0,1.0,0.25,4.0,0.2857142857142857,0.75,0.9,2.5,2.7,3.5,3.0,0.0,1.8,3.5,3.5,3.0,2.071428571428572,0.0,0.75,0.0,1.0,2.0,2.0,0.3076923076923077,2.9375,1.2857142857142858,4.0,3.6,0.4,0.0,0.4,1.0,0.0,1.5,2.6666666666666665,3.6666666666666665,1.375,0.0,0.0,4.0,0.0,0.0,0.0,0.5,4.0,2.5,0.3,0.0,4.0,0.2,0.0,3.5,3.8,0.4,1.6666666666666667,0.0,0.3333333333333333,1.75,0.0,1.3333333333333333,3.176470588235294,2.333333333333333,2.0,0.0,3.0,1.0,2.5,0.0,0.75,0.375,3.6666666666666665,0.75,0.1538461538461538,1.5,0.0,2.0,3.235294117647059,0.0,2.5,2.8666666666666667,1.7,1.1,0.0,3.5,2.4,0.0,4.0,2.25,3.769230769230769,2.6,4.0,0.2,1.3333333333333333,3.142857142857143,0.0,2.5,1.3333333333333333,0.0,1.0,1.4285714285714286,2.7142857142857144,0.6666666666666666,0.25,1.5,4.0,2.75,2.5,0.9375,0.0,0.0,3.2,3.2,0.0,0.1428571428571428,0.0,2.75,0.0,1.6666666666666667,3.25,3.5,3.0,1.25,0.0,0.5,0.0,2.25,1.0,1.6,0.0,2.923076923076923,0.8571428571428571,4.0,0.75,3.0,2.4285714285714284,3.25,0.6666666666666666,2.1666666666666665,0.0,1.0,2.4615384615384617,3.75,4.0,0.0,0.4,2.6,0.8,1.0,1.0,2.4375,1.375,2.0,3.764705882352941,2.0,0.0,3.111111111111111,3.6666666666666665,3.5,2.8461538461538463,1.3333333333333333,0.75,0.0,0.0,0.0,1.0,1.25,2.75,2.0,1.3333333333333333,3.363636363636364,0.0,0.0,3.25,2.0,0.8888888888888888,0.8181818181818182,1.5,3.25,2.6,3.235294117647059,0.0,1.5,4.0,0.0,1.5,0.2142857142857142,0.75,3.071428571428572,0.5,0.0,3.1538461538461537,0.375,2.076923076923077,0.0,3.125,4.0,0.1875,0.6,3.25,3.230769230769231,4.0,0.2222222222222222,3.125,1.0,0.0,2.8,2.333333333333333,0.0,0.0,1.1111111111111112,2.0625,0.25,0.0,3.0,0.0,4.0,0.4,0.0,2.571428571428572,0.1333333333333333,3.769230769230769,0.0,3.0,1.0,2.0,0.0,4.0,0.8,4.0,1.5,4.0,3.75,1.9375,3.333333333333333,1.0,3.5,2.5454545454545454,2.0,3.6,2.5,0.0,3.0,0.3,3.333333333333333,0.0,0.0,0.0,0.0,1.25,1.5,3.4,0.5,2.2857142857142856,0.0,0.0,0.0,3.2,0.4615384615384615,0.3846153846153846,2.0,3.071428571428572,4.0,1.3333333333333333,2.8181818181818183,2.588235294117647,2.0,0.6,1.5714285714285714,1.6666666666666667,0.0],\"xaxis\":\"x\",\"y\":[18.0,0.0,3.0,6.0,0.0,3.0,0.0,3.0,6.0,3.0,0.0,6.0,14.0,0.0,6.0,9.0,4.0,13.0,13.0,3.0,0.0,0.0,6.0,6.0,6.0,12.0,12.0,0.0,0.0,7.0,11.0,6.0,3.0,12.0,9.0,0.0,3.0,0.0,0.0,13.0,0.0,3.0,9.0,16.0,3.0,6.0,0.0,0.0,13.0,13.0,0.0,3.0,2.0,6.0,0.0,0.0,15.0,0.0,6.0,0.0,0.0,3.0,4.0,0.0,9.0,3.0,0.0,1.0,3.0,0.0,13.0,1.0,3.0,4.0,9.0,10.0,12.0,9.0,0.0,9.0,12.0,6.0,12.0,9.0,0.0,3.0,0.0,3.0,6.0,3.0,1.0,16.0,6.0,16.0,15.0,3.0,0.0,3.0,6.0,0.0,6.0,9.0,9.0,3.0,0.0,0.0,16.0,0.0,0.0,0.0,0.0,6.0,6.0,1.0,0.0,12.0,0.0,0.0,12.0,15.0,3.0,3.0,0.0,0.0,9.0,0.0,9.0,17.0,9.0,3.0,0.0,6.0,3.0,8.0,0.0,3.0,0.0,18.0,3.0,1.0,5.0,0.0,3.0,17.0,0.0,6.0,12.0,7.0,4.0,0.0,16.0,12.0,0.0,15.0,9.0,13.0,15.0,12.0,0.0,6.0,14.0,0.0,12.0,3.0,0.0,3.0,6.0,9.0,3.0,0.0,3.0,12.0,16.0,12.0,6.0,0.0,0.0,15.0,15.0,0.0,1.0,0.0,12.0,0.0,6.0,12.0,12.0,3.0,6.0,0.0,3.0,0.0,5.0,3.0,9.0,0.0,13.0,2.0,16.0,3.0,6.0,7.0,13.0,3.0,18.0,0.0,3.0,13.0,12.0,12.0,0.0,3.0,12.0,4.0,3.0,0.0,13.0,6.0,3.0,17.0,6.0,0.0,9.0,9.0,12.0,13.0,6.0,2.0,0.0,0.0,0.0,3.0,1.0,12.0,5.0,3.0,11.0,0.0,0.0,12.0,9.0,1.0,3.0,3.0,12.0,15.0,17.0,0.0,6.0,15.0,0.0,3.0,0.0,3.0,14.0,3.0,0.0,13.0,3.0,9.0,0.0,16.0,14.0,0.0,4.0,12.0,10.0,11.0,1.0,8.0,3.0,0.0,15.0,6.0,0.0,0.0,4.0,11.0,0.0,0.0,11.0,0.0,15.0,0.0,0.0,9.0,1.0,13.0,0.0,6.0,6.0,3.0,0.0,12.0,3.0,12.0,6.0,14.0,12.0,12.0,9.0,3.0,12.0,11.0,1.0,15.0,6.0,0.0,9.0,0.0,9.0,0.0,0.0,0.0,0.0,6.0,6.0,15.0,2.0,10.0,0.0,0.0,0.0,4.0,3.0,1.0,6.0,14.0,6.0,4.0,11.0,17.0,3.0,3.0,5.0,6.0,0.0],\"yaxis\":\"y\",\"type\":\"scattergl\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"GPA_2\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"UNITS_COMPLETED_2\"}},\"legend\":{\"title\":{\"text\":\"SEM_3_STATUS\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.scatter(data_frame=Xy_build_c,y='UNITS_COMPLETED_2',x='GPA_2',color='SEM_3_STATUS')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc01f015-7ad6-4e7c-b9b8-497579f70a89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: What do you notice about this scatterplot? What do you wonder?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "276febef-89d5-46ef-8e44-f209f3976c73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Feature Enginering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcc47edd-9fa8-486b-bc21-331a55ce320f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To build a model with maximum predictive ability, it is necessary to transform existing variables so that they are in a format scikit learn models can use effectively.\n",
    "There are three closely intertwined considerations\n",
    "\n",
    "1. Domain distinctives - Are some of the variables in our data inherently devoid of predictive value? Are there new variables we can create that are likely to be predictive?\n",
    "\n",
    "2. Statistical subtleties - Are there further transformations that need to take place on existing features to minimize the possibility of poor model performance?\n",
    "\n",
    "3. Coding customization - Is the data presented in a format tailored to scikit learn's predictive modeling infrastructure to readily move through prescribed train-test-validate workflows?\n",
    "\n",
    "\n",
    "We first create the new variables and view them in new dataframes, **X_build_c1** and **X_test_c1**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "582b4afe-e1bf-42ee-afa5-1b058b3618be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####Domain distinctives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "243024bb-e585-4ec7-9dad-291fc8218883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Given our knowledge of higher ed data, what variables are devoid of information for predicting dropout? Are there new variables we can create that could be informative? To address point 1., we dropped identifier variables above. These variables identify (as opposed to characterize) the \"who\" and \"when\", and in this context provide no information about academic performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "802ff9f2-39b0-45c7-bf0b-3c77cfb25317",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Exploratory data analysis seemed to indicate strong relationships between academic performance leading up to term 3 and retention. Let's create variables for DFW rate as well as grade points for each of the first two terms, for both the train and the test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac8e0693-c714-4c47-bddb-0e962b76a521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Initialize the new dataframe\n",
    "X_build_c1 = X_build_c.copy()\n",
    "\n",
    "\n",
    "X_build_c1['DFW_RATE_1'] = (X_build_c1['UNITS_ATTEMPTED_1']-X_build_c1['UNITS_COMPLETED_1'])/X_build_c1['UNITS_ATTEMPTED_1']\n",
    "\n",
    "#DFW Rate Term 2\n",
    "X_build_c1['DFW_RATE_2'] = (X_build_c1['UNITS_ATTEMPTED_2']-X_build_c1['UNITS_COMPLETED_2'])/X_build_c1['UNITS_ATTEMPTED_2']\n",
    "\n",
    "#Grade points Term 1\n",
    "X_build_c1['GRADE_POINTS_1'] = X_build_c1['UNITS_ATTEMPTED_1']*X_build_c1['GPA_1']\n",
    "\n",
    "#Grade points Term 2\n",
    "X_build_c1['GRADE_POINTS_2'] = X_build_c1['UNITS_ATTEMPTED_2']*X_build_c1['GPA_2']\n",
    "\n",
    "\n",
    "#Repeat the above for the Validation set\n",
    "X_val_c1 = X_val_c.copy()\n",
    "\n",
    "X_val_c1['DFW_RATE_1'] = (X_val_c1['UNITS_ATTEMPTED_1']-X_val_c1['UNITS_COMPLETED_1'])/X_val_c1['UNITS_ATTEMPTED_1']\n",
    "\n",
    "#DFW Rate Term 2\n",
    "X_val_c1['DFW_RATE_2'] = (X_val_c1['UNITS_ATTEMPTED_2']-X_val_c1['UNITS_COMPLETED_2'])/X_val_c1['UNITS_ATTEMPTED_2']\n",
    "\n",
    "#Grade points Term 1\n",
    "X_val_c1['GRADE_POINTS_1'] = X_val_c1['UNITS_ATTEMPTED_1']*X_val_c1['GPA_1']\n",
    "\n",
    "#Grade points Term 2\n",
    "X_val_c1['GRADE_POINTS_2'] = X_val_c1['UNITS_ATTEMPTED_2']*X_val_c1['GPA_2']\n",
    "\n",
    "\n",
    "#Repeat the above for the Test set\n",
    "X_test_c1 = X_test_c.copy()\n",
    "\n",
    "X_test_c1['DFW_RATE_1'] = (X_test_c1['UNITS_ATTEMPTED_1']-X_test_c1['UNITS_COMPLETED_1'])/X_test_c1['UNITS_ATTEMPTED_1']\n",
    "X_test_c1['DFW_RATE_2'] = (X_test_c1['UNITS_ATTEMPTED_2']-X_test_c1['UNITS_COMPLETED_2'])/X_test_c1['UNITS_ATTEMPTED_2']\n",
    "\n",
    "#Grade points Term 1\n",
    "X_test_c1['GRADE_POINTS_1'] = X_test_c1['UNITS_ATTEMPTED_1']*X_test_c1['GPA_1']\n",
    "\n",
    "#Grade points Term 2\n",
    "X_test_c1['GRADE_POINTS_2'] = X_test_c1['UNITS_ATTEMPTED_2']*X_test_c1['GPA_2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5625d45a-707e-4881-b11d-3529bda6c685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: We're repeating the same process of variable creation for three different data sets: build, val and test. Though beyond the scope of this course, it will be beneficial for your growth in machine learning to learn about loops in coding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5adc576-be02-4d07-8206-dc3e1416252b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's calculate the correlation among predictors. Some machine learning models are sensitive to high correlations, so we'll keep in mind as we proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c01bec8-edcd-4d92-b53c-6ab379248bf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[34]: HS_MATH_GPA          0.333513\nHS_ENGL_GPA          0.359250\nUNITS_ATTEMPTED_1    0.248270\nUNITS_COMPLETED_1    0.507833\nGPA_1                0.625602\nUNITS_ATTEMPTED_2    0.248398\nUNITS_COMPLETED_2    0.782803\nGPA_2                1.000000\nDFW_RATE_1          -0.498655\nDFW_RATE_2          -0.883205\nGRADE_POINTS_1       0.603631\nGRADE_POINTS_2       0.878734\nName: GPA_2, dtype: float64"
     ]
    }
   ],
   "source": [
    "#Calulating the pairwise Pearson correlation coefficient between the response and each predictor\n",
    "X_build_c1.corr().loc[:,'GPA_2']\n",
    "\n",
    "#Note this is done strictly for exploratory purposes, so it is not necessary to apply to the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6205eb7c-7967-4d6b-b560-606e42d67b31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Addressing Class Imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8792bd50-7f79-4191-8f05-9adef5146354",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The training set and its target have a total of 4122 observations each. As mentioned above, however, there is severe *class imbalance*, meaning that there are not (approximately) equal amounts of both classes represented in the data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "291e3784-22f5-4ddc-a31e-bd10770ab806",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"da3af145-09b4-4249-b892-cd088be68d12\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da3af145-09b4-4249-b892-cd088be68d12\")) {                    Plotly.newPlot(                        \"da3af145-09b4-4249-b892-cd088be68d12\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[0.9056815001399384,0.09431849986006158],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"da3af145-09b4-4249-b892-cd088be68d12\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"da3af145-09b4-4249-b892-cd088be68d12\")) {                    Plotly.newPlot(                        \"da3af145-09b4-4249-b892-cd088be68d12\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[0.9056815001399384,0.09431849986006158],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Bar graph visualizing class imbalance\n",
    "px.bar(x=np.unique(y_build_c),y=y_build_c.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6437611-2066-476d-a5b8-fb1d94532c6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There are 9 times as many students that are retained after year 1 than are not (i.e. the *odds* of being retained are 9 times higher than not being retained). This is a good thing for the university, but poses challenges for the classification task. This could cause our algorithm to memorize and learn the majority class so well that it performs poorly on the minority examples. Moreover, it could lead to a false sense of security. Suppose we blindly predict that every student in our DataFrame is retained. Then 90% of our predictions would be correct, which seems great, except for the fact that 0% of our predictions would be correct for students that drop out - which is the more important class to predict correctly. By *resampling* from the minority class, we can build an artificially balanced dataset, and typically boost classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c80bae2e-979e-443c-9bd6-34ada2b47a10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#First, again we combine the features and labels into one DataFrame, as the labels will dictate how we use the corresponding features.\n",
    "\n",
    "y_build.name = 'SEM_3_STATUS'\n",
    "Xy_build_c1 = pd.concat([X_build_c1,y_build_c], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14f6c014-29c7-4ff7-9e9e-a2d5c3034479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next we use numpy to randomly sample with replacement from the minority class. Sometimes this process is referred to as *bootstrap resampling*. How many additional dropout samples do we need? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "997cdc4e-c06b-47a6-a138-cfb4e50b7719",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[37]: 2899"
     ]
    }
   ],
   "source": [
    "#Difference between number retained and number that leave\n",
    "counts = pd.value_counts(y_build_c)\n",
    "counts[0]-counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff77a336-7180-4177-ab49-1a4b6d88393b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>DFW_RATE_1</th>\n",
       "      <th>DFW_RATE_2</th>\n",
       "      <th>GRADE_POINTS_1</th>\n",
       "      <th>GRADE_POINTS_2</th>\n",
       "      <th>SEM_3_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105755</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.34</td>\n",
       "      <td>Science</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.70</td>\n",
       "      <td>3.81</td>\n",
       "      <td>Arts</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.27</td>\n",
       "      <td>Arts</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>36.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>Nonresident alien</td>\n",
       "      <td>Female</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>3.16</td>\n",
       "      <td>3.62</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97456</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.50</td>\n",
       "      <td>University Programs</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.727273</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88943</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.34</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.37</td>\n",
       "      <td>3.63</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51091</th>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.71</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81134</th>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.98</td>\n",
       "      <td>4.29</td>\n",
       "      <td>Health</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>Nonresident alien</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>4.01</td>\n",
       "      <td>4.07</td>\n",
       "      <td>Science</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>41.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6472 rows × 17 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>GPA_2</th>\n      <th>DFW_RATE_1</th>\n      <th>DFW_RATE_2</th>\n      <th>GRADE_POINTS_1</th>\n      <th>GRADE_POINTS_2</th>\n      <th>SEM_3_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105755</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.09</td>\n      <td>2.34</td>\n      <td>Science</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.000000</td>\n      <td>9.0</td>\n      <td>4.0</td>\n      <td>1.666667</td>\n      <td>0.000000</td>\n      <td>0.555556</td>\n      <td>4.0</td>\n      <td>15.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>73202</th>\n      <td>White</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.70</td>\n      <td>3.81</td>\n      <td>Arts</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>4.000000</td>\n      <td>16.0</td>\n      <td>16.0</td>\n      <td>3.687500</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>60.0</td>\n      <td>59.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8941</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.44</td>\n      <td>3.27</td>\n      <td>Arts</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.000000</td>\n      <td>13.0</td>\n      <td>6.0</td>\n      <td>1.692308</td>\n      <td>0.000000</td>\n      <td>0.538462</td>\n      <td>36.0</td>\n      <td>22.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>35002</th>\n      <td>Nonresident alien</td>\n      <td>Female</td>\n      <td>Unknown</td>\n      <td>3.16</td>\n      <td>3.62</td>\n      <td>Engineering</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>9.0</td>\n      <td>9.0</td>\n      <td>4.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>41.0</td>\n      <td>36.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>97456</th>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>2.28</td>\n      <td>2.50</td>\n      <td>University Programs</td>\n      <td>11.0</td>\n      <td>11.0</td>\n      <td>3.727273</td>\n      <td>14.0</td>\n      <td>10.0</td>\n      <td>1.500000</td>\n      <td>0.000000</td>\n      <td>0.285714</td>\n      <td>41.0</td>\n      <td>21.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>88943</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.08</td>\n      <td>3.34</td>\n      <td>Engineering</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.461538</td>\n      <td>12.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1754</th>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.37</td>\n      <td>3.63</td>\n      <td>Engineering</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>0.615385</td>\n      <td>15.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.923077</td>\n      <td>1.000000</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51091</th>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.67</td>\n      <td>3.71</td>\n      <td>Liberal Arts</td>\n      <td>7.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>18.0</td>\n      <td>0.0</td>\n      <td>0.222222</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>81134</th>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.98</td>\n      <td>4.29</td>\n      <td>Health</td>\n      <td>15.0</td>\n      <td>15.0</td>\n      <td>3.600000</td>\n      <td>15.0</td>\n      <td>12.0</td>\n      <td>2.400000</td>\n      <td>0.000000</td>\n      <td>0.200000</td>\n      <td>54.0</td>\n      <td>36.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8543</th>\n      <td>Nonresident alien</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>4.01</td>\n      <td>4.07</td>\n      <td>Science</td>\n      <td>12.0</td>\n      <td>12.0</td>\n      <td>3.416667</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>2.333333</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>41.0</td>\n      <td>21.0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>6472 rows × 17 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The seed ensures reproducibility\n",
    "Xy_build_c1_pos = Xy_build_c1[Xy_build_c1['SEM_3_STATUS']==1].iloc[list(rng.randint(low=0,high=counts[1],size=counts[0]-counts[1])),:]\n",
    "\n",
    "#Now we concatenate rows to create the new data\n",
    "Xy_build_bal = pd.concat([Xy_build_c1,Xy_build_c1_pos],axis=0)\n",
    "Xy_build_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2234f38-fc63-446e-8e97-9464102372d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There are other more complex algorithms for generating brand new, realistic but simulated samples for the minority class. One of the most popular is the synthetic minority over-sampling technique, or SMOTE. It can be implemented as a method in the [imbalanced-learn](https://imbalanced-learn.org/stable/index.html) library. Documentation for SMOTE, and links to similar methods can be found [here](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html).\n",
    "\n",
    "Let's separate our target variable once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d63be30-d5f5-41d6-a741-ddae10397be2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_build_bal = Xy_build_bal.drop('SEM_3_STATUS',axis=1)\n",
    "y_build_bal = Xy_build_bal['SEM_3_STATUS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdd6db69-0a4b-4a1f-a07c-2fb3e8f8ef89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can verify numerically and graphically that the classes are now balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9571d9b-60ee-4054-a34d-159723b1c139",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[40]: 105755    0\n73202     0\n8941      0\n35002     0\n97456     0\n         ..\n88943     1\n1754      1\n51091     1\n81134     1\n8543      1\nName: SEM_3_STATUS, Length: 6472, dtype: uint8"
     ]
    }
   ],
   "source": [
    "y_build_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70fdc9c8-c8f9-40bc-b0f1-8042471a2a5f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[41]: 0    3236\n1    3236\nName: SEM_3_STATUS, dtype: int64"
     ]
    }
   ],
   "source": [
    "y_build_bal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0803185c-5b36-4382-8746-f80f50d81269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"6160778e-5cfa-4f3c-b7af-9843d0c2c165\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6160778e-5cfa-4f3c-b7af-9843d0c2c165\")) {                    Plotly.newPlot(                        \"6160778e-5cfa-4f3c-b7af-9843d0c2c165\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[0.5,0.5],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"6160778e-5cfa-4f3c-b7af-9843d0c2c165\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6160778e-5cfa-4f3c-b7af-9843d0c2c165\")) {                    Plotly.newPlot(                        \"6160778e-5cfa-4f3c-b7af-9843d0c2c165\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0,1],\"xaxis\":\"x\",\"y\":[0.5,0.5],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(x=np.unique(y_build_bal),y=y_build_bal.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d76ab142-7608-43a2-b302-ed26e11b01ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "At this point it will be helpful to create a balanced version of the entire train set as well. We won't use it til later on, in the model testing stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40135675-1af0-4f30-8686-39e36082f7e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train_c1 = pd.concat([X_build_c1,X_val_c1], axis=0)\n",
    "y_train_c = pd.concat([y_build_c,y_val_c], axis=0)\n",
    "\n",
    "Xy_train_c1 = pd.concat([X_train_c1,y_train_c], axis=1)\n",
    "\n",
    "#Difference between number retained and number that leave\n",
    "counts = pd.value_counts(y_train_c)\n",
    "counts[0]-counts[1]\n",
    "\n",
    "#The following code ensures reproducibility of np.random.randint \n",
    "Xy_train_c1_pos = Xy_train_c1[Xy_train_c1['SEM_3_STATUS']==1].iloc[list(rng.randint(low=0,high=counts[1],size=counts[0]-counts[1])),:]\n",
    "\n",
    "#Now we concatenate rows to create the new data\n",
    "Xy_train_bal = pd.concat([Xy_train_c1,Xy_train_c1_pos],axis=0)\n",
    "\n",
    "X_train_bal = Xy_train_bal.drop('SEM_3_STATUS',axis=1)\n",
    "y_train_bal = Xy_train_bal['SEM_3_STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb9d00f8-a119-41d3-b145-75566c0b7842",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[44]: 0    3704\n1    3704\nName: SEM_3_STATUS, dtype: int64"
     ]
    }
   ],
   "source": [
    "pd.value_counts(Xy_train_bal['SEM_3_STATUS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9568f500-9adf-4b0b-b057-9f25c9b4a5e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#####Statistical subtleties and Coding customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b97cc58b-6e5a-4fe7-b3c0-45589829632c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As indicated earlier, there are essentially two types of features in our data, and it is best practcie to pre-process each type in a different way to prepare it for effective inclusion in our model.\n",
    "\n",
    "1. Quantitative or numeric variables are typically measured on different scales, and machine learning models can be sensitive to that. For example, while GPA's stay in the \"ones\" place value (between 0 and 4), units per semester are in the \"tens\". Variables such as parental income or financial aid award or student loan amounts would have many values in the tens of thousands or even higher. Values on a larger scale can wield disproportional influnce on model parameters due to their sheer magnitude, regardless their actual importance. Two methods used to level the playing field among predictors are \n",
    "\n",
    "  a. **Standardization.**\n",
    "  Suppose \\\\(x_1,x_2,\\ldots,x_n\\\\) are the values of a given variable in our data. Further let\n",
    "\n",
    "  \\\\(\\bar{x}=mean(x_1,x_2,\\ldots,x_n)\\\\) and \n",
    "  \\\\(s=sd(x_1,x_2,\\ldots,x_n)\\\\)\n",
    "  represent the mean and standard deviation of our variable, respectively. Then the *standardized* version of each value \\\\(x_i\\\\) would be\n",
    "  $$ z_i = \\frac{x_i - \\bar{x}}{s}$$\n",
    "\n",
    "  for \\\\(i = 1,\\ldots,n\\\\). This results in variable values typically between -5 and 5 for all variables.\n",
    "\n",
    "  b. **Min-Max Scaling.**\n",
    "  Suppose \\\\(x_1,x_2,\\ldots,x_n\\\\) are the values of a given variable in our data. Further let\n",
    "\n",
    "  \\\\(min = minimum(x_1,x_2,\\ldots,x_n)\\\\) and \n",
    "  \\\\(max=maximum(x_1,x_2,\\ldots,x_n)\\\\)\n",
    "  represent the smallest and largest values of our variable, respectively. Then the *max-min normalized* version of each value \\\\(x_i\\\\) would be\n",
    "  $$ u_i = \\frac{x_i - min}{max}$$\n",
    "\n",
    "  for \\\\(i=1,\\ldots,n\\\\). This results in variable values between 0 and 1 for all variables.\n",
    "\n",
    "More details on these techniques can be found in *Get Your Data Machine Learn Ready* in Module 3.\n",
    "\n",
    "\n",
    "2. Qualitative or categorical variables are primarily encoded in strings. This is a non-starter for analysis, as all variables input into a predictive model must be numerical. As mentioned above, **One hot encoding** is a technique used to assign numeric values to categorical variables without losing the identification of each observation as falling under a given category. The one hot encoder in scikit learn will create a new variable for each possibility in the original variable. For example, three new variables will be created corresponding to the FIRST_GEN_STATUS variable:\n",
    "\n",
    "  - First Generation indicator: each first gen student will be assigned a value of 1, all others 0.\n",
    "\n",
    "  - Continuing Generation indicator: each continuing gen student will be assigned a value of 1, all others 0.\n",
    "\n",
    "  - Unknown indicator: each student with unknown first gen status will be assigned a value of 1, all others 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f956d08c-b3f5-4bee-9223-c5d967f16ce3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Preparing the Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96672bcb-9876-4d85-8d58-dabc353cd5ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "At this stage we introduce yet another powerful tool within scikit learn - *Preprocessors*. These provide us the ability to create a smooth workflow that automatically implements a given transformation of our choosing based on the type of variable - quantitative or qualitative. It is highly recommended to apply the transformations on the train and test feature sets seperately yet simultaneously, in parallel. Preprocessors will be the first step of *Pipelines* that take us from our engineered data to classification results in one click."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16fbebcc-4522-4dfe-b4ff-2a64526ff408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Classes for transforming quantitative and qualitative variables, respectively in the Preprocessing module\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "\n",
    "#Module for create new transformed columns, needed for newly created indicators\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8eb0966-275c-4944-ad44-aa84b2529d3f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 1 - Select Features to Include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "975c1fe1-b6bc-4d10-ac78-ac1091f76f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Recall the features in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4f38580-2834-40cd-9d86-5d18f557fd84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[46]: Index(['RACE_ETHNICITY', 'GENDER', 'FIRST_GEN_STATUS', 'HS_MATH_GPA',\n       'HS_ENGL_GPA', 'COLLEGE', 'UNITS_ATTEMPTED_1', 'UNITS_COMPLETED_1',\n       'GPA_1', 'UNITS_ATTEMPTED_2', 'UNITS_COMPLETED_2', 'GPA_2',\n       'DFW_RATE_1', 'DFW_RATE_2', 'GRADE_POINTS_1', 'GRADE_POINTS_2'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "X_build_bal.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d43d9fb8-6852-48e0-8575-9e1c03fea8b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Due to multicollinearity or adverse impacts of high dimensionality, some machine learning models recommend a reduction of our feature space. The code below allows us to select a subset of features if so desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cbc3c81-0234-440f-936d-836599440543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#First identify the variables to include in the analysis\n",
    "selected_columns = ['HS_ENGL_GPA', 'HS_MATH_GPA', 'GPA_1','UNITS_ATTEMPTED_1','DFW_RATE_1', 'UNITS_ATTEMPTED_2', 'GPA_2', 'DFW_RATE_2', 'RACE_ETHNICITY', 'GENDER', 'FIRST_GEN_STATUS']\n",
    "\n",
    "#To use all features select line below\n",
    "#selected_columns = X_build_bal.columns\n",
    "\n",
    "Build_c = X_build_bal[selected_columns] \n",
    "Train_c = X_train_bal[selected_columns]\n",
    "\n",
    "Val_c = X_val_c1[selected_columns]\n",
    "Test_c = X_test_c1[selected_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8d193ab-6e09-44f3-b0b1-fe0e093abf7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 2 - Automatically Identify Qualitative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e26ac8cc-7f9e-4241-8532-fcd2058c8f0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Qualitative features are denoted by the 'object' type. List their names.\n",
    "categorical_columns=list(Build_c.select_dtypes('object').columns)\n",
    "\n",
    "#Identify the classes in each qualitative variable\n",
    "all_categories = [Build_c[col].unique() for col in categorical_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "469ed5b7-a176-4e86-add0-38a09dbfcb21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 3 - Automatically Identify Quantitative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "afc2eef2-ea97-4e14-b577-2bf5c9db58ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Quantitative features are denoted by the 'float64' type. List their names.\n",
    "numeric_columns=list(Build_c.select_dtypes('float64').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91422550-bd29-4b9f-a11a-e91b587046de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 4 - Create Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b4bb231-44fe-4669-8cd3-4dba00f95fe4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a function that inputs our feature set and transforms variables (standardizes numerical, and one hot encodes categorical) based on variable type\n",
    "preprocessor=ColumnTransformer([\n",
    "    ('num',StandardScaler(),numeric_columns),\n",
    "    ('cat',OneHotEncoder(categories = all_categories),categorical_columns),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81fc34c2-e348-4067-890f-c18c97b7e2ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The *preprocessor* object we just created allows us to visualize how the preprocessing workflow is applied to our dataframe. Click on the triangles to reveal details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eb992e7-6eae-41b2-8b7b-950adc756c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;,\n",
       "                                  &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;,\n",
       "                                  &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n",
       "       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n",
       "      dtype=object),\n",
       "                                                           array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n",
       "                                                           array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n",
       "      dtype=object)]),\n",
       "                                 [&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;,\n",
       "                                  &#x27;FIRST_GEN_STATUS&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n",
       "                                 [&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;,\n",
       "                                  &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;,\n",
       "                                  &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n",
       "       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n",
       "      dtype=object),\n",
       "                                                           array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n",
       "                                                           array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n",
       "      dtype=object)]),\n",
       "                                 [&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;,\n",
       "                                  &#x27;FIRST_GEN_STATUS&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;, &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;, &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;, &#x27;FIRST_GEN_STATUS&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n",
       "       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n",
       "      dtype=object),\n",
       "                          array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n",
       "                          array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n",
       "      dtype=object)])</pre></div></div></div></div></div></div></div></div></div></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;,\n                                  &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;,\n                                  &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]),\n                                (&#x27;cat&#x27;,\n                                 OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n      dtype=object),\n                                                           array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n                                                           array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n      dtype=object)]),\n                                 [&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;,\n                                  &#x27;FIRST_GEN_STATUS&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, StandardScaler(),\n                                 [&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;,\n                                  &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;,\n                                  &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]),\n                                (&#x27;cat&#x27;,\n                                 OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n      dtype=object),\n                                                           array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n                                                           array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n      dtype=object)]),\n                                 [&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;,\n                                  &#x27;FIRST_GEN_STATUS&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;HS_ENGL_GPA&#x27;, &#x27;HS_MATH_GPA&#x27;, &#x27;GPA_1&#x27;, &#x27;UNITS_ATTEMPTED_1&#x27;, &#x27;DFW_RATE_1&#x27;, &#x27;UNITS_ATTEMPTED_2&#x27;, &#x27;GPA_2&#x27;, &#x27;DFW_RATE_2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;RACE_ETHNICITY&#x27;, &#x27;GENDER&#x27;, &#x27;FIRST_GEN_STATUS&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[array([&#x27;Hispanic&#x27;, &#x27;White&#x27;, &#x27;Nonresident alien&#x27;, &#x27;Asian&#x27;,\n       &#x27;Black or African American&#x27;, &#x27;Two or More Races&#x27;, &#x27;Other&#x27;],\n      dtype=object),\n                          array([&#x27;Male&#x27;, &#x27;Female&#x27;], dtype=object),\n                          array([&#x27;First Generation&#x27;, &#x27;Continuing Generation&#x27;, &#x27;Unknown&#x27;],\n      dtype=object)])</pre></div></div></div></div></div></div></div></div></div></div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d738238-459a-478f-ba14-be40b44722a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 5 - Apply the Preprocessor to our Training and Test Data to Transform Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e341e014-599c-4c9f-a4bf-d6ab251f48bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Transform the training dataframes. Note that the output is a numpy array\n",
    "X_build_array = preprocessor.fit_transform(Build_c)\n",
    "X_train_array = preprocessor.fit_transform(Train_c)\n",
    "X_val_array = preprocessor.fit_transform(Val_c)\n",
    "X_test_array = preprocessor.fit_transform(Test_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f808648-3efd-491b-8fa5-f9f2abb0e114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###### Step 6 - Create Final Feature DataFrames with Column Names for Newly Created Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e182ebd-c1ac-4919-a3c0-299817d36ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Although scikit learn can work with NumPy arrays, it will be to our advantage to work with Pandas DataFrames in which variable names are clearly identified. The following code changes the arrays back to DataFrames, and also gives names to the new indicators resulting from the one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e3aa667-b682-4f1a-8472-0396c517b31a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get column names for one hot encoded columns\n",
    "ohe_column_names = (preprocessor.named_transformers_['cat']\n",
    "                    .get_feature_names_out(categorical_columns)) #Note that depending on your version of sklearn, you may need to use either get_feature_names_out or get_feature_names\n",
    "\n",
    "# Combine original numeric column names and one hot encoded column names\n",
    "all_column_names = numeric_columns + ohe_column_names.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaba3ce9-13d3-44b7-8d51-6513c87ef078",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the numpy array back to dataframe with column names to make model interpretation easier\n",
    "X_build_p = pd.DataFrame(X_build_array, columns=all_column_names, index = X_build_bal.index)\n",
    "X_train_p = pd.DataFrame(X_train_array, columns=all_column_names, index = X_train_bal.index)\n",
    "X_val_p = pd.DataFrame(X_val_array, columns=all_column_names, index = X_val_c1.index)\n",
    "X_test_p = pd.DataFrame(X_test_array, columns=all_column_names, index = X_test_c1.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e57f8040-5432-4f6f-84e2-0d6a5ab6f650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[55]: array(['RACE_ETHNICITY_Hispanic', 'RACE_ETHNICITY_White',\n       'RACE_ETHNICITY_Nonresident alien', 'RACE_ETHNICITY_Asian',\n       'RACE_ETHNICITY_Black or African American',\n       'RACE_ETHNICITY_Two or More Races', 'RACE_ETHNICITY_Other',\n       'GENDER_Male', 'GENDER_Female',\n       'FIRST_GEN_STATUS_First Generation',\n       'FIRST_GEN_STATUS_Continuing Generation',\n       'FIRST_GEN_STATUS_Unknown'], dtype=object)"
     ]
    }
   ],
   "source": [
    "ohe_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a44d2f3-cae0-48e8-abff-729e85619a0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We now have more variables than before we preprocessed the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6276b300-2509-4f88-be84-0c2a40850f6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(all_column_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3667a01-36c4-44e3-bea4-417dbd623ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[57]: ['HS_ENGL_GPA',\n 'HS_MATH_GPA',\n 'GPA_1',\n 'UNITS_ATTEMPTED_1',\n 'DFW_RATE_1',\n 'UNITS_ATTEMPTED_2',\n 'GPA_2',\n 'DFW_RATE_2',\n 'RACE_ETHNICITY_Hispanic',\n 'RACE_ETHNICITY_White',\n 'RACE_ETHNICITY_Nonresident alien',\n 'RACE_ETHNICITY_Asian',\n 'RACE_ETHNICITY_Black or African American',\n 'RACE_ETHNICITY_Two or More Races',\n 'RACE_ETHNICITY_Other',\n 'GENDER_Male',\n 'GENDER_Female',\n 'FIRST_GEN_STATUS_First Generation',\n 'FIRST_GEN_STATUS_Continuing Generation',\n 'FIRST_GEN_STATUS_Unknown']"
     ]
    }
   ],
   "source": [
    "all_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61a76baf-cc0e-47bb-ab99-a26141c22e72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Recall that the steps above were applied to the train and test sets in parallel. All preprocessing steps should be applied to the test set before model predictions are made. Remember not to view or analyze the test set in any way until after your final model is selected.\n",
    "\n",
    "Let's take a look at our preprocessed training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812c7f89-045d-403b-ac7d-bb3f83d67581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>DFW_RATE_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>DFW_RATE_2</th>\n",
       "      <th>RACE_ETHNICITY_Hispanic</th>\n",
       "      <th>RACE_ETHNICITY_White</th>\n",
       "      <th>RACE_ETHNICITY_Nonresident alien</th>\n",
       "      <th>RACE_ETHNICITY_Asian</th>\n",
       "      <th>RACE_ETHNICITY_Black or African American</th>\n",
       "      <th>RACE_ETHNICITY_Two or More Races</th>\n",
       "      <th>RACE_ETHNICITY_Other</th>\n",
       "      <th>GENDER_Male</th>\n",
       "      <th>GENDER_Female</th>\n",
       "      <th>FIRST_GEN_STATUS_First Generation</th>\n",
       "      <th>FIRST_GEN_STATUS_Continuing Generation</th>\n",
       "      <th>FIRST_GEN_STATUS_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105755</th>\n",
       "      <td>-3.027546</td>\n",
       "      <td>-2.727821</td>\n",
       "      <td>1.160747</td>\n",
       "      <td>-4.170247</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>-1.062209</td>\n",
       "      <td>-0.505191</td>\n",
       "      <td>0.681962</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73202</th>\n",
       "      <td>0.322258</td>\n",
       "      <td>0.561694</td>\n",
       "      <td>1.160747</td>\n",
       "      <td>0.913611</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>1.160634</td>\n",
       "      <td>0.996505</td>\n",
       "      <td>-0.759513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8941</th>\n",
       "      <td>-0.908283</td>\n",
       "      <td>0.030468</td>\n",
       "      <td>0.356776</td>\n",
       "      <td>-0.175787</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>0.207987</td>\n",
       "      <td>-0.486137</td>\n",
       "      <td>0.637609</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35002</th>\n",
       "      <td>-0.110710</td>\n",
       "      <td>-0.541622</td>\n",
       "      <td>0.941482</td>\n",
       "      <td>-0.538920</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>-1.062209</td>\n",
       "      <td>1.228726</td>\n",
       "      <td>-0.759513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97456</th>\n",
       "      <td>-2.662942</td>\n",
       "      <td>-2.339618</td>\n",
       "      <td>0.941482</td>\n",
       "      <td>-0.538920</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>0.525536</td>\n",
       "      <td>-0.629042</td>\n",
       "      <td>-0.018183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88943</th>\n",
       "      <td>-0.748768</td>\n",
       "      <td>-0.705076</td>\n",
       "      <td>-1.684071</td>\n",
       "      <td>0.187346</td>\n",
       "      <td>1.988308</td>\n",
       "      <td>-0.109562</td>\n",
       "      <td>-1.743703</td>\n",
       "      <td>1.835143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1754</th>\n",
       "      <td>-0.087922</td>\n",
       "      <td>-0.112555</td>\n",
       "      <td>-1.560384</td>\n",
       "      <td>0.187346</td>\n",
       "      <td>1.988308</td>\n",
       "      <td>0.843085</td>\n",
       "      <td>-1.743703</td>\n",
       "      <td>1.835143</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51091</th>\n",
       "      <td>0.094380</td>\n",
       "      <td>0.500398</td>\n",
       "      <td>-2.055135</td>\n",
       "      <td>-1.991451</td>\n",
       "      <td>2.211601</td>\n",
       "      <td>1.795732</td>\n",
       "      <td>-1.578568</td>\n",
       "      <td>1.835143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81134</th>\n",
       "      <td>1.416071</td>\n",
       "      <td>1.133783</td>\n",
       "      <td>0.839158</td>\n",
       "      <td>0.913611</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>0.843085</td>\n",
       "      <td>0.039754</td>\n",
       "      <td>-0.240582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8543</th>\n",
       "      <td>0.914740</td>\n",
       "      <td>1.195079</td>\n",
       "      <td>0.691764</td>\n",
       "      <td>-0.175787</td>\n",
       "      <td>-0.691208</td>\n",
       "      <td>-1.062209</td>\n",
       "      <td>-0.009786</td>\n",
       "      <td>0.105372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6472 rows × 20 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HS_ENGL_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>DFW_RATE_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>GPA_2</th>\n      <th>DFW_RATE_2</th>\n      <th>RACE_ETHNICITY_Hispanic</th>\n      <th>RACE_ETHNICITY_White</th>\n      <th>RACE_ETHNICITY_Nonresident alien</th>\n      <th>RACE_ETHNICITY_Asian</th>\n      <th>RACE_ETHNICITY_Black or African American</th>\n      <th>RACE_ETHNICITY_Two or More Races</th>\n      <th>RACE_ETHNICITY_Other</th>\n      <th>GENDER_Male</th>\n      <th>GENDER_Female</th>\n      <th>FIRST_GEN_STATUS_First Generation</th>\n      <th>FIRST_GEN_STATUS_Continuing Generation</th>\n      <th>FIRST_GEN_STATUS_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>105755</th>\n      <td>-3.027546</td>\n      <td>-2.727821</td>\n      <td>1.160747</td>\n      <td>-4.170247</td>\n      <td>-0.691208</td>\n      <td>-1.062209</td>\n      <td>-0.505191</td>\n      <td>0.681962</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>73202</th>\n      <td>0.322258</td>\n      <td>0.561694</td>\n      <td>1.160747</td>\n      <td>0.913611</td>\n      <td>-0.691208</td>\n      <td>1.160634</td>\n      <td>0.996505</td>\n      <td>-0.759513</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8941</th>\n      <td>-0.908283</td>\n      <td>0.030468</td>\n      <td>0.356776</td>\n      <td>-0.175787</td>\n      <td>-0.691208</td>\n      <td>0.207987</td>\n      <td>-0.486137</td>\n      <td>0.637609</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>35002</th>\n      <td>-0.110710</td>\n      <td>-0.541622</td>\n      <td>0.941482</td>\n      <td>-0.538920</td>\n      <td>-0.691208</td>\n      <td>-1.062209</td>\n      <td>1.228726</td>\n      <td>-0.759513</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>97456</th>\n      <td>-2.662942</td>\n      <td>-2.339618</td>\n      <td>0.941482</td>\n      <td>-0.538920</td>\n      <td>-0.691208</td>\n      <td>0.525536</td>\n      <td>-0.629042</td>\n      <td>-0.018183</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>88943</th>\n      <td>-0.748768</td>\n      <td>-0.705076</td>\n      <td>-1.684071</td>\n      <td>0.187346</td>\n      <td>1.988308</td>\n      <td>-0.109562</td>\n      <td>-1.743703</td>\n      <td>1.835143</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1754</th>\n      <td>-0.087922</td>\n      <td>-0.112555</td>\n      <td>-1.560384</td>\n      <td>0.187346</td>\n      <td>1.988308</td>\n      <td>0.843085</td>\n      <td>-1.743703</td>\n      <td>1.835143</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>51091</th>\n      <td>0.094380</td>\n      <td>0.500398</td>\n      <td>-2.055135</td>\n      <td>-1.991451</td>\n      <td>2.211601</td>\n      <td>1.795732</td>\n      <td>-1.578568</td>\n      <td>1.835143</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>81134</th>\n      <td>1.416071</td>\n      <td>1.133783</td>\n      <td>0.839158</td>\n      <td>0.913611</td>\n      <td>-0.691208</td>\n      <td>0.843085</td>\n      <td>0.039754</td>\n      <td>-0.240582</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>8543</th>\n      <td>0.914740</td>\n      <td>1.195079</td>\n      <td>0.691764</td>\n      <td>-0.175787</td>\n      <td>-0.691208</td>\n      <td>-1.062209</td>\n      <td>-0.009786</td>\n      <td>0.105372</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6472 rows × 20 columns</p>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_build_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e921a222-77b4-4c29-8f09-68f64e0a6332",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can see that all quantitative variables appear to fall within the range between -5 and 5 or so. Additionally, new one-hot encoded variables were created corresponding to the categories of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6047e7ab-716b-4d7a-aaec-92ad8b8a50e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Some models are sensitive to multicollinearity: when the features in our data are highly correlated with each other. This is a reason why it may be advisable to drop some of the variables before we proceed with the analysis. We use the next code chunk as an on/off switch, where we decide whether we'de use all features or a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f23b605-e0ad-4ba9-ac5c-6947a7d42b07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Keep all features\n",
    "final_column_names = all_column_names\n",
    "\n",
    "#Select a subset of features\n",
    "#final_column_names = ['HS_ENGL_GPA','HS_MATH_GPA','GPA_1','UNITS_ATTEMPTED_1','DFW_RATE_1','UNITS_ATTEMPTED_2','GPA_2','DFW_RATE_2','RACE_ETHNICITY_Two or More Races','RACE_ETHNICITY_Hispanic','RACE_ETHNICITY_Asian','RACE_ETHNICITY_Nonresident alien','RACE_ETHNICITY_White','RACE_ETHNICITY_Black or African American','RACE_ETHNICITY_Other','GENDER_Male','GENDER_Female','FIRST_GEN_STATUS_Continuing Generation','FIRST_GEN_STATUS_First Generation','FIRST_GEN_STATUS_Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2bf3659-3be2-46f8-9a73-f7bd4c3d9938",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_build_p1 = X_build_p[final_column_names]\n",
    "X_train_p1 = X_train_p[final_column_names]\n",
    "X_val_p1 = X_val_p[final_column_names]\n",
    "X_test_p1 = X_test_p[final_column_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0243d7f2-dbe8-41f9-8823-2b07b3a57adb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30f21478-84ce-4cc4-81d2-9485b6d4d4f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Analyzing and Learning from the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "623a37bd-94c7-4961-aae2-a9ede3a26405",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Model Specification - The Logistic Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc8e1d01-cfc3-4e80-99a6-bd853f3c4662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Logistic Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a805e085-cc47-46fe-880b-82f145f858da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The Logistic model is used for classification, but in the context of classical statistics where it was birthed, it is considered a regression model. For this model, whether the name \"regression\" or \"classification\" is used, we will use this method to predict the label of a qualitative variable. How can a model be regression and classification at the same time? The idea is a two step process\n",
    "\n",
    "1. First we use features in the data to model a quantitative variable: the chances (probability) that each individual in our data possesses a characteristic of interest (i.e. is a member of the \"positive\" class: \\\\(y=1\\\\)). In this tutorial, the characteristic of interest is departure from the university (thus, the \"positive\" class is not intrinsically positive). \n",
    "\n",
    "2. Next, we use the probability to assign each individual to one of the classes based on a chosen threshold. The most common choice is \\\\(c=0.50\\\\); if our model predicts it is more likely than not that the individual possesses the characteristic, we assign them to that class.\n",
    "\n",
    "One challenge associated with step 1 however is that the probability we are hoping to predict is a precisely defined mathematical quantity that is confined to the region from 0 to 1. To ensure that our estimates retain this quality, we take a linear function of our input, and plug it into a function we know will provide probabilities. A popular choice of function for this purpose is the *logistic* function, a special case of the *softmax*:\n",
    "\n",
    "$$\\pi(x)=\\frac{e^x}{1+e^x}$$\n",
    "\n",
    "Since the function \\\\(f(x)=e^x\\\\) is never negative, we are guaranteed that this function will always be greater than zero. Since the denominator is one more than the numerator,we are guaranteed that this function will always spit out a number less than 1. Let's get an idea of what the logistic function looks like. Sometimes it is referred to as *sigmoidal* because of its *S* shape. Here we use it to as a hypothetical model for the relationship between DFW units and probability of dropout:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "403bb74f-b6d3-40a0-a211-4d30253ef115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\")) {                    Plotly.newPlot(                        \"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.1,0.2,0.30000000000000004,0.4,0.5,0.6000000000000001,0.7000000000000001,0.8,0.9,1.0,1.1,1.2000000000000002,1.3,1.4000000000000001,1.5,1.6,1.7000000000000002,1.8,1.9000000000000001,2.0,2.1,2.2,2.3000000000000003,2.4000000000000004,2.5,2.6,2.7,2.8000000000000003,2.9000000000000004,3.0,3.1,3.2,3.3000000000000003,3.4000000000000004,3.5,3.6,3.7,3.8000000000000003,3.9000000000000004,4.0,4.1000000000000005,4.2,4.3,4.4,4.5,4.6000000000000005,4.7,4.800000000000001,4.9,5.0,5.1000000000000005,5.2,5.300000000000001,5.4,5.5,5.6000000000000005,5.7,5.800000000000001,5.9,6.0,6.1000000000000005,6.2,6.300000000000001,6.4,6.5,6.6000000000000005,6.7,6.800000000000001,6.9,7.0,7.1000000000000005,7.2,7.300000000000001,7.4,7.5,7.6000000000000005,7.7,7.800000000000001,7.9,8.0,8.1,8.200000000000001,8.3,8.4,8.5,8.6,8.700000000000001,8.8,8.9,9.0,9.1,9.200000000000001,9.3,9.4,9.5,9.600000000000001,9.700000000000001,9.8,9.9,10.0,10.100000000000001,10.200000000000001,10.3,10.4,10.5,10.600000000000001,10.700000000000001,10.8,10.9,11.0,11.100000000000001,11.200000000000001,11.3,11.4,11.5,11.600000000000001,11.700000000000001,11.8,11.9,12.0,12.100000000000001,12.200000000000001,12.3,12.4,12.5,12.600000000000001,12.700000000000001,12.8,12.9,13.0,13.100000000000001,13.200000000000001,13.3,13.4,13.5,13.600000000000001,13.700000000000001,13.8,13.9,14.0,14.100000000000001,14.200000000000001,14.3,14.4,14.5,14.600000000000001,14.700000000000001,14.8,14.9,15.0,15.100000000000001,15.200000000000001,15.3,15.4,15.5,15.600000000000001,15.700000000000001,15.8,15.9,16.0,16.1,16.2,16.3,16.400000000000002,16.5,16.6,16.7,16.8,16.900000000000002,17.0,17.1,17.2,17.3,17.400000000000002,17.5,17.6,17.7,17.8,17.900000000000002,18.0,18.1,18.2,18.3,18.400000000000002,18.5,18.6,18.7,18.8,18.900000000000002,19.0,19.1,19.200000000000003,19.3,19.400000000000002,19.5,19.6,19.700000000000003,19.8,19.900000000000002],\"xaxis\":\"x\",\"y\":[0.004070137715896127,0.004299276419903346,0.004541256245830871,0.0047967900155682945,0.005066629333466254,0.005351566605225267,0.0056524371512370695,0.005970121417520965,0.006305547287335863,0.00665969249645843,0.007033587154995159,0.007428316378435995,0.007845023030455625,0.008284910579719272,0.00874924607264706,0.009239363223728833,0.00975666562455135,0.01030263007219559,0.010878810017073925,0.011486839129596605,0.012128434984274234,0.012805402858966817,0.013519639645969639,0.014273137870468841,0.01506798981059282,0.01590639171181471,0.016790648086813815,0.017723176090062267,0.018706509954354605,0.019743305474224586,0.020836344518680414,0.021988539552919663,0.023202938145644073,0.024482727435265486,0.025831238524664058,0.027251950770216075,0.028748495926539955,0.030324662103807975,0.031984397489533266,0.033731813781467224,0.03557118927263616,0.0375069715236202,0.03954377955095296,0.04168640545402418,0.04393981539614133,0.046309149848500354,0.048799722998800005,0.05141702121918567,0.05416670048123608,0.05705458259892042,0.06008665017400762,0.06326904011246003,0.06660803557509065,0.07011005622141818,0.07378164660246529,0.07762946255648838,0.08166025546159467,0.08588085420122657,0.09029814470291989,0.09491904691793245,0.09975048911968513,0.10479937941282438,0.110072574362503,0.1155768446755336,0.12131883789173686,0.12730503807537166,0.13354172253321248,0.14003491562777273,0.14679033980138242,0.1538133639792068,0.1611089495765852,0.16868159439781957,0.1765352747791167,0.18467338639691716,0.19309868423321644,0.20181322226037882,0.21081829347774714,0.22011437099927417,0.22970105095339816,0.23957699801126903,0.2497398944048824,0.260186393330312,0.2709120776506936,0.28191142481665027,0.29317777890643243,0.3047033306524346,0.3164791062636843,0.32849496577459425,0.34073961154861465,0.35320060744201437,0.3658644089891993,0.3787164048089321,0.3917409692534857,0.40492152613386606,0.4182406231581638,0.4316800165217519,0.4452207648927854,0.45884333184977205,0.4725276956554064,0.4862534650976451,0.5,0.5137465349023551,0.5274723043445939,0.5411566681502281,0.5547792351072147,0.5683199834782481,0.5817593768418364,0.5950784738661342,0.6082590307465144,0.6212835951910679,0.6341355910108007,0.6467993925579859,0.6592603884513856,0.671505034225406,0.6835208937363156,0.6952966693475654,0.7068222210935677,0.7180885751833499,0.7290879223493065,0.739813606669688,0.7502601055951176,0.7604230019887311,0.7702989490466019,0.779885629000726,0.7891817065222528,0.7981867777396212,0.8069013157667837,0.815326613603083,0.8234647252208833,0.8313184056021805,0.8388910504234148,0.8461866360207934,0.8532096601986177,0.8599650843722273,0.8664582774667876,0.8726949619246284,0.8786811621082631,0.8844231553244665,0.889927425637497,0.8952006205871756,0.9002495108803149,0.9050809530820676,0.9097018552970803,0.9141191457987734,0.9183397445384054,0.9223705374435116,0.9262183533975348,0.9298899437785819,0.9333919644249093,0.93673095988754,0.9399133498259925,0.9429454174010796,0.9458332995187639,0.9485829787808143,0.9512002770012,0.9536908501514997,0.9560601846038587,0.9583135945459759,0.9604562204490471,0.9624930284763799,0.9644288107273639,0.9662681862185328,0.9680156025104667,0.9696753378961921,0.9712515040734601,0.972748049229784,0.9741687614753359,0.9755172725647345,0.9767970618543559,0.9780114604470803,0.9791636554813196,0.9802566945257755,0.9812934900456454,0.9822768239099378,0.9832093519131861,0.9840936082881853,0.9849320101894072,0.9857268621295312,0.9864803603540304,0.9871945971410332,0.9878715650157258,0.9885131608704034,0.9891211899829261,0.9896973699278044,0.9902433343754486,0.9907606367762711,0.991250753927353,0.9917150894202807,0.9921549769695444,0.992571683621564,0.9929664128450049,0.9933403075035416,0.9936944527126641,0.994029878582479,0.9943475628487629,0.9946484333947747,0.9949333706665338,0.9952032099844317,0.9954587437541691,0.9957007235800966],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DFW_UNITS\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability of Dropout\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"The Logistic Curve\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\")) {                    Plotly.newPlot(                        \"2ee7554d-4aab-4b27-a9d1-d00c5943c51e\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.0,0.1,0.2,0.30000000000000004,0.4,0.5,0.6000000000000001,0.7000000000000001,0.8,0.9,1.0,1.1,1.2000000000000002,1.3,1.4000000000000001,1.5,1.6,1.7000000000000002,1.8,1.9000000000000001,2.0,2.1,2.2,2.3000000000000003,2.4000000000000004,2.5,2.6,2.7,2.8000000000000003,2.9000000000000004,3.0,3.1,3.2,3.3000000000000003,3.4000000000000004,3.5,3.6,3.7,3.8000000000000003,3.9000000000000004,4.0,4.1000000000000005,4.2,4.3,4.4,4.5,4.6000000000000005,4.7,4.800000000000001,4.9,5.0,5.1000000000000005,5.2,5.300000000000001,5.4,5.5,5.6000000000000005,5.7,5.800000000000001,5.9,6.0,6.1000000000000005,6.2,6.300000000000001,6.4,6.5,6.6000000000000005,6.7,6.800000000000001,6.9,7.0,7.1000000000000005,7.2,7.300000000000001,7.4,7.5,7.6000000000000005,7.7,7.800000000000001,7.9,8.0,8.1,8.200000000000001,8.3,8.4,8.5,8.6,8.700000000000001,8.8,8.9,9.0,9.1,9.200000000000001,9.3,9.4,9.5,9.600000000000001,9.700000000000001,9.8,9.9,10.0,10.100000000000001,10.200000000000001,10.3,10.4,10.5,10.600000000000001,10.700000000000001,10.8,10.9,11.0,11.100000000000001,11.200000000000001,11.3,11.4,11.5,11.600000000000001,11.700000000000001,11.8,11.9,12.0,12.100000000000001,12.200000000000001,12.3,12.4,12.5,12.600000000000001,12.700000000000001,12.8,12.9,13.0,13.100000000000001,13.200000000000001,13.3,13.4,13.5,13.600000000000001,13.700000000000001,13.8,13.9,14.0,14.100000000000001,14.200000000000001,14.3,14.4,14.5,14.600000000000001,14.700000000000001,14.8,14.9,15.0,15.100000000000001,15.200000000000001,15.3,15.4,15.5,15.600000000000001,15.700000000000001,15.8,15.9,16.0,16.1,16.2,16.3,16.400000000000002,16.5,16.6,16.7,16.8,16.900000000000002,17.0,17.1,17.2,17.3,17.400000000000002,17.5,17.6,17.7,17.8,17.900000000000002,18.0,18.1,18.2,18.3,18.400000000000002,18.5,18.6,18.7,18.8,18.900000000000002,19.0,19.1,19.200000000000003,19.3,19.400000000000002,19.5,19.6,19.700000000000003,19.8,19.900000000000002],\"xaxis\":\"x\",\"y\":[0.004070137715896127,0.004299276419903346,0.004541256245830871,0.0047967900155682945,0.005066629333466254,0.005351566605225267,0.0056524371512370695,0.005970121417520965,0.006305547287335863,0.00665969249645843,0.007033587154995159,0.007428316378435995,0.007845023030455625,0.008284910579719272,0.00874924607264706,0.009239363223728833,0.00975666562455135,0.01030263007219559,0.010878810017073925,0.011486839129596605,0.012128434984274234,0.012805402858966817,0.013519639645969639,0.014273137870468841,0.01506798981059282,0.01590639171181471,0.016790648086813815,0.017723176090062267,0.018706509954354605,0.019743305474224586,0.020836344518680414,0.021988539552919663,0.023202938145644073,0.024482727435265486,0.025831238524664058,0.027251950770216075,0.028748495926539955,0.030324662103807975,0.031984397489533266,0.033731813781467224,0.03557118927263616,0.0375069715236202,0.03954377955095296,0.04168640545402418,0.04393981539614133,0.046309149848500354,0.048799722998800005,0.05141702121918567,0.05416670048123608,0.05705458259892042,0.06008665017400762,0.06326904011246003,0.06660803557509065,0.07011005622141818,0.07378164660246529,0.07762946255648838,0.08166025546159467,0.08588085420122657,0.09029814470291989,0.09491904691793245,0.09975048911968513,0.10479937941282438,0.110072574362503,0.1155768446755336,0.12131883789173686,0.12730503807537166,0.13354172253321248,0.14003491562777273,0.14679033980138242,0.1538133639792068,0.1611089495765852,0.16868159439781957,0.1765352747791167,0.18467338639691716,0.19309868423321644,0.20181322226037882,0.21081829347774714,0.22011437099927417,0.22970105095339816,0.23957699801126903,0.2497398944048824,0.260186393330312,0.2709120776506936,0.28191142481665027,0.29317777890643243,0.3047033306524346,0.3164791062636843,0.32849496577459425,0.34073961154861465,0.35320060744201437,0.3658644089891993,0.3787164048089321,0.3917409692534857,0.40492152613386606,0.4182406231581638,0.4316800165217519,0.4452207648927854,0.45884333184977205,0.4725276956554064,0.4862534650976451,0.5,0.5137465349023551,0.5274723043445939,0.5411566681502281,0.5547792351072147,0.5683199834782481,0.5817593768418364,0.5950784738661342,0.6082590307465144,0.6212835951910679,0.6341355910108007,0.6467993925579859,0.6592603884513856,0.671505034225406,0.6835208937363156,0.6952966693475654,0.7068222210935677,0.7180885751833499,0.7290879223493065,0.739813606669688,0.7502601055951176,0.7604230019887311,0.7702989490466019,0.779885629000726,0.7891817065222528,0.7981867777396212,0.8069013157667837,0.815326613603083,0.8234647252208833,0.8313184056021805,0.8388910504234148,0.8461866360207934,0.8532096601986177,0.8599650843722273,0.8664582774667876,0.8726949619246284,0.8786811621082631,0.8844231553244665,0.889927425637497,0.8952006205871756,0.9002495108803149,0.9050809530820676,0.9097018552970803,0.9141191457987734,0.9183397445384054,0.9223705374435116,0.9262183533975348,0.9298899437785819,0.9333919644249093,0.93673095988754,0.9399133498259925,0.9429454174010796,0.9458332995187639,0.9485829787808143,0.9512002770012,0.9536908501514997,0.9560601846038587,0.9583135945459759,0.9604562204490471,0.9624930284763799,0.9644288107273639,0.9662681862185328,0.9680156025104667,0.9696753378961921,0.9712515040734601,0.972748049229784,0.9741687614753359,0.9755172725647345,0.9767970618543559,0.9780114604470803,0.9791636554813196,0.9802566945257755,0.9812934900456454,0.9822768239099378,0.9832093519131861,0.9840936082881853,0.9849320101894072,0.9857268621295312,0.9864803603540304,0.9871945971410332,0.9878715650157258,0.9885131608704034,0.9891211899829261,0.9896973699278044,0.9902433343754486,0.9907606367762711,0.991250753927353,0.9917150894202807,0.9921549769695444,0.992571683621564,0.9929664128450049,0.9933403075035416,0.9936944527126641,0.994029878582479,0.9943475628487629,0.9946484333947747,0.9949333706665338,0.9952032099844317,0.9954587437541691,0.9957007235800966],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"DFW_UNITS\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Probability of Dropout\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"The Logistic Curve\"}},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0,20,0.1) #Variable representing DFW Units\n",
    "scale = 0.55\n",
    "shift = 10\n",
    "\n",
    "PROB_DROPOUT = np.exp(scale*(x-shift))/(1+np.exp(scale*(x-shift)))\n",
    "fig = px.line(x=x,y=PROB_DROPOUT)\n",
    "fig.update_layout(title = 'The Logistic Curve',xaxis_title='DFW_UNITS', yaxis_title='Probability of Dropout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca54ff6f-7dd2-4b1d-baed-e91860610e4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: Using a 50% threshold (i.e. \\\\(c=0.50\\\\)), how many DFW units would a student need to accrue for our model to classify them as likely to drop out?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a74b2cf-894f-4e1b-82de-1c19572fdc3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: Modify the values of the *scale* and *shift* variables in the preceeding code chunk. Describe the impact each has on the appearance of the logistic curve.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a5d88b5-beb4-416c-810d-44f277437425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As stated above, once probabilities are generated, we define a classifier by assigning a given example to the 0 label if the probability is below a given, user determined threshold \\\\(c\\\\), and 1 if the probability is above that threshold.\n",
    "\n",
    "In the case where we incorporate more than one feature to predict this probability, the model is called *Multiple Logistic Regression*, and the two step process remains the same. Let's visualize in the following diagram:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff023a80-5b86-483e-827c-5865596c7fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**FIGURE: Multiple Logistic Regression: a two step process**\n",
    "\n",
    "<img src=\"files/ml-file-store/bronze/logistic_flow.png\" width=\"800\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56b49154-88cb-4429-bcc9-ccf155e03c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As seen in the figure, the regression task correnponds to using the features of each observation to predict the probability of belonging to the class of interest, i.e. the one associated with the \"1\" label. In our case this is the event that a student is not retained in semester 3. We start by combining the values of the features for each individual in a linear way: \n",
    "\n",
    "$$\\vec{x}\\vec{\\beta} = \\beta_0+\\beta_1\\ x_{1i}+\\beta_2\\ x_{2i}+\\cdots+\\beta_{p-1}\\ x_{(p-1)i}$$. \n",
    "\n",
    "Estimates for these \\\\(\\beta\\\\)'s are learned from our data and are called coefficients. Then, probabilities are calculated by\n",
    "\n",
    "$$\\hat{\\pi}(\\vec{x}) = \\frac{\\exp(\\beta_0+\\beta_1\\ x_{1i}+\\beta_2\\ x_{2i}+\\cdots+\\beta_{p-1}\\ x_{(p-1)i})}{1+\\exp(\\beta_0+\\beta_1\\ x_{1i}+\\beta_2\\ x_{2i}+\\cdots+\\beta_{p-1}\\ x_{(p-1)i})}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0db72694-e4c6-46fc-b220-a5a4cdd66f1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Objective Function for Parameter Estimation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47fe7ce5-2d85-4719-b7a2-584dca1c48d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The \\\\(\\beta_i\\\\) values are parameters that characterize the true relationship between student characteristics and probability of leaving campus. They cannot be known, and must be estimated from the data. The objective function for logistic regression is derived using the *maximum likelihood* principle from classical statistics. The *log likelihood* \\\\(l(\\vec{\\beta})\\\\) is a measurement of the probability we would randomly obtain our observed data. It is seen primarily as a function of the parameters that define our model, the \\\\(\\beta_i\\\\)'s, though the features and label also play a role in its calculation. To put it another way, for a given set of values for our mix of academic and demographic variables it is conceivable that there are a variety of reasonable values for the \\\\(\\beta_i\\\\)'s (and thus probability of departure) that might fit the observed data. Let's choose values for the \\\\(\\beta_i\\\\)'s that *maximize* (i.e. make as large as possible) the probability of their observed class. Scikit Learn uses computational algorithms to identify the values of the \\\\(\\beta_i\\\\)'s that maximize this probability. In an equivalent formulation, it will be beneficial to frame this task as *minimizing* the objective function \\\\(-l(\\vec{\\beta})\\\\). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60802a2e-2ace-4798-92c8-9547a5d3f8f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Criteria for Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a5669b-4aa6-4059-83ea-845f98cfd066",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Confusion Matrix**\n",
    "\n",
    "The *confusion matrix* cross-tabulates the classes predicted by our model versus the actual classes. The four entries correspond to\n",
    "- True Negatives: Observations from the 0 class that we classified as 0's\n",
    "- False Negatives: Observations from the 1 class that we classified as 0's\n",
    "- False Positives: Observations from the 0 class that we classified as 1's\n",
    "- True Positives: Observations from the 1 class that we classified as 1's\n",
    "\n",
    "A perfect classifier has 0 values in the top right (FP=0) and bottom left (FN=0).\n",
    "\n",
    "There are many other classification metrics that may be investigated in scikit learn (see [here](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)). Most can be understood in the framework of the confusion matrix, we discuss some below.\n",
    "\n",
    "<img src=\"files/ml-file-store/bronze/conf_matrx.png\" width=\"800\" height=\"500\"> \n",
    "\n",
    "**Accuracy and AUC**\n",
    "\n",
    "*Accuracy* represents the proportion of all classifications that were done correctly. \n",
    "\n",
    "$$\n",
    "Acc = \\frac{TP+TN}{TP+TN+FP+FN}\n",
    "$$\n",
    "\n",
    "*AUC* refers to *Area Under the Curve*, and will be discussed later.\n",
    "\n",
    "*Example: In our context, Acc represents the proportion of students we classified as either being retained in term 3 or not.*\n",
    "\n",
    "**Precision**\n",
    "\n",
    "*Precision* represents the proportion of all observations clasified as 1's that were truly 1's.\n",
    "\n",
    "$$\n",
    "Precision = \\frac{TP}{TP+FP}\n",
    "$$\n",
    "\n",
    "*Example: In our context, Precision represents the proportion of students we classified as being retained in term 3 that actually were.*\n",
    "\n",
    "**Recall** \n",
    "\n",
    "*Recall* represents the proportion of all observations that are actually 1's that were classified as 1's.\n",
    "\n",
    "$$\n",
    "Recall = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "*Example: In our context, Recall represents the proportion of students that were actually retained in term 3 that we classify as being retained.*\n",
    "\n",
    "**Sensitivity and Specificity**\n",
    "\n",
    "These are terms used heavily in medical literature and directly applicable to machine learning classification.\n",
    "\n",
    "*Sensitivity* is equivalent to recall.\n",
    "$$\n",
    "Sensitivity = \\frac{TP}{TP+FN}\n",
    "$$\n",
    "\n",
    "*Specificity* represents the proportion of all observations that are actually 0's that were classified as 0's.\n",
    "$$\n",
    "Specificity = \\frac{TN}{TN+FP}\n",
    "$$\n",
    "\n",
    "*Example: In our context, Specificity represents the proportion of students that were actually not retained in term 3 that we classify as being not retained.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a60ed73-ad45-4bac-9703-7f9fe6859fba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Model Fitting - Learning parameters and learning from parameter estimates (training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe2d96e-07a9-4ab5-85fe-0a6b74b9e9e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Our first approach is to fit the model in which our entire curated list of predictors is included. Let's call this the \"full model\". Because we are interested in gleaning insights available through statistical inference and not black box machine learning, we use the statsmodels library as our primary workhorse instead of scikit learn. That being said, the latter will play a supporting role throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9706bbc7-3d1c-4c11-a4db-17bab29496aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe5c7f3-b4ef-4744-8de5-3ae896fef051",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using the training data to learn optimal weights for the features included in our model can be done in just a few lines of code with [statsmodels](https://www.statsmodels.org/stable/index.html). This Python library is useful for applying classical statistical methods to a variety of hypotheses and data types. The main benefit for us is its ability to generate a thorough, traditional multiple linear regression output, putting parameter inference at our fingertips. This is not readily available using scikitlearn. The latter however is tailor made for the steps of the machine learning workflow, so we'll be seeing more of it soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ef2a7d4-2a6d-4412-a8e3-bd10d8d50867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning:\n\nIn a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:           SEM_3_STATUS   No. Observations:                 6472\nModel:                            GLM   Df Residuals:                     6454\nModel Family:                Binomial   Df Model:                           17\nLink Function:                  logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3095.7\nDate:                Thu, 11 Jan 2024   Deviance:                       6191.4\nTime:                        07:52:09   Pearson chi2:                 6.10e+03\nNo. Iterations:                    49                                         \nCovariance Type:            nonrobust                                         \n============================================================================================================\n                                               coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------------------------------------\nconst                                        0.1817      0.033      5.494      0.000       0.117       0.247\nHS_ENGL_GPA                                 -0.0061      0.061     -0.100      0.921      -0.125       0.113\nHS_MATH_GPA                                  0.1357      0.059      2.301      0.021       0.020       0.251\nGPA_1                                       -0.0808      0.098     -0.822      0.411      -0.274       0.112\nUNITS_ATTEMPTED_1                           -0.0026      0.036     -0.073      0.942      -0.073       0.068\nDFW_RATE_1                                   0.5338      0.095      5.620      0.000       0.348       0.720\nUNITS_ATTEMPTED_2                           -0.4289      0.036    -11.967      0.000      -0.499      -0.359\nGPA_2                                       -0.4192      0.104     -4.038      0.000      -0.623      -0.216\nDFW_RATE_2                                   0.7584      0.099      7.626      0.000       0.563       0.953\nRACE_ETHNICITY_Hispanic                     -0.1704      0.068     -2.490      0.013      -0.304      -0.036\nRACE_ETHNICITY_White                         0.4276      0.091      4.715      0.000       0.250       0.605\nRACE_ETHNICITY_Nonresident alien             0.8027      0.157      5.106      0.000       0.495       1.111\nRACE_ETHNICITY_Asian                        -0.3644      0.085     -4.303      0.000      -0.530      -0.198\nRACE_ETHNICITY_Black or African American     0.0044      0.142      0.031      0.975      -0.274       0.282\nRACE_ETHNICITY_Two or More Races            -0.2348      0.147     -1.594      0.111      -0.524       0.054\nRACE_ETHNICITY_Other                        -0.2833      0.242     -1.168      0.243      -0.759       0.192\nGENDER_Male                                 -0.0282      0.039     -0.717      0.474      -0.105       0.049\nGENDER_Female                                0.2099      0.036      5.911      0.000       0.140       0.279\nFIRST_GEN_STATUS_First Generation           -0.1119      0.057     -1.953      0.051      -0.224       0.000\nFIRST_GEN_STATUS_Continuing Generation       0.0226      0.050      0.457      0.648      -0.074       0.120\nFIRST_GEN_STATUS_Unknown                     0.2709      0.082      3.321      0.001       0.111       0.431\n============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add a constant to get an intercept\n",
    "X_build_sm = sm.add_constant(X_build_p1)\n",
    "X_test_sm = sm.add_constant(X_test_p1)\n",
    "# Fit the logistic regression using ‘GLM’\n",
    "lrs = sm.GLM(y_build_bal, X_build_sm, family=sm.families.Binomial()).fit()\n",
    "\n",
    "print(lrs.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "269715bd-d950-4d08-8aea-362daeb5f0b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Interpreting Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cd5404f-e1d7-4ef8-a2a3-f8a03f6c652f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "When the output drops in our notebook, all of the numbers can feel intimidating. Fortunately, most of this output is relevant for detailed *statistical* analysis, not machine learning which is our goal. Thus for our purposes we'll be zeroing in on only a couple of items: \n",
    "\n",
    "**P>|z| and Coefficients**\n",
    "\n",
    "These are *p-values* corresponding to the significance test\n",
    "$$H_0:\\beta_i = 0 \\text{ vs } H_a:\\beta_i \\neq 0$$\n",
    "Of the 15 predictors in our model, 9 are significant at the 0.05 level. One benefit of a baseline statistical model in the machine learning is that it provides a precise, detailed interpretation of how specific features impact the response variable. In general, the interpretation of \\\\(b_j\\\\) is as follows:\n",
    "\n",
    "*We expect the odds of dropout to increase/decrease by a factor of \\\\(e^{b_j}\\\\) when \\\\(x_j\\\\) increases by one unit.*\n",
    "\n",
    "For example, the estimated regression coefficient for DFW_RATE_2 is *0.6579*. Since \\\\(e^{0.6579}=1.93\\\\), this indicates that with all other variables equal, if student B has a DFW_RATE_2 that is one standard deviation higher than student A, then student B is 1.93 times(0r 1.93-1 = 93%) more likely to leave the university than student A.\n",
    "\n",
    "Similarly, the estimated regression coefficient for FIRST_GEN_STATUS_First Generation is *-0.2805*. Since \\\\(e^{-0.2805}=0.76\\\\), this indicates that with all other variables equal, if student B is FIRST_GEN_STATUS_First Generation while student A is not, then student B is (1-0.76)=34% less likely to leave the university than student A.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a57e877-bf32-4ced-ab40-957b04fe6c59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9307335337320999 0.7554059440422217\n"
     ]
    }
   ],
   "source": [
    "print(np.exp(0.6579),np.exp(-0.2805))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa450a0a-b377-44e1-ac49-8e8211f94bcb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This gives us overall performance on prediction of students who were and were not retained. Let's dissect this performance by creating the *confusion matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "729ddabf-12bf-46ba-bf3f-5299591d5480",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc1a7d77-0b67-4711-aaed-9c604d1de076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[66]: <sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f11b67ce790>"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_lrs = confusion_matrix(y_build_bal, list(map(round,lrs.predict(X_build_sm))), labels=None, sample_weight=None, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(cm_lrs, display_labels=None)\n",
    "disp.plot()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62131329-d1f0-4a98-b10d-84b9c4cb1b8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can thus calculate the accuracy at about 77%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8d16d2a-084c-4634-8c37-57c5b88b41ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[67]: 0.7665327564894932"
     ]
    }
   ],
   "source": [
    "cm = cm_lrs\n",
    "\n",
    "acc_lrs = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[1,1]+cm[0,1]+cm[1,0])\n",
    "\n",
    "acc_lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2aae2cc2-b572-410f-967b-f0c54e1fc6d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The confusion matrix reveals that our ML algorithm seems to have done a satisfactory job of addressing one of the most important challenges in higher ed. If we slice it \n",
    "\n",
    "- vertically: we see that about 82% of students predicted to leave actually did \n",
    "- horizontally: 68% of students that actually left the university were predicted to leave."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8b97475-fc51-4983-8355-b43476d0d003",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**EXERCISE: How was the 82% calculated? Write it as a fraction. What is this metric called? How was the 68% calculated? Write it as a fraction. What is this metric called?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "706793f9-2e53-48cd-8cbf-7b48ba640d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "While this seems promising for an essentially fresh out the box model, we have to remember that the approximately 77% accurate predictions were made on the *training set*, i.e. the data used to build the model. In our running human learning analogy, all we've done is **memorize** a set of facts and definitions, and regurgitate them nearly flawlessly on a multiple choice exam that consisted of the precisely the same material we studied.  Unfortunately that is not indicative of whether we would be able to write an essay on the material we studied, or apply concepts learned to a scenario not discussed in class. To do that we'd need to examine our acuracy on an unseen test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b632d29-9a09-409b-8e0a-2a176ff65cba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd26de2d-7c11-44e2-88df-b2b69e48de95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Model Validation and Selection - Hyperparameter tuning and model generalizability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a12747a-f384-43b3-b655-41266eb3feb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A model's performance on the training set is an initial indication of how well parameter choices do at minimizing the objective function. This is an important characteristic we build in to the modeling process. However, if our ultimate aim is deployment to new data, then it is mandatory that model choice be informed by applying the prediction and scoring steps of the *Fit-Predict-Score* cycle to unseen data.\n",
    "\n",
    "As discussed in *Explaining Machine Learning Cycle With Hyperparameter Tuning* in Module 4, *k-Fold Cross Validation* is a powerful process we can apply to our data and model to simulate performance on unseen data. Figure 3 gives a visual representation on our example training data. To perform 6-fold cross validation, we randomly partition the training data into six mutually exclusive samples of size 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c8408eb-eb29-4991-be79-db3daf07130e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Figure 3:** An example of 6-fold cross validation on a the training set of a dataframe with 15 observations.\n",
    "![ih](files/ml-file-store/bronze/k_fold_pic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4df88850-4bc9-4d2f-b6aa-1ddac1670c75",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "These six mutually exclusive samples of size 2 refered to above will serve as test sets (referred to as *validation* sets in this context) for 6 independent batches of *Fit-Predict-Score* cycles. The corresponding training sets (referred to as *building* sets in this context) are the remaining 10 observations not selected for the validation set. For each batch, we fit the data with various combinations of features and keep track to identify the best subset. To execute this process we first import the *cross_val_score* method from the *model_selection* module in scikit learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2205be2-0e7a-4784-b81b-bf4f054ef831",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "425badbe-f172-4e29-a73f-6d1e951136f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 1: Identify Feature Search Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b7e0854-a498-4e3f-a67f-956b39223d4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "List the set of features you'd like to include in feature selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4961ab4e-198c-4a4e-9bb7-2beb29d2e866",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 2: Specify Number of Folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc898c42-45ce-47c8-8ffd-01f641c398b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To what extent should we divvy up our data up for validation? Consider two extremes:\n",
    "\n",
    "\\\\(k=2\\\\)\n",
    "\n",
    "Set one validation set that is half of the training set.\n",
    " - Pro: Computationally efficient. Validation is more challenging, so a better simulation of unseen data. \n",
    " - Con: Only one Fit-Predict-Score cycle, minimal training experience.\n",
    "\n",
    "\\\\(k=n\\\\)\n",
    "\n",
    "Each observation becomes its own validation set, and we use the remaining data to fit the model. Also known as leave-one-out cross validation.\n",
    " - Pro: Maximizes number of Fit-Predict-Score cycles, providing a profile of each point\n",
    " - Con: Computationally expensive\n",
    "\n",
    "As we've become accustomed to, the ideal is in the balance. Typically we use \\\\(k\\\\) between \\\\(5\\\\) and \\\\(10\\\\)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "961dfecf-466b-437b-a3e9-197b5a574c95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cv_folds = 5  # Selecting 5-fold cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cc06568-d2dd-4fbb-8901-3f5fe078d8fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Step 3: *Fit-Predict-Score*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7551909-c3c9-4343-98aa-b2742a959598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Implement the *Fit-Predict-Score* cycle to identify average score across the 5 folds for each point in the hyperparameter space. This provides the criterion we will use to select our estimate for \\\\(k\\\\) and fit our final model. The following figure and subsequent code illustrate and execute this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0796af6-49ef-42e3-a4e6-5f106e6b18b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The **GridSearchCV** function in scikit learn will provide a powerful tool for a smooth implementation of the Fit-Predict-Score cycle in the framework of k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c17c885-29d0-4a7d-8492-92bde54ea557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site\n\n*** WARNING: max output size exceeded, skipping output. ***\n\nll be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "features = X_build_p1.shape[1]\n",
    "acc_values = [0]  # Starting value for no regressors\n",
    "\n",
    "model = LogisticRegression(penalty ='none',random_state=rms,max_iter=1000)\n",
    "cv_folds = 5  # Example: 5-fold cross-validation\n",
    "\n",
    "classification_metric='accuracy'\n",
    "\n",
    "# For each number of features, perform SFS and evaluate the model using k-fold cross-validation\n",
    "for k in range(1, features):\n",
    "    sfs = SequentialFeatureSelector(model, n_features_to_select=k)\n",
    "    X_build_selected = sfs.fit_transform(X_build_p1, y_build_bal)\n",
    "\n",
    "    # Use cross-validation to get mean R^2 score over all folds\n",
    "    scores = cross_val_score(model, X_build_selected, y_build_bal, cv=cv_folds, scoring=classification_metric)\n",
    "    mean_re = scores.mean()\n",
    "    \n",
    "    acc_values.append(mean_re)\n",
    "\n",
    "# Now, acc_values contains the mean accuracy scores from cross-validation for each number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a3969e-97a7-41a0-864d-92f8349c472d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's use *graph_objects* from Plotly to visualize the increase in \\\\(Accuracy\\\\) as a function of the number of parameters in our model. We're looking to identify where the increase levels off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee827c14-348f-4b93-ad67-8cef49763761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"3247a929-f9a0-4092-87ae-9d2738f95932\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3247a929-f9a0-4092-87ae-9d2738f95932\")) {                    Plotly.newPlot(                        \"3247a929-f9a0-4092-87ae-9d2738f95932\",                        [{\"mode\":\"lines+markers\",\"name\":\"$Accuracy$ Score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0,0.742737314483837,0.7592705268748545,0.7660685193915487,0.769930716762247,0.771012633300114,0.7730214294665608,0.7727130265615583,0.7736410996998323,0.774104778216061,0.7741044201631528,0.771941541895174,0.7710131107039917,0.7705493128367935,0.7705493128367935,0.7679225173506472,0.7679225173506472,0.7673041599780394,0.7673041599780394,0.7640593651721936],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Number of Regressors (p-1)\"},\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]},\"title\":{\"text\":\"Number of Regressors vs. $Acc$ Score using SFS\"},\"yaxis\":{\"title\":{\"text\":\"$Acc$ Score\"},\"range\":[0,1]},\"showlegend\":true,\"width\":800,\"height\":800},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"3247a929-f9a0-4092-87ae-9d2738f95932\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3247a929-f9a0-4092-87ae-9d2738f95932\")) {                    Plotly.newPlot(                        \"3247a929-f9a0-4092-87ae-9d2738f95932\",                        [{\"mode\":\"lines+markers\",\"name\":\"$Accuracy$ Score\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],\"y\":[0,0.742737314483837,0.7592705268748545,0.7660685193915487,0.769930716762247,0.771012633300114,0.7730214294665608,0.7727130265615583,0.7736410996998323,0.774104778216061,0.7741044201631528,0.771941541895174,0.7710131107039917,0.7705493128367935,0.7705493128367935,0.7679225173506472,0.7679225173506472,0.7673041599780394,0.7673041599780394,0.7640593651721936],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"title\":{\"text\":\"Number of Regressors (p-1)\"},\"tickvals\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]},\"title\":{\"text\":\"Number of Regressors vs. $Acc$ Score using SFS\"},\"yaxis\":{\"title\":{\"text\":\"$Acc$ Score\"},\"range\":[0,1]},\"showlegend\":true,\"width\":800,\"height\":800},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# Plot using plotly\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(x=list(range(0, features + 1)), \n",
    "                         y=acc_values,\n",
    "                         mode='lines+markers',\n",
    "                         name='$Accuracy$ Score'))\n",
    "\n",
    "fig.update_layout(title='Number of Regressors vs. $Acc$ Score using SFS',\n",
    "                  xaxis_title='Number of Regressors (p-1)',\n",
    "                  yaxis_title='$Acc$ Score',\n",
    "                  xaxis=dict(tickvals=list(range(features + 1))),\n",
    "                  showlegend=True,\n",
    "                  width=800,   # Width of the figure in pixels\n",
    "                  height=800)  # Height of the figure in pixels\n",
    "\n",
    "fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3dbf4d4-ba5c-444e-a1fb-d323f521a228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The appearance of this graph is a common occurence in ML, particularly for metrics (such as \\\\(Acc\\\\)) that will deterministically improve when you increase the number of predictor variables. There comes a point that the benefits of adding another variable to increase the \\\\(Acc\\\\) are dwarfed by the cost of overfitting. *The corner principle* states that this crucial point typically occurs at or near a corner in the graph, right before the plot levels off. Investigating the values, it seems that **the 6 regressor model** is where the \\\\(Acc\\\\) seems to stabilize at about 0.7685. Note this actually exceeds our metric above, even though less data is used due to cross validation. \n",
    "\n",
    "Let's identify the variables using the *SequentialFeatureSelector*, and fit to the entire training set to prepare to deploy. That will provide us our final fitted model. At that point we'll be able to determine how well our model performs on the heretofor untouched test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "772a97d0-180a-4fab-a020-f4d4a7c4f246",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site\n\n*** WARNING: max output size exceeded, skipping output. ***\n\n_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\nThe top 6 features selected by SFS are:\n['HS_MATH_GPA', 'UNITS_ATTEMPTED_2', 'DFW_RATE_2', 'RACE_ETHNICITY_Hispanic', 'RACE_ETHNICITY_Asian', 'RACE_ETHNICITY_Other']\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n"
     ]
    }
   ],
   "source": [
    "# For a given k, perform SFS\n",
    "k = 6\n",
    "sfs = SequentialFeatureSelector(model, n_features_to_select=k)\n",
    "sfs.fit(X_build_p1, y_build_bal)\n",
    "\n",
    "# Identify and print the selected features\n",
    "selected_features = np.array(final_column_names)[np.where(sfs.get_support() == True)]\n",
    "print(f\"The top {k} features selected by SFS are:\")\n",
    "print(list(selected_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "429af441-a18f-42de-94c0-f5f3eed7451d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Reduced Logistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4607bcbb-891b-4075-b4c4-7debe21ccd00",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now that the optimal number of features has been chosen via cross validation, we fit the entire training set with the *best_lrc* model, and use that to evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e95cea2-68d0-4a93-b86e-82d0e91a0773",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning:\n\nIn a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:           SEM_3_STATUS   No. Observations:                 6472\nModel:                            GLM   Df Residuals:                     6465\nModel Family:                Binomial   Df Model:                            6\nLink Function:                  logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3225.0\nDate:                Thu, 11 Jan 2024   Deviance:                       6450.0\nTime:                        07:55:35   Pearson chi2:                 6.87e+03\nNo. Iterations:                     5                                         \nCovariance Type:            nonrobust                                         \n===========================================================================================\n                              coef    std err          z      P>|z|      [0.025      0.975]\n-------------------------------------------------------------------------------------------\nconst                       0.5888      0.062      9.549      0.000       0.468       0.710\nHS_MATH_GPA                 0.0661      0.033      2.034      0.042       0.002       0.130\nUNITS_ATTEMPTED_2          -0.5390      0.033    -16.310      0.000      -0.604      -0.474\nDFW_RATE_2                  1.4425      0.043     33.433      0.000       1.358       1.527\nRACE_ETHNICITY_Hispanic    -0.4623      0.073     -6.315      0.000      -0.606      -0.319\nRACE_ETHNICITY_Asian       -0.7554      0.092     -8.175      0.000      -0.936      -0.574\nRACE_ETHNICITY_Other       -0.4975      0.269     -1.850      0.064      -1.025       0.030\n===========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Add a constant to get an intercept\n",
    "X_build_sm1 = sm.add_constant(X_build_p1[selected_features])\n",
    "\n",
    "# Fit the regression line using ‘OLS’\n",
    "lrs1 = sm.GLM(y_build_bal, X_build_sm1,family=sm.families.Binomial()).fit()\n",
    "\n",
    "print(lrs1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32567ecd-0007-469a-88c9-094886199f23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Thus our final multiple linear regression model is the reduced one: \n",
    "$$logit(\\pi(\\vec{x})) = 0.2214+0.6486\\*\\text{DFW.RATE.1}-0.3972\\*\\text{UNITS.ATTEMPTED.2}+1.0787\\*\\text{DFW.RATE.2}+0.4520\\*\\text{RACE.ETHNICITY.White}+0.4860\\*\\text{RACE.ETHNICITY.Nonresident.alien}-0.2224\\*\\text{FIRST.GEN.STATUS.First Generation}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bbb04453-43e5-41ea-b7d2-70329a1f7521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[74]: <sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f11b659dd90>"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_lrs1 = confusion_matrix(y_build_bal, list(map(round,lrs1.predict(X_build_sm1))), labels=None, sample_weight=None, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(cm_lrs1, display_labels=None)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e58bb69b-70ec-4e47-9aec-03d971bf7a5b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[75]: 0.7734857849196539"
     ]
    }
   ],
   "source": [
    "cm = cm_lrs1\n",
    "\n",
    "acc_lrs1 = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[1,1]+cm[0,1]+cm[1,0])\n",
    "\n",
    "acc_lrs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "504970e4-5b21-4c3f-bdda-9d231949e940",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Note that this represents a slight improvement over the \"out of the box\" logistic classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9dc732a-b59d-461c-8f1a-c10b081f9569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[76]: 0.006953028430160768"
     ]
    }
   ],
   "source": [
    "acc_lrs1-acc_lrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1fa93a-69c5-43bb-8ddc-e66c0c97babb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Validaiton**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a4fb4e9-f920-434f-a5a7-29afd12ae1c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:           SEM_3_STATUS   No. Observations:                 7408\nModel:                            GLM   Df Residuals:                     7401\nModel Family:                Binomial   Df Model:                            6\nLink Function:                  logit   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3673.4\nDate:                Thu, 11 Jan 2024   Deviance:                       7346.9\nTime:                        07:55:35   Pearson chi2:                 7.74e+03\nNo. Iterations:                     5                                         \nCovariance Type:            nonrobust                                         \n===========================================================================================\n                              coef    std err          z      P>|z|      [0.025      0.975]\n-------------------------------------------------------------------------------------------\nconst                       0.5942      0.059     10.109      0.000       0.479       0.709\nHS_MATH_GPA                 0.0418      0.030      1.388      0.165      -0.017       0.101\nUNITS_ATTEMPTED_2          -0.5163      0.031    -16.411      0.000      -0.578      -0.455\nDFW_RATE_2                  1.4638      0.040     36.278      0.000       1.385       1.543\nRACE_ETHNICITY_Hispanic    -0.5177      0.070     -7.412      0.000      -0.655      -0.381\nRACE_ETHNICITY_Asian       -0.5740      0.085     -6.752      0.000      -0.741      -0.407\nRACE_ETHNICITY_Other       -0.4250      0.237     -1.792      0.073      -0.890       0.040\n===========================================================================================\n/databricks/python/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning:\n\nIn a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n\n"
     ]
    }
   ],
   "source": [
    "# Add a constant to get an intercept\n",
    "X_train_sm1 = sm.add_constant(X_train_p1[selected_features])\n",
    "X_val_sm1 = sm.add_constant(X_val_p1[selected_features])\n",
    "X_test_sm1 = sm.add_constant(X_test_p1[selected_features])\n",
    "# Fit the regression line using ‘OLS’\n",
    "lrs_train = sm.GLM(y_train_bal, X_train_sm1,family=sm.families.Binomial()).fit()\n",
    "\n",
    "print(lrs_train.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61095c6a-4115-48da-bb35-60553d6350ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "######Variable Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbf6cece-056f-49db-82da-f8e395718859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Recall that logistic regression from the machine learning perspective does not make the strong assumptions on the response variable that ordinary least squares does, and because of that, statistical inference concerning individual predictors is not available. That being said, this is not a complete black box; we can identify and rank the variables that played the biggest role in identifying the optimal model. *Variable importance* is usually visualized graphically as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3358e6ce-6b71-4884-808b-9e2fc47a3956",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ba0f7c-799d-44b4-8be9-d3d711e8a65d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n/local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning:\n\n`penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"4347cf17-a05e-428b-91a2-ea262c54d1fc\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4347cf17-a05e-428b-91a2-ea262c54d1fc\")) {                    Plotly.newPlot(                        \"4347cf17-a05e-428b-91a2-ea262c54d1fc\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Change in Accuracy=%{x}<br>Feature=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[-0.0004042204404690608,0.0002702700239927136,0.0005395376979300259,0.0067500986403576935,0.015928253605498766,0.1299970567357469],\"xaxis\":\"x\",\"y\":[\"RACE_ETHNICITY_Hispanic\",\"RACE_ETHNICITY_Other\",\"HS_MATH_GPA\",\"RACE_ETHNICITY_Asian\",\"UNITS_ATTEMPTED_2\",\"DFW_RATE_2\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Change in Accuracy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Feature\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Feature Importance for Statsmodels Logistic Regression\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"4347cf17-a05e-428b-91a2-ea262c54d1fc\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4347cf17-a05e-428b-91a2-ea262c54d1fc\")) {                    Plotly.newPlot(                        \"4347cf17-a05e-428b-91a2-ea262c54d1fc\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Change in Accuracy=%{x}<br>Feature=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[-0.0004042204404690608,0.0002702700239927136,0.0005395376979300259,0.0067500986403576935,0.015928253605498766,0.1299970567357469],\"xaxis\":\"x\",\"y\":[\"RACE_ETHNICITY_Hispanic\",\"RACE_ETHNICITY_Other\",\"HS_MATH_GPA\",\"RACE_ETHNICITY_Asian\",\"UNITS_ATTEMPTED_2\",\"DFW_RATE_2\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Change in Accuracy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Feature\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Feature Importance for Statsmodels Logistic Regression\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Select features based on whether PCA was used or not\n",
    "#Original Variables\n",
    "X = X_train_p1[selected_features]\n",
    "\n",
    "#PCA\n",
    "#X = pca_X_train[:,[0,1,2,3]]\n",
    "\n",
    "y = y_train_bal\n",
    "\n",
    "model = LogisticRegression(penalty ='none',random_state=rms,max_iter=1000)\n",
    "\n",
    "# Calculate baseline accuracy\n",
    "baseline_accuracy = cross_val_score(model, X, y, cv=5, scoring=classification_metric).mean()\n",
    "\n",
    "# Calculate feature importance scores\n",
    "importance_scores = []\n",
    "\n",
    "for feature_index in range(X.shape[1]):\n",
    "    X_subset = X.drop(X.columns[feature_index], axis=1)\n",
    "    accuracy_after_removal = cross_val_score(model, X_subset, y, cv=5, scoring=classification_metric).mean()\n",
    "    importance_scores.append(baseline_accuracy - accuracy_after_removal)\n",
    "\n",
    "#Original Variables\n",
    "importance_df = pd.DataFrame({'Feature': selected_features, 'Change in Accuracy': importance_scores})\n",
    "\n",
    "#PCA: Create a DataFrame for Plotly Express\n",
    "#importance_df = pd.DataFrame({'Feature': ['pc1', 'pc2', 'pc3', 'pc4'], 'Change in Accuracy': importance_scores})\n",
    "\n",
    "importance_df_sorted = importance_df.sort_values('Change in Accuracy')\n",
    "\n",
    "# Plot the importance scores using Plotly Express\n",
    "fig = px.bar(importance_df_sorted, y='Feature', x='Change in Accuracy',\n",
    "             labels={'Change in Accuracy': 'Change in Accuracy'},\n",
    "             orientation='h',  # Set orientation to horizontal\n",
    "             title='Feature Importance for Statsmodels Logistic Regression')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "48d4d5bd-b88c-4d96-b769-0561fe3d7c6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"cdd79be4-4f3c-4818-a575-65bc07ffdf35\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cdd79be4-4f3c-4818-a575-65bc07ffdf35\")) {                    Plotly.newPlot(                        \"cdd79be4-4f3c-4818-a575-65bc07ffdf35\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Z-Statistic=%{x}<br>Variable=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[2.034459055092325,6.315239492425373,8.175153502453439,16.309924643616284,33.43305031190763],\"xaxis\":\"x\",\"y\":[\"HS_MATH_GPA\",\"RACE_ETHNICITY_Hispanic\",\"RACE_ETHNICITY_Asian\",\"UNITS_ATTEMPTED_2\",\"DFW_RATE_2\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Z-Statistic\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Variable\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Variable Importance Plot\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"cdd79be4-4f3c-4818-a575-65bc07ffdf35\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"cdd79be4-4f3c-4818-a575-65bc07ffdf35\")) {                    Plotly.newPlot(                        \"cdd79be4-4f3c-4818-a575-65bc07ffdf35\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Z-Statistic=%{x}<br>Variable=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"h\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[2.034459055092325,6.315239492425373,8.175153502453439,16.309924643616284,33.43305031190763],\"xaxis\":\"x\",\"y\":[\"HS_MATH_GPA\",\"RACE_ETHNICITY_Hispanic\",\"RACE_ETHNICITY_Asian\",\"UNITS_ATTEMPTED_2\",\"DFW_RATE_2\"],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Z-Statistic\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Variable\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Variable Importance Plot\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extracting z-statistics and corresponding variable names\n",
    "z_stats = np.abs(lrs1.tvalues)\n",
    "variable_names = z_stats.index[1:6].tolist()\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "data = pd.DataFrame({'Variable': variable_names, 'Z-Statistic': z_stats.values[1:6]}).sort_values(by='Z-Statistic')\n",
    "\n",
    "# Create a horizontal bar chart using plotly.express\n",
    "fig = px.bar(data, x='Z-Statistic', y='Variable', orientation='h', title='Variable Importance Plot')\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "646c2f92-a2b9-4769-acb6-c9e934c8cbe8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f07fd610-fc80-43d3-b357-6ac7ace9062c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Model Testing - Evaluating generalizability and looking ahead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9431d5e4-1d33-456e-85d7-dee60f443318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "A model is only useful to the extent that it can be deployed to make accurate predictions on unseen data from similar target populations. This is the reason for reserving a portion of our data as a test set, completely untouched by the building, validation or specification steps. We use accuracy as the primary metric to evaluate performance of our model, but due to the critical nature of identifying the positive class (students who leave campus), monitoring recall and sensitivity will be of utmost importance.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c0bd84-a1c2-4fe5-9ac2-c26a6d353cfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "predictions_lrs_test = lrs_train.predict(X_test_sm1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24d952a9-2641-4013-8594-51ee40579aaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.695274831243973  Specificity= 0.6876332622601279  Precision= 0.20596205962059622  Sensitivity/Recall= 0.7676767676767676\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_lrs = confusion_matrix(y_test_c, list(map(round,lrs1.predict(X_test_sm1))), labels=None, sample_weight=None, normalize=None)\n",
    "disp = ConfusionMatrixDisplay(cm_lrs, display_labels=None)\n",
    "disp.plot()\n",
    "cm = cm_lrs\n",
    "\n",
    "acc_lrs = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[1,1]+cm[0,1]+cm[1,0])\n",
    "\n",
    "specif_lrs = (cm[0,0])/(cm[0,0]+cm[0,1])\n",
    "\n",
    "prec_lrs = (cm[1,1])/(cm[1,1]+cm[0,1])\n",
    "\n",
    "sens_lrs = (cm[1,1])/(cm[1,1]+cm[1,0])\n",
    "\n",
    "print(\"Accuracy=\",acc_lrs,\" Specificity=\",specif_lrs,\" Precision=\",prec_lrs,\" Sensitivity/Recall=\",sens_lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c6691c-2301-4722-a382-0990912b0fc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "probs = predictions_lrs_test\n",
    "#threshold = y_train_c.sum()/len(y_train_c)\n",
    "threshold = 0.50\n",
    "yhat_th = (probs>=threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74fa30e-9a47-4e73-8e53-5107b7d43c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\")) {                    Plotly.newPlot(                        \"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"x=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.522064569742357,0.6720316596496955,0.2790426070663309,0.3532716194850535,0.43799259121779704,0.5046902377429663,0.7059942579638454,0.43801357190828627,0.40162801643536594,0.38832132176234413,0.5788729264831378,0.5269122554318363,0.15460131966525964,0.38736776354895897,0.5188175878720079,0.2617313451310628,0.23446150169090302,0.3948324842094052,0.5243488140013364,0.8344470518690592,0.44568565457893794,0.26852274882987476,0.3840363831646621,0.8675849492322494,0.34917204177709854,0.24381356704685778,0.29941150100680397,0.356409699581892,0.5495272540169901,0.7191527442110948,0.3913781384638569,0.5098295103913437,0.4802751489893829,0.9346757845070475,0.9896336491080364,0.3071957628775672,0.22036274727396782,0.41014357802717555,0.43470792126570335,0.35209807561767203,0.9043769237567183,0.38493082851613963,0.34256268618533514,0.22268052241177694,0.3818095465623364,0.5214716134282595,0.9781032586638376,0.3926032701429938,0.20895504496749093,0.9448450139453877,0.33412405643123816,0.2891481181348036,0.7149812234028593,0.34781042294168657,0.5100436092007222,0.7818017599905392,0.377746882589232,0.23910618098063846,0.9738859062376987,0.9414308434295785,0.42266211891138655,0.6649883010957232,0.27088517356067865,0.3000070565673174,0.24160900179074804,0.46374836162648353,0.5228799744172232,0.9964453826497414,0.37415547707968494,0.3838337408841039,0.517622223508576,0.9988307500364032,0.33909810298700804,0.5068317841478627,0.4439270451396255,0.3926032701429938,0.9659084704854026,0.9786111781372872,0.7086546149921334,0.8811882674757239,0.22720801198625754,0.9931448276747095,0.37537993066090586,0.26255991437050485,0.9683015300691402,0.38899553265733416,0.9962585847268406,0.3804151326816632,0.252082456256175,0.24790601963740935,0.5282205258179367,0.34878275546496734,0.2811565038021407,0.3843224903689777,0.7042128341467032,0.9643903886324212,0.9435664215881733,0.4633222731993138,0.31546128196091433,0.34044341857832794,0.270430586075151,0.32964302243369753,0.33490591634054334,0.4022458505585119,0.43441077066138056,0.2712765753692646,0.7544594399828649,0.4331482124401911,0.9978570720369008,0.23988639838625256,0.515180694865652,0.237706180271798,0.5776192986827121,0.9743083816347496,0.22581025611041866,0.5249897999605757,0.338409449807137,0.3010876639573207,0.3969017974272492,0.4358848305201172,0.9700933938623881,0.308656372393502,0.31012081794072516,0.34878275546496734,0.3953262532591143,0.3950575798413368,0.33204953248370905,0.2693649733876409,0.5322750946616289,0.9781486432524285,0.4061659365023192,0.4570754760155952,0.2636708361511336,0.22897102036928782,0.2967785810212357,0.33172887252641037,0.2589268626070751,0.8089969283856311,0.3641800055247228,0.39368906205606147,0.3834285773792917,0.2655045758981329,0.9118642655870718,0.7065828938587811,0.5261062618042193,0.308656372393502,0.5492500248675553,0.9057022478638761,0.38687757486996055,0.35916568073309685,0.27326061810914076,0.37960773775489093,0.9816225762206604,0.29205456308908373,0.9933916948553337,0.2636708361511336,0.16613299318288874,0.9752145958442957,0.2419231063921983,0.8563731644827215,0.35916568073309685,0.6665134675532345,0.24483405624730253,0.3004908841073562,0.7572895043780179,0.3374510506881966,0.752046736046706,0.35405496700026123,0.30126798045473496,0.9859693647164629,0.24817574426679587,0.6529388207274198,0.515180694865652,0.38411979126505286,0.3519026580189731,0.9086597638111255,0.2355396370048312,0.44861269214674276,0.2599144437634275,0.26783345599456926,0.44599289669807,0.39485284998967596,0.5284340217445245,0.4136991254254566,0.9083749392530013,0.8175637950188415,0.7848697017643603,0.2690278835099227,0.9954816746563125,0.22223595342629,0.7653755632130667,0.5081562644774702,0.6275880251097549,0.39854356691662596,0.3979276337865008,0.6919922766140411,0.3733733034247174,0.338409449807137,0.4995499737830978,0.37556084162723863,0.2375509733562133,0.502850839895215,0.2553266761147601,0.524135134081661,0.9924292149882992,0.39035823932223174,0.212947864279776,0.3952623465098851,0.6580826713185433,0.39301194882367113,0.5246108356100692,0.25794172606227755,0.6690033103002766,0.9768649662924808,0.3061596240227598,0.26035766229825735,0.5183626913006129,0.4664434540790215,0.8780015664085953,0.9964332238357685,0.39362524768123164,0.22585699786648866,0.2562543175902648,0.993261073847574,0.6769367945036336,0.22686039886208498,0.5229012380510095,0.4277736571808614,0.3840363831646621,0.5567271417009991,0.30011294000596783,0.24934644362424116,0.3132454126219032,0.2666757321055919,0.6211136747808452,0.26919639512117866,0.39998199066950063,0.39158223249641827,0.38899553265733416,0.37335336200175545,0.3114626708490959,0.47719402856981624,0.4454079664677166,0.267346438302705,0.3248687755057627,0.38872839578332635,0.5267257696118575,0.3852530803108617,0.3822973177518292,0.3655697876173703,0.39389358125707075,0.2295765845117604,0.37898256813211234,0.4954052200904148,0.8294162000541787,0.7673929178074655,0.9756155500201804,0.2825437976775934,0.2633217695970591,0.33584173955940966,0.446137065745031,0.2794889608660231,0.43820349174006434,0.39287135841908905,0.7672939735239672,0.29543152462140954,0.5198869001998437,0.3419840767311156,0.22675704091605908,0.46097976059014695,0.37737082047556997,0.6607954656367292,0.3379470391721936,0.6636509468879187,0.661352235503552,0.525679043784602,0.33718072716069686,0.7289094554803014,0.4008047237812398,0.19693389260010777,0.724656492469695,0.38872839578332635,0.3950575798413368,0.8982974431573055,0.26600609762636895,0.5382423353221839,0.3885045904003771,0.3735538256745847,0.37497826014693,0.2231720718517911,0.9962329504094556,0.38879192529515455,0.22376675036201352,0.2326212474484024,0.9424043027034794,0.25745007574168843,0.9564582031179515,0.3842390657142107,0.9989267408100001,0.2291223060605212,0.39957083527246656,0.9056199750395472,0.4833956198457317,0.8250233302276329,0.24204310038078905,0.36678261058823913,0.7075921737493973,0.9148463332618285,0.25630527484955107,0.3918500733526827,0.9049306747541329,0.3071957628775672,0.9978667816280246,0.34007790718174025,0.21904089926194406,0.6674649323134093,0.5825896805196606,0.45218985472852047,0.5113281219365052,0.34534874479748845,0.38872839578332635,0.8073438721782034,0.2534883715818845,0.841472299914283,0.2510482367552457,0.5100436092007222,0.3366852914031458,0.3632702384966603,0.3530759055015817,0.26785017044016746,0.33401190008102466,0.5143247073113897,0.911311011265747,0.46196936876603784,0.3186148335356194,0.23048703700157322,0.7072375219120444,0.493884803568708,0.30810819325709393,0.3354786557212636,0.6977482448052534,0.3429678924211851,0.40286399521843197,0.438079383546667,0.9975546365255823,0.32541403812587494,0.9977869065050218,0.9696659858479404,0.44327163376522427,0.736712488249047,0.3070134573642861,0.27275050140652773,0.3417913112455106,0.22851758476563463,0.43934517493493414,0.2353854078907362,0.3472276311554041,0.3863516810305896,0.26284001067360074,0.35975746667646363,0.6601018170643927,0.43155264569074586,0.3410399266223894,0.40265791260596373,0.3858619682947058,0.8966523163866474,0.44561960644106974,0.9933860683334935,0.2630060409380016,0.38809760194653736,0.6724092051956965,0.5784551626955449,0.7726050676150203,0.4445616052851885,0.7981629806804923,0.37737082047556997,0.8806371331750104,0.4111803054138714,0.7194986867504732,0.9115193885598989,0.27190163065404926,0.42496342983363,0.34923280003134577,0.5153675442306982,0.2553266761147601,0.8511804624491621,0.260522678686771,0.22750901094417858,0.917265305645748,0.23079108261592104,0.6278080168031808,0.3950575798413368,0.506189342973236,0.9880774742192298,0.25761389113776406,0.3424491539862881,0.40018762125738244,0.5089459290939424,0.26869106034208917,0.3571961622884147,0.3907660845178453,0.25909128980836804,0.9857275766939176,0.3112216578370403,0.37958766506158587,0.3476161082659223,0.9985085645532945,0.5356861874574629,0.30483050310779614,0.6653888945305232,0.26500365834005646,0.22169030783747223,0.22376675036201352,0.2611834213127523,0.21539908994723958,0.9344124294471482,0.23063902472635475,0.4454079664677166,0.3026562914243234,0.4918129434676183,0.3822140597934826,0.47668893976496607,0.5890989808257107,0.5911643616762645,0.22332063581175407,0.2693649733876409,0.5874960420632672,0.4298720841024913,0.2531642657020286,0.34084741765493015,0.38169055879525954,0.24854551869523978,0.3993653105960185,0.3734358565436859,0.4626832411619427,0.26500365834005646,0.3764476110951698,0.9737465471286418,0.49333049012531766,0.2801187596382983,0.3956719900366467,0.9792124606881502,0.7165499056029199,0.5348337146441171,0.3818095465623364,0.7737539968924578,0.27513613079891364,0.9957785937350131,0.9750835481222755,0.9217041048489304,0.9955379233447166,0.47975946113124696,0.39833822008416114,0.29923181980958347,0.2713931034898996,0.9112266298706424,0.36378333958150927,0.37123344164079625,0.3864712136270969,0.2480657909382099,0.39998199066950063,0.35470418370253187,0.3785994310451079,0.30737812862792596,0.16298964779283642,0.6482648273792284,0.6518044125554464,0.23879458169550008,0.8095259007204358,0.38689779265718777,0.3532716194850535,0.5201007411172818,0.4080270338840023,0.5928843587600032,0.5201887441250256,0.36935330150830137,0.39854356691662596,0.2246608810658983,0.46673242834812056,0.5248032397628886,0.6457920770809492,0.6600077874406464,0.27599127184965566,0.25777777458388396,0.9687037317875673,0.5316351690537969,0.3820117827329077,0.9937686563028966,0.6748390971931707,0.3369892825821378,0.8755748992579767,0.5243759090274432,0.4361443902585954,0.4404006049122718,0.5252305341771685,0.7081789328113309,0.26706327951610537,0.9093105277528926,0.3112216578370403,0.38736776354895897,0.9112404136498544,0.39015437414727033,0.5343803706051933,0.9135696477626044,0.7294520271381579,0.5275528994551462,0.3751590938006273,0.9690038905435372,0.29713630791514645,0.36676281514111675,0.2264567451816426,0.3812030840083674,0.2646700492284067,0.1680406654823225,0.26350453626445514,0.4293658054267636,0.708831467373794,0.6046509890908022,0.3585743230549301,0.4954052200904148,0.4669456696412791,0.2909122370922524,0.1759705132288035,0.3507311955128376,0.6243530528897363,0.5348337146441171,0.3315389750716856,0.2969574133542868,0.5626538842033741,0.34567576011134415,0.26818632605926,0.27054688571302815,0.40533964298700004,0.9324427623964375,0.25936898726750934,0.533981038282443,0.28150293824125144,0.9595233522643307,0.3655697876173703,0.5222387323366762,0.45438773188508624,0.2667280185073757,0.5688665730559134,0.9113810968775893,0.5160578797076667,0.3235361590156029,0.7629050367500068,0.2353854078907362,0.3839171324044438,0.8750247131338476,0.7026258178310131,0.3494275343788993,0.27650514518830116,0.29779659793151014,0.3363027328183528,0.39587686676423556,0.1797562878915237,0.2656716827053571,0.38933929775922776,0.6447721929344215,0.8818177718779798,0.33852233221670425,0.9162622771207686,0.34360759360777554,0.2697023297967259,0.2636542885887494,0.5363254055224101,0.22720801198625754,0.260522678686771,0.6394961629971918,0.5034052222568178,0.26417013986337456,0.25925578489743784,0.2392620851465269,0.651609946939421,0.19901682405507304,0.40740637213288033,0.8954553683307314,0.2599144437634275,0.21816284201832117,0.3615353791592021,0.220215593127112,0.5216853979049061,0.3592351000631369,0.38079898122060024,0.8707845716098513,0.3950575798413368,0.39957083527246656,0.2631721386378894,0.38363113893488293,0.2855439506444948,0.3926032701429938,0.25838275507323766,0.37880100877688005,0.35170729000313816,0.9980627206265597,0.46822536832983913,0.7627466941386125,0.6910214304702265,0.38122318963531543,0.7146319192010037,0.22570723693526976,0.3771695417196737,0.38140519713834903,0.22791398763164447,0.602601157770604,0.9752558096517164,0.9939050887850829,0.5395394637422258,0.9610316393712252,0.2546248983787507,0.4866054685425905,0.3339334730030284,0.33764262400433254,0.3854761933662152,0.3425818821043629,0.4325172576350512,0.3447075043823677,0.26924899428383864,0.2297281510989427,0.5151535603514821,0.6634596814053674,0.32692039424589214,0.258038235932058,0.4020398712574854,0.4931645757558614,0.3757617798304868,0.4024518643636562,0.9904528091027757,0.9934476992176381,0.40059898787974996,0.48596340192158066,0.1897607974009772,0.7086546149921334,0.5361335430686779,0.3039800777094909,0.4357887907432664,0.701262687332822,0.397376044130393,0.9168090446826993,0.22585699786648866,0.533981038282443,0.9924534050117031,0.39895436761865544,0.2715625462161114,0.5282417661815527,0.38486753264164314,0.3956719900366467,0.33967435017429387,0.45731627115540313,0.3522935427463685,0.3885248393341327,0.7646288740585545,0.5286475072696817,0.9923170304065368,0.2447625428672553,0.9752701973535047,0.30319902132526877,0.328697115617477,0.3907660845178453,0.6988312298152728,0.47450408751024464,0.3759827579866855,0.3522935427463685,0.41286816164699713,0.3318406442451929,0.5155815224754117,0.381001012015258,0.27037784148959665,0.6419074576795636,0.37940599292480665,0.997936185226517,0.37277216061718094,0.37817635786664716,0.9452308219216711,0.40039328701629007,0.5196459344782088,0.22036274727396782,0.7407720729637272,0.44012359514899335,0.386694588387342,0.2241669987032286,0.33338099003240246,0.5380505828670833,0.3860852125136652,0.26634078081610135,0.2610181341334377,0.3573928984347446,0.34084741765493015,0.3412133284793995,0.9962998703557643,0.3977223944532253,0.6789008738401056,0.22006850950925141,0.3326009098551863,0.7572679395147288,0.2252583763818834,0.26383720339329997,0.2556526027054781,0.7819624053474381,0.3538590564910031,0.33975343779548267,0.7065274626121366,0.6996081802738304,0.25838275507323766,0.4594150585560504,0.2996473469686077,0.3425818821043629,0.2736010264527174,0.3842592320322373,0.9857275638050624,0.3979276337865008,0.3681567465598909,0.4739889449531102,0.29767336463220956,0.9953328537867009,0.9657104362992485,0.38626809224905134,0.2683545040615933,0.9121384330930422,0.6103440614192859,0.3812030840083674,0.26068776280142947,0.33975343779548267,0.28809269860456904,0.38122318963531543,0.6468156204510782,0.22376675036201352,0.2584339885124234,0.39854356691662596,0.2656716827053571,0.9937420734424578,0.2730905130760174,0.23461531119347348,0.267346438302705,0.9211458517785017,0.35405496700026123,0.25558551367433885,0.5101317194116305,0.34509465254538146,0.3909497695163671,0.3899505473395629,0.34917204177709854,0.6589636547542329,0.35412394438879846,0.25658102032072727,0.22436255582282735,0.7167238811704603,0.4289669164481885,0.2355396370048312,0.34110001146047236,0.4623449327647889,0.9855578327970672,0.9726376044575038,0.3885045904003771,0.5248032397628886,0.496591137135884,0.8989997169798826,0.7867299989764518,0.35837729925596906,0.18818514648925921,0.3374510506881966,0.42337549434377425,0.7736569603441292,0.4752707360628833,0.3926032701429938,0.1794760494399509,0.2562543175902648,0.9545017750820127,0.2545130550418662,0.27224098025045523,0.6475145779426429,0.38140519713834903,0.3002929235680569,0.27343078924269154,0.24854551869523978,0.26450334551257715,0.37926722852364747,0.21094453313542869,0.8650049412964522,0.3899505473395629,0.3673599429198848,0.3034365585402389,0.8733499742999938,0.27343078924269154,0.2529648040093742,0.4519776383618084,0.5276012198168977,0.36955288402881353,0.7255103873891725,0.7042128341467032,0.7735069009488857,0.7122335353153317,0.3569994742755006,0.47462979871745575,0.39074579341890203,0.4308357866823358,0.3838337408841039,0.385133687968549,0.38241637768220615,0.515795495007319,0.19870125176608885,0.8200209850774893,0.25679549501097665,0.2675142821473915,0.35778651490936186,0.25909128980836804,0.8776453222268498,0.5229022963049424,0.5091871926411634,0.22540792618768485,0.6687946899749456,0.5008079138676191,0.3875076415190893,0.3141676633470587,0.255927887640754,0.27428263557616983,0.9780872701792255,0.33279111274485645,0.3909700644103314,0.2556017306092931,0.9742587520500744,0.4346701289818353,0.551435252835975,0.2578905562740318,0.9979005926147556,0.5371987006845298,0.4921716711622953,0.369036365502866,0.9741942162890541,0.9980157795595778,0.4429358184951794,0.9066849454830321,0.39362524768123164,0.9610729257351444,0.30374230054891704,0.5222599984375874,0.9765470183187555,0.37283467294626854,0.26538965520016156,0.2635564243614291,0.3765659598409728,0.3509069009097832,0.48211204905105093,0.19303415389217396,0.3735538256745847,0.9947571156899802,0.33110013092939344,0.4397672816468379,0.5083307221532812,0.2282627385116064,0.37857937913327516,0.7420858644192143,0.9956055331556811,0.34625732884596794,0.7759142266198638,0.27942823163335084,0.8303294922315068,0.328449128103728,0.2569079956940124,0.5138966817041266,0.2409816267180369,0.7092761153334541,0.381001012015258,0.26222828407154075,0.34878275546496734,0.3979072136946024,0.4390473164167983,0.49024461893366655,0.49005181870785364,0.7158533579545678,0.26768219286710676,0.8952290940868939,0.7323167272711453,0.24941961492394685,0.3838337408841039,0.3658973036005022,0.30717762329469217,0.9413072782724724,0.38466472567560117,0.9449538203248662,0.5130802211818987,0.42854724646498976,0.24599414988151383,0.4008047237812398,0.5665038776990201,0.22791398763164447,0.26818632605926,0.2514369017826845,0.3854560031620262,0.5019941266057918,0.4846794097723401,0.2353854078907362,0.3485688338850034,0.37676711134194324,0.6231013598604148,0.39280759071776084,0.41827809497967416,0.6980220539648213,0.5320617978180858,0.5322963141116568,0.32831914099305737,0.3509263148235634,0.31067097004718125,0.42538220272414196,0.3468393573752633,0.2853692017353198,0.9722776247831499,0.29982717092380334,0.38872839578332635,0.9914173578480371,0.2618969238841438,0.5106858832080889,0.5231149679186864,0.2640036379707903,0.9979589968571556,0.36977237374869465,0.235848304935462,0.2770196092310301,0.31663763448678056,0.7012073698097523,0.501905981856333,0.6395605054434915,0.6636699722331726,0.6263602536576013,0.23430776215442953,0.2373958362211433,0.3066490271970156,0.5113281219365052,0.7461392585982279,0.9947378132672479,0.7894626266550354,0.3923989871639959,0.9678514309165006,0.3987489494501518,0.993463854968374,0.3743561141450993,0.24129517520231375,0.5179620134094598,0.2291223060605212,0.35778651490936186,0.6365032793337023,0.38249965242519085,0.25111453655049454,0.174484709178406,0.8747939002384891,0.2572352435709595,0.2712765753692646,0.3483936708332064,0.2656716827053571,0.29887264285346865,0.7105965062079371,0.9865471644165336,0.8687511165658968,0.16439706025382558,0.7999501481515475,0.49088694029301183,0.26383720339329997,0.5991724122492789,0.9905415128514637,0.848667090072807,0.28591676433402907,0.35975746667646363,0.5478194051182418,0.5175341863645425,0.4022458505585119,0.43546355374332607,0.6190954290859189,0.21564358749923357,0.5100164606244293,0.3449010527420462,0.5147527119074682,0.22042991083674882,0.5816714105257165,0.8291507799796312,0.25876250331184797,0.8539070994573581,0.9070964251119022,0.9964393084140947,0.25826983304447965,0.373754332784852,0.5096154079759664,0.977841488582892,0.2303351194487633,0.3751590938006273,0.9966113321961898,0.4057527230257632,0.539093944681618,0.5070855966642367,0.36803948049155644,0.35936289520274234,0.7577770770777527,0.9801536358949918,0.2212471530752429,0.9926932130403254,0.7099828233837501,0.5335546253132136,0.9970603729295194,0.9793492268615315,0.5239485425935955,0.5324613347756721,0.9963469439138672,0.7577497908233725,0.58096004054284,0.7159077360062656,0.3503411066400181,0.7151557790504754,0.24105238799852363,0.34515507757376307,0.38933929775922776,0.9988258364731543,0.24822563122413246,0.9929820197504959,0.2364664793487796,0.7748549025661509,0.39074579341890203,0.476097195605312,0.3019335077119403,0.19706942100238925,0.4002517972766348,0.8184349330003167,0.26650822295897836,0.3747575178136139,0.29108899773086705,0.2553266761147601,0.2081400274370645,0.7951020883088116,0.9853557654536651,0.30737812862792596,0.4340764342871178,0.2530023155198339,0.2909928775469899,0.3405225929226924,0.7538954924299914,0.6990677587154622,0.31527630348264396,0.27462383596904466],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\" class=\"plotly-graph-div\" style=\"height:100%; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\")) {                    Plotly.newPlot(                        \"462368fe-f290-4eb9-bc2f-23dfe7f01ea7\",                        [{\"alignmentgroup\":\"True\",\"bingroup\":\"x\",\"hovertemplate\":\"x=%{x}<br>count=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.522064569742357,0.6720316596496955,0.2790426070663309,0.3532716194850535,0.43799259121779704,0.5046902377429663,0.7059942579638454,0.43801357190828627,0.40162801643536594,0.38832132176234413,0.5788729264831378,0.5269122554318363,0.15460131966525964,0.38736776354895897,0.5188175878720079,0.2617313451310628,0.23446150169090302,0.3948324842094052,0.5243488140013364,0.8344470518690592,0.44568565457893794,0.26852274882987476,0.3840363831646621,0.8675849492322494,0.34917204177709854,0.24381356704685778,0.29941150100680397,0.356409699581892,0.5495272540169901,0.7191527442110948,0.3913781384638569,0.5098295103913437,0.4802751489893829,0.9346757845070475,0.9896336491080364,0.3071957628775672,0.22036274727396782,0.41014357802717555,0.43470792126570335,0.35209807561767203,0.9043769237567183,0.38493082851613963,0.34256268618533514,0.22268052241177694,0.3818095465623364,0.5214716134282595,0.9781032586638376,0.3926032701429938,0.20895504496749093,0.9448450139453877,0.33412405643123816,0.2891481181348036,0.7149812234028593,0.34781042294168657,0.5100436092007222,0.7818017599905392,0.377746882589232,0.23910618098063846,0.9738859062376987,0.9414308434295785,0.42266211891138655,0.6649883010957232,0.27088517356067865,0.3000070565673174,0.24160900179074804,0.46374836162648353,0.5228799744172232,0.9964453826497414,0.37415547707968494,0.3838337408841039,0.517622223508576,0.9988307500364032,0.33909810298700804,0.5068317841478627,0.4439270451396255,0.3926032701429938,0.9659084704854026,0.9786111781372872,0.7086546149921334,0.8811882674757239,0.22720801198625754,0.9931448276747095,0.37537993066090586,0.26255991437050485,0.9683015300691402,0.38899553265733416,0.9962585847268406,0.3804151326816632,0.252082456256175,0.24790601963740935,0.5282205258179367,0.34878275546496734,0.2811565038021407,0.3843224903689777,0.7042128341467032,0.9643903886324212,0.9435664215881733,0.4633222731993138,0.31546128196091433,0.34044341857832794,0.270430586075151,0.32964302243369753,0.33490591634054334,0.4022458505585119,0.43441077066138056,0.2712765753692646,0.7544594399828649,0.4331482124401911,0.9978570720369008,0.23988639838625256,0.515180694865652,0.237706180271798,0.5776192986827121,0.9743083816347496,0.22581025611041866,0.5249897999605757,0.338409449807137,0.3010876639573207,0.3969017974272492,0.4358848305201172,0.9700933938623881,0.308656372393502,0.31012081794072516,0.34878275546496734,0.3953262532591143,0.3950575798413368,0.33204953248370905,0.2693649733876409,0.5322750946616289,0.9781486432524285,0.4061659365023192,0.4570754760155952,0.2636708361511336,0.22897102036928782,0.2967785810212357,0.33172887252641037,0.2589268626070751,0.8089969283856311,0.3641800055247228,0.39368906205606147,0.3834285773792917,0.2655045758981329,0.9118642655870718,0.7065828938587811,0.5261062618042193,0.308656372393502,0.5492500248675553,0.9057022478638761,0.38687757486996055,0.35916568073309685,0.27326061810914076,0.37960773775489093,0.9816225762206604,0.29205456308908373,0.9933916948553337,0.2636708361511336,0.16613299318288874,0.9752145958442957,0.2419231063921983,0.8563731644827215,0.35916568073309685,0.6665134675532345,0.24483405624730253,0.3004908841073562,0.7572895043780179,0.3374510506881966,0.752046736046706,0.35405496700026123,0.30126798045473496,0.9859693647164629,0.24817574426679587,0.6529388207274198,0.515180694865652,0.38411979126505286,0.3519026580189731,0.9086597638111255,0.2355396370048312,0.44861269214674276,0.2599144437634275,0.26783345599456926,0.44599289669807,0.39485284998967596,0.5284340217445245,0.4136991254254566,0.9083749392530013,0.8175637950188415,0.7848697017643603,0.2690278835099227,0.9954816746563125,0.22223595342629,0.7653755632130667,0.5081562644774702,0.6275880251097549,0.39854356691662596,0.3979276337865008,0.6919922766140411,0.3733733034247174,0.338409449807137,0.4995499737830978,0.37556084162723863,0.2375509733562133,0.502850839895215,0.2553266761147601,0.524135134081661,0.9924292149882992,0.39035823932223174,0.212947864279776,0.3952623465098851,0.6580826713185433,0.39301194882367113,0.5246108356100692,0.25794172606227755,0.6690033103002766,0.9768649662924808,0.3061596240227598,0.26035766229825735,0.5183626913006129,0.4664434540790215,0.8780015664085953,0.9964332238357685,0.39362524768123164,0.22585699786648866,0.2562543175902648,0.993261073847574,0.6769367945036336,0.22686039886208498,0.5229012380510095,0.4277736571808614,0.3840363831646621,0.5567271417009991,0.30011294000596783,0.24934644362424116,0.3132454126219032,0.2666757321055919,0.6211136747808452,0.26919639512117866,0.39998199066950063,0.39158223249641827,0.38899553265733416,0.37335336200175545,0.3114626708490959,0.47719402856981624,0.4454079664677166,0.267346438302705,0.3248687755057627,0.38872839578332635,0.5267257696118575,0.3852530803108617,0.3822973177518292,0.3655697876173703,0.39389358125707075,0.2295765845117604,0.37898256813211234,0.4954052200904148,0.8294162000541787,0.7673929178074655,0.9756155500201804,0.2825437976775934,0.2633217695970591,0.33584173955940966,0.446137065745031,0.2794889608660231,0.43820349174006434,0.39287135841908905,0.7672939735239672,0.29543152462140954,0.5198869001998437,0.3419840767311156,0.22675704091605908,0.46097976059014695,0.37737082047556997,0.6607954656367292,0.3379470391721936,0.6636509468879187,0.661352235503552,0.525679043784602,0.33718072716069686,0.7289094554803014,0.4008047237812398,0.19693389260010777,0.724656492469695,0.38872839578332635,0.3950575798413368,0.8982974431573055,0.26600609762636895,0.5382423353221839,0.3885045904003771,0.3735538256745847,0.37497826014693,0.2231720718517911,0.9962329504094556,0.38879192529515455,0.22376675036201352,0.2326212474484024,0.9424043027034794,0.25745007574168843,0.9564582031179515,0.3842390657142107,0.9989267408100001,0.2291223060605212,0.39957083527246656,0.9056199750395472,0.4833956198457317,0.8250233302276329,0.24204310038078905,0.36678261058823913,0.7075921737493973,0.9148463332618285,0.25630527484955107,0.3918500733526827,0.9049306747541329,0.3071957628775672,0.9978667816280246,0.34007790718174025,0.21904089926194406,0.6674649323134093,0.5825896805196606,0.45218985472852047,0.5113281219365052,0.34534874479748845,0.38872839578332635,0.8073438721782034,0.2534883715818845,0.841472299914283,0.2510482367552457,0.5100436092007222,0.3366852914031458,0.3632702384966603,0.3530759055015817,0.26785017044016746,0.33401190008102466,0.5143247073113897,0.911311011265747,0.46196936876603784,0.3186148335356194,0.23048703700157322,0.7072375219120444,0.493884803568708,0.30810819325709393,0.3354786557212636,0.6977482448052534,0.3429678924211851,0.40286399521843197,0.438079383546667,0.9975546365255823,0.32541403812587494,0.9977869065050218,0.9696659858479404,0.44327163376522427,0.736712488249047,0.3070134573642861,0.27275050140652773,0.3417913112455106,0.22851758476563463,0.43934517493493414,0.2353854078907362,0.3472276311554041,0.3863516810305896,0.26284001067360074,0.35975746667646363,0.6601018170643927,0.43155264569074586,0.3410399266223894,0.40265791260596373,0.3858619682947058,0.8966523163866474,0.44561960644106974,0.9933860683334935,0.2630060409380016,0.38809760194653736,0.6724092051956965,0.5784551626955449,0.7726050676150203,0.4445616052851885,0.7981629806804923,0.37737082047556997,0.8806371331750104,0.4111803054138714,0.7194986867504732,0.9115193885598989,0.27190163065404926,0.42496342983363,0.34923280003134577,0.5153675442306982,0.2553266761147601,0.8511804624491621,0.260522678686771,0.22750901094417858,0.917265305645748,0.23079108261592104,0.6278080168031808,0.3950575798413368,0.506189342973236,0.9880774742192298,0.25761389113776406,0.3424491539862881,0.40018762125738244,0.5089459290939424,0.26869106034208917,0.3571961622884147,0.3907660845178453,0.25909128980836804,0.9857275766939176,0.3112216578370403,0.37958766506158587,0.3476161082659223,0.9985085645532945,0.5356861874574629,0.30483050310779614,0.6653888945305232,0.26500365834005646,0.22169030783747223,0.22376675036201352,0.2611834213127523,0.21539908994723958,0.9344124294471482,0.23063902472635475,0.4454079664677166,0.3026562914243234,0.4918129434676183,0.3822140597934826,0.47668893976496607,0.5890989808257107,0.5911643616762645,0.22332063581175407,0.2693649733876409,0.5874960420632672,0.4298720841024913,0.2531642657020286,0.34084741765493015,0.38169055879525954,0.24854551869523978,0.3993653105960185,0.3734358565436859,0.4626832411619427,0.26500365834005646,0.3764476110951698,0.9737465471286418,0.49333049012531766,0.2801187596382983,0.3956719900366467,0.9792124606881502,0.7165499056029199,0.5348337146441171,0.3818095465623364,0.7737539968924578,0.27513613079891364,0.9957785937350131,0.9750835481222755,0.9217041048489304,0.9955379233447166,0.47975946113124696,0.39833822008416114,0.29923181980958347,0.2713931034898996,0.9112266298706424,0.36378333958150927,0.37123344164079625,0.3864712136270969,0.2480657909382099,0.39998199066950063,0.35470418370253187,0.3785994310451079,0.30737812862792596,0.16298964779283642,0.6482648273792284,0.6518044125554464,0.23879458169550008,0.8095259007204358,0.38689779265718777,0.3532716194850535,0.5201007411172818,0.4080270338840023,0.5928843587600032,0.5201887441250256,0.36935330150830137,0.39854356691662596,0.2246608810658983,0.46673242834812056,0.5248032397628886,0.6457920770809492,0.6600077874406464,0.27599127184965566,0.25777777458388396,0.9687037317875673,0.5316351690537969,0.3820117827329077,0.9937686563028966,0.6748390971931707,0.3369892825821378,0.8755748992579767,0.5243759090274432,0.4361443902585954,0.4404006049122718,0.5252305341771685,0.7081789328113309,0.26706327951610537,0.9093105277528926,0.3112216578370403,0.38736776354895897,0.9112404136498544,0.39015437414727033,0.5343803706051933,0.9135696477626044,0.7294520271381579,0.5275528994551462,0.3751590938006273,0.9690038905435372,0.29713630791514645,0.36676281514111675,0.2264567451816426,0.3812030840083674,0.2646700492284067,0.1680406654823225,0.26350453626445514,0.4293658054267636,0.708831467373794,0.6046509890908022,0.3585743230549301,0.4954052200904148,0.4669456696412791,0.2909122370922524,0.1759705132288035,0.3507311955128376,0.6243530528897363,0.5348337146441171,0.3315389750716856,0.2969574133542868,0.5626538842033741,0.34567576011134415,0.26818632605926,0.27054688571302815,0.40533964298700004,0.9324427623964375,0.25936898726750934,0.533981038282443,0.28150293824125144,0.9595233522643307,0.3655697876173703,0.5222387323366762,0.45438773188508624,0.2667280185073757,0.5688665730559134,0.9113810968775893,0.5160578797076667,0.3235361590156029,0.7629050367500068,0.2353854078907362,0.3839171324044438,0.8750247131338476,0.7026258178310131,0.3494275343788993,0.27650514518830116,0.29779659793151014,0.3363027328183528,0.39587686676423556,0.1797562878915237,0.2656716827053571,0.38933929775922776,0.6447721929344215,0.8818177718779798,0.33852233221670425,0.9162622771207686,0.34360759360777554,0.2697023297967259,0.2636542885887494,0.5363254055224101,0.22720801198625754,0.260522678686771,0.6394961629971918,0.5034052222568178,0.26417013986337456,0.25925578489743784,0.2392620851465269,0.651609946939421,0.19901682405507304,0.40740637213288033,0.8954553683307314,0.2599144437634275,0.21816284201832117,0.3615353791592021,0.220215593127112,0.5216853979049061,0.3592351000631369,0.38079898122060024,0.8707845716098513,0.3950575798413368,0.39957083527246656,0.2631721386378894,0.38363113893488293,0.2855439506444948,0.3926032701429938,0.25838275507323766,0.37880100877688005,0.35170729000313816,0.9980627206265597,0.46822536832983913,0.7627466941386125,0.6910214304702265,0.38122318963531543,0.7146319192010037,0.22570723693526976,0.3771695417196737,0.38140519713834903,0.22791398763164447,0.602601157770604,0.9752558096517164,0.9939050887850829,0.5395394637422258,0.9610316393712252,0.2546248983787507,0.4866054685425905,0.3339334730030284,0.33764262400433254,0.3854761933662152,0.3425818821043629,0.4325172576350512,0.3447075043823677,0.26924899428383864,0.2297281510989427,0.5151535603514821,0.6634596814053674,0.32692039424589214,0.258038235932058,0.4020398712574854,0.4931645757558614,0.3757617798304868,0.4024518643636562,0.9904528091027757,0.9934476992176381,0.40059898787974996,0.48596340192158066,0.1897607974009772,0.7086546149921334,0.5361335430686779,0.3039800777094909,0.4357887907432664,0.701262687332822,0.397376044130393,0.9168090446826993,0.22585699786648866,0.533981038282443,0.9924534050117031,0.39895436761865544,0.2715625462161114,0.5282417661815527,0.38486753264164314,0.3956719900366467,0.33967435017429387,0.45731627115540313,0.3522935427463685,0.3885248393341327,0.7646288740585545,0.5286475072696817,0.9923170304065368,0.2447625428672553,0.9752701973535047,0.30319902132526877,0.328697115617477,0.3907660845178453,0.6988312298152728,0.47450408751024464,0.3759827579866855,0.3522935427463685,0.41286816164699713,0.3318406442451929,0.5155815224754117,0.381001012015258,0.27037784148959665,0.6419074576795636,0.37940599292480665,0.997936185226517,0.37277216061718094,0.37817635786664716,0.9452308219216711,0.40039328701629007,0.5196459344782088,0.22036274727396782,0.7407720729637272,0.44012359514899335,0.386694588387342,0.2241669987032286,0.33338099003240246,0.5380505828670833,0.3860852125136652,0.26634078081610135,0.2610181341334377,0.3573928984347446,0.34084741765493015,0.3412133284793995,0.9962998703557643,0.3977223944532253,0.6789008738401056,0.22006850950925141,0.3326009098551863,0.7572679395147288,0.2252583763818834,0.26383720339329997,0.2556526027054781,0.7819624053474381,0.3538590564910031,0.33975343779548267,0.7065274626121366,0.6996081802738304,0.25838275507323766,0.4594150585560504,0.2996473469686077,0.3425818821043629,0.2736010264527174,0.3842592320322373,0.9857275638050624,0.3979276337865008,0.3681567465598909,0.4739889449531102,0.29767336463220956,0.9953328537867009,0.9657104362992485,0.38626809224905134,0.2683545040615933,0.9121384330930422,0.6103440614192859,0.3812030840083674,0.26068776280142947,0.33975343779548267,0.28809269860456904,0.38122318963531543,0.6468156204510782,0.22376675036201352,0.2584339885124234,0.39854356691662596,0.2656716827053571,0.9937420734424578,0.2730905130760174,0.23461531119347348,0.267346438302705,0.9211458517785017,0.35405496700026123,0.25558551367433885,0.5101317194116305,0.34509465254538146,0.3909497695163671,0.3899505473395629,0.34917204177709854,0.6589636547542329,0.35412394438879846,0.25658102032072727,0.22436255582282735,0.7167238811704603,0.4289669164481885,0.2355396370048312,0.34110001146047236,0.4623449327647889,0.9855578327970672,0.9726376044575038,0.3885045904003771,0.5248032397628886,0.496591137135884,0.8989997169798826,0.7867299989764518,0.35837729925596906,0.18818514648925921,0.3374510506881966,0.42337549434377425,0.7736569603441292,0.4752707360628833,0.3926032701429938,0.1794760494399509,0.2562543175902648,0.9545017750820127,0.2545130550418662,0.27224098025045523,0.6475145779426429,0.38140519713834903,0.3002929235680569,0.27343078924269154,0.24854551869523978,0.26450334551257715,0.37926722852364747,0.21094453313542869,0.8650049412964522,0.3899505473395629,0.3673599429198848,0.3034365585402389,0.8733499742999938,0.27343078924269154,0.2529648040093742,0.4519776383618084,0.5276012198168977,0.36955288402881353,0.7255103873891725,0.7042128341467032,0.7735069009488857,0.7122335353153317,0.3569994742755006,0.47462979871745575,0.39074579341890203,0.4308357866823358,0.3838337408841039,0.385133687968549,0.38241637768220615,0.515795495007319,0.19870125176608885,0.8200209850774893,0.25679549501097665,0.2675142821473915,0.35778651490936186,0.25909128980836804,0.8776453222268498,0.5229022963049424,0.5091871926411634,0.22540792618768485,0.6687946899749456,0.5008079138676191,0.3875076415190893,0.3141676633470587,0.255927887640754,0.27428263557616983,0.9780872701792255,0.33279111274485645,0.3909700644103314,0.2556017306092931,0.9742587520500744,0.4346701289818353,0.551435252835975,0.2578905562740318,0.9979005926147556,0.5371987006845298,0.4921716711622953,0.369036365502866,0.9741942162890541,0.9980157795595778,0.4429358184951794,0.9066849454830321,0.39362524768123164,0.9610729257351444,0.30374230054891704,0.5222599984375874,0.9765470183187555,0.37283467294626854,0.26538965520016156,0.2635564243614291,0.3765659598409728,0.3509069009097832,0.48211204905105093,0.19303415389217396,0.3735538256745847,0.9947571156899802,0.33110013092939344,0.4397672816468379,0.5083307221532812,0.2282627385116064,0.37857937913327516,0.7420858644192143,0.9956055331556811,0.34625732884596794,0.7759142266198638,0.27942823163335084,0.8303294922315068,0.328449128103728,0.2569079956940124,0.5138966817041266,0.2409816267180369,0.7092761153334541,0.381001012015258,0.26222828407154075,0.34878275546496734,0.3979072136946024,0.4390473164167983,0.49024461893366655,0.49005181870785364,0.7158533579545678,0.26768219286710676,0.8952290940868939,0.7323167272711453,0.24941961492394685,0.3838337408841039,0.3658973036005022,0.30717762329469217,0.9413072782724724,0.38466472567560117,0.9449538203248662,0.5130802211818987,0.42854724646498976,0.24599414988151383,0.4008047237812398,0.5665038776990201,0.22791398763164447,0.26818632605926,0.2514369017826845,0.3854560031620262,0.5019941266057918,0.4846794097723401,0.2353854078907362,0.3485688338850034,0.37676711134194324,0.6231013598604148,0.39280759071776084,0.41827809497967416,0.6980220539648213,0.5320617978180858,0.5322963141116568,0.32831914099305737,0.3509263148235634,0.31067097004718125,0.42538220272414196,0.3468393573752633,0.2853692017353198,0.9722776247831499,0.29982717092380334,0.38872839578332635,0.9914173578480371,0.2618969238841438,0.5106858832080889,0.5231149679186864,0.2640036379707903,0.9979589968571556,0.36977237374869465,0.235848304935462,0.2770196092310301,0.31663763448678056,0.7012073698097523,0.501905981856333,0.6395605054434915,0.6636699722331726,0.6263602536576013,0.23430776215442953,0.2373958362211433,0.3066490271970156,0.5113281219365052,0.7461392585982279,0.9947378132672479,0.7894626266550354,0.3923989871639959,0.9678514309165006,0.3987489494501518,0.993463854968374,0.3743561141450993,0.24129517520231375,0.5179620134094598,0.2291223060605212,0.35778651490936186,0.6365032793337023,0.38249965242519085,0.25111453655049454,0.174484709178406,0.8747939002384891,0.2572352435709595,0.2712765753692646,0.3483936708332064,0.2656716827053571,0.29887264285346865,0.7105965062079371,0.9865471644165336,0.8687511165658968,0.16439706025382558,0.7999501481515475,0.49088694029301183,0.26383720339329997,0.5991724122492789,0.9905415128514637,0.848667090072807,0.28591676433402907,0.35975746667646363,0.5478194051182418,0.5175341863645425,0.4022458505585119,0.43546355374332607,0.6190954290859189,0.21564358749923357,0.5100164606244293,0.3449010527420462,0.5147527119074682,0.22042991083674882,0.5816714105257165,0.8291507799796312,0.25876250331184797,0.8539070994573581,0.9070964251119022,0.9964393084140947,0.25826983304447965,0.373754332784852,0.5096154079759664,0.977841488582892,0.2303351194487633,0.3751590938006273,0.9966113321961898,0.4057527230257632,0.539093944681618,0.5070855966642367,0.36803948049155644,0.35936289520274234,0.7577770770777527,0.9801536358949918,0.2212471530752429,0.9926932130403254,0.7099828233837501,0.5335546253132136,0.9970603729295194,0.9793492268615315,0.5239485425935955,0.5324613347756721,0.9963469439138672,0.7577497908233725,0.58096004054284,0.7159077360062656,0.3503411066400181,0.7151557790504754,0.24105238799852363,0.34515507757376307,0.38933929775922776,0.9988258364731543,0.24822563122413246,0.9929820197504959,0.2364664793487796,0.7748549025661509,0.39074579341890203,0.476097195605312,0.3019335077119403,0.19706942100238925,0.4002517972766348,0.8184349330003167,0.26650822295897836,0.3747575178136139,0.29108899773086705,0.2553266761147601,0.2081400274370645,0.7951020883088116,0.9853557654536651,0.30737812862792596,0.4340764342871178,0.2530023155198339,0.2909928775469899,0.3405225929226924,0.7538954924299914,0.6990677587154622,0.31527630348264396,0.27462383596904466],\"xaxis\":\"x\",\"yaxis\":\"y\",\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"count\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.histogram(x=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32d4ae99-0d41-48d7-bb3c-a3958ebb492e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d19f1c-740e-41cc-a41d-0d5ae18627fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"ff0f5545-4581-4e5e-963d-8d85e79a06b7\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff0f5545-4581-4e5e-963d-8d85e79a06b7\")) {                    Plotly.newPlot(                        \"ff0f5545-4581-4e5e-963d-8d85e79a06b7\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.0010660980810234541,0.0010660980810234541,0.0021321961620469083,0.0021321961620469083,0.006396588486140725,0.006396588486140725,0.007462686567164179,0.007462686567164179,0.008528784648187633,0.008528784648187633,0.009594882729211088,0.009594882729211088,0.011727078891257996,0.011727078891257996,0.01279317697228145,0.01279317697228145,0.01812366737739872,0.01812366737739872,0.021321961620469083,0.021321961620469083,0.022388059701492536,0.022388059701492536,0.023454157782515993,0.023454157782515993,0.024520255863539446,0.024520255863539446,0.0255863539445629,0.0255863539445629,0.029850746268656716,0.029850746268656716,0.03411513859275053,0.03411513859275053,0.035181236673773986,0.035181236673773986,0.039445628997867806,0.039445628997867806,0.042643923240938165,0.042643923240938165,0.04584221748400853,0.04584221748400853,0.054371002132196165,0.054371002132196165,0.057569296375266525,0.057569296375266525,0.0650319829424307,0.0650319829424307,0.07889125799573561,0.07889125799573561,0.08315565031982942,0.08315565031982942,0.08955223880597014,0.08955223880597014,0.09808102345415778,0.09808102345415778,0.11087420042643924,0.11087420042643924,0.11194029850746269,0.11194029850746269,0.1300639658848614,0.1300639658848614,0.13326226012793177,0.13326226012793177,0.13539445628997868,0.13539445628997868,0.1396588486140725,0.1396588486140725,0.14072494669509594,0.14072494669509594,0.14712153518123666,0.14818763326226012,0.14925373134328357,0.14925373134328357,0.1535181236673774,0.15565031982942432,0.1886993603411514,0.1886993603411514,0.1908315565031983,0.1908315565031983,0.19829424307036247,0.19829424307036247,0.23667377398720682,0.23880597014925373,0.23987206823027718,0.2420042643923241,0.26119402985074625,0.26332622601279315,0.2921108742004264,0.2942430703624733,0.2995735607675906,0.3017057569296375,0.30383795309168443,0.3049040511727079,0.32409381663113007,0.326226012793177,0.35181236673773986,0.35181236673773986,0.36673773987206826,0.36673773987206826,0.36886993603411516,0.36886993603411516,0.37100213219616207,0.39232409381663114,0.39232409381663114,0.4157782515991471,0.4157782515991471,0.417910447761194,0.417910447761194,0.4200426439232409,0.42217484008528783,0.42430703624733473,0.42857142857142855,0.43283582089552236,0.43603411513859275,0.43923240938166314,0.44029850746268656,0.44243070362473347,0.44776119402985076,0.44989339019189767,0.4520255863539446,0.4562899786780384,0.4594882729211087,0.4594882729211087,0.4605543710021322,0.46375266524520253,0.4680170575692964,0.4701492537313433,0.4701492537313433,0.4722814498933902,0.4722814498933902,0.47654584221748403,0.47867803837953093,0.48507462686567165,0.4861407249466951,0.48933901918976547,0.4904051172707889,0.4925373134328358,0.4946695095948827,0.4946695095948827,0.4968017057569296,0.4968017057569296,0.5159914712153518,0.5181236673773987,0.5191897654584222,0.5223880597014925,0.5298507462686567,0.5319829424307037,0.5330490405117271,0.5415778251599147,0.5543710021321961,0.5565031982942431,0.5650319829424307,0.5671641791044776,0.5724946695095949,0.5735607675906184,0.5778251599147122,0.5778251599147122,0.5852878464818764,0.5852878464818764,0.5884861407249466,0.5906183368869936,0.5948827292110874,0.5970149253731343,0.5991471215351812,0.6012793176972282,0.603411513859275,0.6044776119402985,0.6108742004264393,0.6130063965884861,0.6140724946695096,0.6162046908315565,0.6172707889125799,0.6194029850746269,0.6257995735607675,0.6257995735607675,0.6279317697228145,0.6300639658848614,0.6332622601279317,0.6481876332622601,0.6481876332622601,0.650319829424307,0.6577825159914712,0.6599147121535182,0.6631130063965884,0.6652452025586354,0.6684434968017058,0.6705756929637526,0.6727078891257996,0.6748400852878464,0.7100213219616205,0.7121535181236673,0.7142857142857143,0.7164179104477612,0.7174840085287847,0.7217484008528785,0.7761194029850746,0.7782515991471215,0.7857142857142857,0.7878464818763327,0.7931769722814499,0.7953091684434968,0.8017057569296375,0.8038379530916845,0.8081023454157783,0.8102345415778252,0.8166311300639659,0.8198294243070362,0.8219616204690832,0.82409381663113,0.8283582089552238,0.8326226012793176,0.847547974413646,0.849680170575693,0.8507462686567164,0.8528784648187633,0.8550106609808102,0.8571428571428571,0.8592750533049041,0.8592750533049041,0.8614072494669509,0.8688699360341151,0.8688699360341151,0.8731343283582089,0.8752665245202559,0.8795309168443497,0.8827292110874201,0.8955223880597015,0.8976545842217484,0.9221748400852878,0.9243070362473348,0.9275053304904051,0.9381663113006397,0.9402985074626866,0.9434968017057569,0.9456289978678039,0.9466950959488273,0.9488272921108742,0.9520255863539445,0.9541577825159915,0.9573560767590619,0.9573560767590619,0.9605543710021321,0.9637526652452025,0.9701492537313433,0.9701492537313433,0.9722814498933902,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.010101010101010102,0.1111111111111111,0.1111111111111111,0.20202020202020202,0.20202020202020202,0.24242424242424243,0.24242424242424243,0.26262626262626265,0.26262626262626265,0.2828282828282828,0.2828282828282828,0.29292929292929293,0.29292929292929293,0.32323232323232326,0.32323232323232326,0.37373737373737376,0.37373737373737376,0.3939393939393939,0.3939393939393939,0.41414141414141414,0.41414141414141414,0.42424242424242425,0.42424242424242425,0.43434343434343436,0.43434343434343436,0.4444444444444444,0.4444444444444444,0.45454545454545453,0.45454545454545453,0.494949494949495,0.494949494949495,0.5050505050505051,0.5050505050505051,0.5151515151515151,0.5151515151515151,0.5353535353535354,0.5353535353535354,0.5454545454545454,0.5454545454545454,0.5555555555555556,0.5555555555555556,0.5656565656565656,0.5656565656565656,0.5757575757575758,0.5757575757575758,0.5858585858585859,0.5858585858585859,0.5959595959595959,0.5959595959595959,0.6060606060606061,0.6060606060606061,0.6161616161616161,0.6161616161616161,0.6262626262626263,0.6262626262626263,0.6363636363636364,0.6363636363636364,0.6464646464646465,0.6464646464646465,0.6565656565656566,0.6565656565656566,0.6666666666666666,0.6666666666666666,0.6767676767676768,0.6767676767676768,0.6868686868686869,0.6868686868686869,0.696969696969697,0.696969696969697,0.7070707070707071,0.7070707070707071,0.7171717171717171,0.7171717171717171,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7373737373737373,0.7373737373737373,0.7474747474747475,0.7474747474747475,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7777777777777778,0.7777777777777778,0.7878787878787878,0.7878787878787878,0.797979797979798,0.797979797979798,0.797979797979798,0.8080808080808081,0.8080808080808081,0.8181818181818182,0.8181818181818182,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8383838383838383,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8585858585858586,0.8585858585858586,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8888888888888888,0.8888888888888888,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.9090909090909091,0.9090909090909091,0.9191919191919192,0.9191919191919192,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8364)\"},\"height\":500,\"width\":700,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}]},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"ff0f5545-4581-4e5e-963d-8d85e79a06b7\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ff0f5545-4581-4e5e-963d-8d85e79a06b7\")) {                    Plotly.newPlot(                        \"ff0f5545-4581-4e5e-963d-8d85e79a06b7\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"False Positive Rate=%{x}<br>True Positive Rate=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[0.0,0.0,0.0,0.0010660980810234541,0.0010660980810234541,0.0021321961620469083,0.0021321961620469083,0.006396588486140725,0.006396588486140725,0.007462686567164179,0.007462686567164179,0.008528784648187633,0.008528784648187633,0.009594882729211088,0.009594882729211088,0.011727078891257996,0.011727078891257996,0.01279317697228145,0.01279317697228145,0.01812366737739872,0.01812366737739872,0.021321961620469083,0.021321961620469083,0.022388059701492536,0.022388059701492536,0.023454157782515993,0.023454157782515993,0.024520255863539446,0.024520255863539446,0.0255863539445629,0.0255863539445629,0.029850746268656716,0.029850746268656716,0.03411513859275053,0.03411513859275053,0.035181236673773986,0.035181236673773986,0.039445628997867806,0.039445628997867806,0.042643923240938165,0.042643923240938165,0.04584221748400853,0.04584221748400853,0.054371002132196165,0.054371002132196165,0.057569296375266525,0.057569296375266525,0.0650319829424307,0.0650319829424307,0.07889125799573561,0.07889125799573561,0.08315565031982942,0.08315565031982942,0.08955223880597014,0.08955223880597014,0.09808102345415778,0.09808102345415778,0.11087420042643924,0.11087420042643924,0.11194029850746269,0.11194029850746269,0.1300639658848614,0.1300639658848614,0.13326226012793177,0.13326226012793177,0.13539445628997868,0.13539445628997868,0.1396588486140725,0.1396588486140725,0.14072494669509594,0.14072494669509594,0.14712153518123666,0.14818763326226012,0.14925373134328357,0.14925373134328357,0.1535181236673774,0.15565031982942432,0.1886993603411514,0.1886993603411514,0.1908315565031983,0.1908315565031983,0.19829424307036247,0.19829424307036247,0.23667377398720682,0.23880597014925373,0.23987206823027718,0.2420042643923241,0.26119402985074625,0.26332622601279315,0.2921108742004264,0.2942430703624733,0.2995735607675906,0.3017057569296375,0.30383795309168443,0.3049040511727079,0.32409381663113007,0.326226012793177,0.35181236673773986,0.35181236673773986,0.36673773987206826,0.36673773987206826,0.36886993603411516,0.36886993603411516,0.37100213219616207,0.39232409381663114,0.39232409381663114,0.4157782515991471,0.4157782515991471,0.417910447761194,0.417910447761194,0.4200426439232409,0.42217484008528783,0.42430703624733473,0.42857142857142855,0.43283582089552236,0.43603411513859275,0.43923240938166314,0.44029850746268656,0.44243070362473347,0.44776119402985076,0.44989339019189767,0.4520255863539446,0.4562899786780384,0.4594882729211087,0.4594882729211087,0.4605543710021322,0.46375266524520253,0.4680170575692964,0.4701492537313433,0.4701492537313433,0.4722814498933902,0.4722814498933902,0.47654584221748403,0.47867803837953093,0.48507462686567165,0.4861407249466951,0.48933901918976547,0.4904051172707889,0.4925373134328358,0.4946695095948827,0.4946695095948827,0.4968017057569296,0.4968017057569296,0.5159914712153518,0.5181236673773987,0.5191897654584222,0.5223880597014925,0.5298507462686567,0.5319829424307037,0.5330490405117271,0.5415778251599147,0.5543710021321961,0.5565031982942431,0.5650319829424307,0.5671641791044776,0.5724946695095949,0.5735607675906184,0.5778251599147122,0.5778251599147122,0.5852878464818764,0.5852878464818764,0.5884861407249466,0.5906183368869936,0.5948827292110874,0.5970149253731343,0.5991471215351812,0.6012793176972282,0.603411513859275,0.6044776119402985,0.6108742004264393,0.6130063965884861,0.6140724946695096,0.6162046908315565,0.6172707889125799,0.6194029850746269,0.6257995735607675,0.6257995735607675,0.6279317697228145,0.6300639658848614,0.6332622601279317,0.6481876332622601,0.6481876332622601,0.650319829424307,0.6577825159914712,0.6599147121535182,0.6631130063965884,0.6652452025586354,0.6684434968017058,0.6705756929637526,0.6727078891257996,0.6748400852878464,0.7100213219616205,0.7121535181236673,0.7142857142857143,0.7164179104477612,0.7174840085287847,0.7217484008528785,0.7761194029850746,0.7782515991471215,0.7857142857142857,0.7878464818763327,0.7931769722814499,0.7953091684434968,0.8017057569296375,0.8038379530916845,0.8081023454157783,0.8102345415778252,0.8166311300639659,0.8198294243070362,0.8219616204690832,0.82409381663113,0.8283582089552238,0.8326226012793176,0.847547974413646,0.849680170575693,0.8507462686567164,0.8528784648187633,0.8550106609808102,0.8571428571428571,0.8592750533049041,0.8592750533049041,0.8614072494669509,0.8688699360341151,0.8688699360341151,0.8731343283582089,0.8752665245202559,0.8795309168443497,0.8827292110874201,0.8955223880597015,0.8976545842217484,0.9221748400852878,0.9243070362473348,0.9275053304904051,0.9381663113006397,0.9402985074626866,0.9434968017057569,0.9456289978678039,0.9466950959488273,0.9488272921108742,0.9520255863539445,0.9541577825159915,0.9573560767590619,0.9573560767590619,0.9605543710021321,0.9637526652452025,0.9701492537313433,0.9701492537313433,0.9722814498933902,1.0],\"xaxis\":\"x\",\"y\":[0.0,0.010101010101010102,0.1111111111111111,0.1111111111111111,0.20202020202020202,0.20202020202020202,0.24242424242424243,0.24242424242424243,0.26262626262626265,0.26262626262626265,0.2828282828282828,0.2828282828282828,0.29292929292929293,0.29292929292929293,0.32323232323232326,0.32323232323232326,0.37373737373737376,0.37373737373737376,0.3939393939393939,0.3939393939393939,0.41414141414141414,0.41414141414141414,0.42424242424242425,0.42424242424242425,0.43434343434343436,0.43434343434343436,0.4444444444444444,0.4444444444444444,0.45454545454545453,0.45454545454545453,0.494949494949495,0.494949494949495,0.5050505050505051,0.5050505050505051,0.5151515151515151,0.5151515151515151,0.5353535353535354,0.5353535353535354,0.5454545454545454,0.5454545454545454,0.5555555555555556,0.5555555555555556,0.5656565656565656,0.5656565656565656,0.5757575757575758,0.5757575757575758,0.5858585858585859,0.5858585858585859,0.5959595959595959,0.5959595959595959,0.6060606060606061,0.6060606060606061,0.6161616161616161,0.6161616161616161,0.6262626262626263,0.6262626262626263,0.6363636363636364,0.6363636363636364,0.6464646464646465,0.6464646464646465,0.6565656565656566,0.6565656565656566,0.6666666666666666,0.6666666666666666,0.6767676767676768,0.6767676767676768,0.6868686868686869,0.6868686868686869,0.696969696969697,0.696969696969697,0.7070707070707071,0.7070707070707071,0.7171717171717171,0.7171717171717171,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7373737373737373,0.7373737373737373,0.7474747474747475,0.7474747474747475,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7777777777777778,0.7777777777777778,0.7878787878787878,0.7878787878787878,0.797979797979798,0.797979797979798,0.797979797979798,0.8080808080808081,0.8080808080808081,0.8181818181818182,0.8181818181818182,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8383838383838383,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8585858585858586,0.8585858585858586,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8888888888888888,0.8888888888888888,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.9090909090909091,0.9090909090909091,0.9191919191919192,0.9191919191919192,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"False Positive Rate\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"True Positive Rate\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"ROC Curve (AUC=0.8364)\"},\"height\":500,\"width\":700,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":0,\"y1\":1}]},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test_c, probs)\n",
    "\n",
    "fig = px.area(\n",
    "    x=fpr, y=tpr,\n",
    "    title=f'ROC Curve (AUC={auc(fpr, tpr):.4f})',\n",
    "    labels=dict(x='False Positive Rate', y='True Positive Rate'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=0, y1=1\n",
    ")\n",
    "\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abd01105-0ac3-4afa-8442-72966dfb9218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"7c033536-9a23-4b9c-9075-d069f1d83257\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7c033536-9a23-4b9c-9075-d069f1d83257\")) {                    Plotly.newPlot(                        \"7c033536-9a23-4b9c-9075-d069f1d83257\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}<br>Precision=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.8888888888888888,0.8888888888888888,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8585858585858586,0.8585858585858586,0.8585858585858586,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8383838383838383,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8181818181818182,0.8181818181818182,0.8181818181818182,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.7878787878787878,0.7878787878787878,0.7878787878787878,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7373737373737373,0.7373737373737373,0.7373737373737373,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7171717171717171,0.7171717171717171,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.696969696969697,0.696969696969697,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6767676767676768,0.6767676767676768,0.6767676767676768,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6464646464646465,0.6464646464646465,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5757575757575758,0.5757575757575758,0.5757575757575758,0.5757575757575758,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5454545454545454,0.5454545454545454,0.5454545454545454,0.5454545454545454,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5252525252525253,0.5151515151515151,0.5151515151515151,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.494949494949495,0.494949494949495,0.494949494949495,0.494949494949495,0.494949494949495,0.48484848484848486,0.47474747474747475,0.46464646464646464,0.45454545454545453,0.45454545454545453,0.4444444444444444,0.4444444444444444,0.43434343434343436,0.43434343434343436,0.42424242424242425,0.42424242424242425,0.41414141414141414,0.41414141414141414,0.41414141414141414,0.41414141414141414,0.40404040404040403,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3838383838383838,0.37373737373737376,0.37373737373737376,0.36363636363636365,0.35353535353535354,0.3434343434343434,0.3333333333333333,0.32323232323232326,0.32323232323232326,0.32323232323232326,0.31313131313131315,0.30303030303030304,0.29292929292929293,0.29292929292929293,0.2828282828282828,0.2828282828282828,0.2727272727272727,0.26262626262626265,0.26262626262626265,0.25252525252525254,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.23232323232323232,0.2222222222222222,0.21212121212121213,0.20202020202020202,0.20202020202020202,0.1919191919191919,0.18181818181818182,0.1717171717171717,0.16161616161616163,0.15151515151515152,0.1414141414141414,0.13131313131313133,0.12121212121212122,0.1111111111111111,0.1111111111111111,0.10101010101010101,0.09090909090909091,0.08080808080808081,0.0707070707070707,0.06060606060606061,0.050505050505050504,0.04040404040404041,0.030303030303030304,0.020202020202020204,0.010101010101010102,0.0],\"xaxis\":\"x\",\"y\":[0.09546769527483125,0.09555984555984556,0.09565217391304348,0.09574468085106383,0.09583736689254599,0.09593023255813954,0.09602327837051407,0.09611650485436893,0.09620991253644315,0.0963035019455253,0.09639727361246349,0.09649122807017543,0.09658536585365854,0.0966796875,0.0967741935483871,0.09686888454011741,0.0969637610186092,0.09705882352941177,0.0971540726202159,0.09724950884086445,0.09734513274336283,0.09744094488188976,0.09753694581280788,0.09763313609467456,0.09772951628825272,0.09782608695652174,0.09792284866468842,0.0981169474727453,0.09722222222222222,0.09731876861966236,0.09741550695825049,0.09751243781094528,0.09760956175298804,0.09770687936191426,0.09780439121756487,0.0980980980980981,0.09819639278557114,0.09829488465396188,0.09839357429718876,0.09748743718592964,0.09758551307847083,0.09768378650553877,0.09778225806451613,0.09797979797979799,0.0980788675429727,0.09817813765182186,0.09827760891590678,0.09847715736040609,0.09857723577235772,0.09877800407331976,0.09887869520897044,0.09897959183673469,0.09908069458631256,0.0992835209825998,0.09938524590163934,0.09948717948717949,0.09958932238193019,0.09969167523124357,0.09979423868312758,0.09989701338825953,0.1,0.1001031991744066,0.10020661157024793,0.10031023784901758,0.10062240663900415,0.10083160083160084,0.10093652445369407,0.10104166666666667,0.10114702815432743,0.10125260960334029,0.1013584117032393,0.10146443514644352,0.10157068062827225,0.10167714884696016,0.10178384050367262,0.10189075630252101,0.10199789695057834,0.10210526315789474,0.10221285563751317,0.10232067510548523,0.10242872228088701,0.10253699788583509,0.10264550264550265,0.1027542372881356,0.10286320254506894,0.1029723991507431,0.1030818278427205,0.10319148936170212,0.1033013844515442,0.10352187833511206,0.10363247863247864,0.10374331550802139,0.10385438972162742,0.10396570203644159,0.10407725321888411,0.1041890440386681,0.1043010752688172,0.10441334768568353,0.10452586206896551,0.104638619201726,0.10475161987041037,0.10486486486486486,0.1052060737527115,0.10532030401737243,0.10543478260869565,0.10554951033732318,0.1056644880174292,0.10589519650655022,0.10601092896174863,0.1061269146608315,0.10624315443592552,0.10635964912280702,0.10537870472008781,0.1054945054945055,0.10561056105610561,0.10572687224669604,0.10584343991179714,0.10596026490066225,0.10607734806629834,0.10619469026548672,0.10643015521064302,0.10543840177580466,0.10555555555555556,0.10567296996662959,0.10590858416945373,0.10602678571428571,0.10614525139664804,0.10638297872340426,0.10650224215246637,0.10674157303370786,0.10686164229471316,0.10698198198198199,0.10710259301014656,0.1072234762979684,0.10734463276836158,0.1074660633484163,0.10758776896942242,0.10770975056689343,0.10783200908059024,0.10795454545454546,0.1080773606370876,0.1082004555808656,0.10832383124287344,0.10844748858447488,0.10869565217391304,0.10894495412844037,0.10907003444316878,0.10919540229885058,0.1093210586881473,0.10944700460829493,0.10969976905311778,0.10982658959537572,0.1099537037037037,0.11033681765389082,0.11046511627906977,0.11059371362048893,0.11072261072261072,0.11085180863477247,0.11098130841121495,0.1111111111111111,0.11137162954279015,0.11150234741784038,0.11163337250293771,0.11176470588235295,0.11189634864546526,0.11216056670602124,0.11229314420803782,0.11242603550295859,0.11255924170616113,0.11269276393831554,0.11282660332541568,0.11296076099881094,0.11323003575685339,0.11336515513126491,0.1135005973715651,0.11363636363636363,0.11377245508982035,0.11390887290167866,0.1141826923076923,0.11432009626955475,0.1144578313253012,0.11459589867310012,0.11473429951690821,0.11487303506650544,0.11501210653753027,0.11515151515151516,0.11543134872417983,0.11557177615571776,0.11571254567600488,0.11585365853658537,0.115995115995116,0.11613691931540342,0.11627906976744186,0.11642156862745098,0.1165644171779141,0.1167076167076167,0.11685116851168512,0.11699507389162561,0.11713933415536375,0.11728395061728394,0.11742892459826947,0.11757425742574257,0.11771995043370508,0.11786600496277916,0.11801242236024845,0.1181592039800995,0.11830635118306351,0.11845386533665836,0.11860174781523096,0.11875,0.11889862327909888,0.11904761904761904,0.1191969887076537,0.11934673366834171,0.11949685534591195,0.11964735516372796,0.11979823455233292,0.11994949494949494,0.12010113780025285,0.12025316455696203,0.12040557667934093,0.12055837563451777,0.1207115628970775,0.12086513994910941,0.12101910828025478,0.1211734693877551,0.12132822477650064,0.12148337595907928,0.12163892445582586,0.12179487179487179,0.12195121951219512,0.12210796915167095,0.12226512226512226,0.12242268041237113,0.12258064516129032,0.1227390180878553,0.12289780077619664,0.12305699481865284,0.12337662337662338,0.12369791666666667,0.12385919165580182,0.12418300653594772,0.1243455497382199,0.12450851900393185,0.12483574244415244,0.125,0.1251646903820817,0.12532981530343007,0.12549537648612946,0.12566137566137567,0.12582781456953643,0.1259946949602122,0.12616201859229748,0.12632978723404256,0.12649800266311584,0.12666666666666668,0.1268357810413885,0.1270053475935829,0.12717536813922356,0.12734584450402145,0.12751677852348994,0.12768817204301075,0.1278600269179004,0.1280323450134771,0.1282051282051282,0.12837837837837837,0.12855209742895804,0.12872628726287264,0.12890094979647218,0.12907608695652173,0.1292517006802721,0.12942779291553133,0.1296043656207367,0.12978142076502733,0.12995896032831739,0.13013698630136986,0.13031550068587106,0.1304945054945055,0.13085399449035812,0.1310344827586207,0.13121546961325967,0.13157894736842105,0.1317614424410541,0.13194444444444445,0.13212795549374132,0.13249651324965134,0.13268156424581007,0.13286713286713286,0.1330532212885154,0.13342696629213482,0.13361462728551335,0.13380281690140844,0.13399153737658676,0.134180790960452,0.13437057991513437,0.13456090651558072,0.1347517730496454,0.13513513513513514,0.1339031339031339,0.1340941512125535,0.13428571428571429,0.13447782546494993,0.1346704871060172,0.13486370157819225,0.13505747126436782,0.13525179856115108,0.13544668587896252,0.13564213564213565,0.13583815028901733,0.13603473227206947,0.13623188405797101,0.13642960812772134,0.13662790697674418,0.13722627737226278,0.1376281112737921,0.1378299120234604,0.13803230543318648,0.13676470588235295,0.13696612665684832,0.13716814159292035,0.13737075332348597,0.13757396449704143,0.13777777777777778,0.13798219584569732,0.13839285714285715,0.13859910581222057,0.13901345291479822,0.13922155688622753,0.13963963963963963,0.13984962406015036,0.14006024096385541,0.14027149321266968,0.1404833836858006,0.14069591527987896,0.1409090909090909,0.1398176291793313,0.1400304414003044,0.1402439024390244,0.14067278287461774,0.14088820826952528,0.1411042944785276,0.14153846153846153,0.14175654853620956,0.1419753086419753,0.14219474497681608,0.14241486068111456,0.14285714285714285,0.14307931570762053,0.14330218068535824,0.1435257410296412,0.1421875,0.14241001564945227,0.1426332288401254,0.14285714285714285,0.1430817610062893,0.14330708661417324,0.14353312302839116,0.14375987361769352,0.14240506329113925,0.14263074484944532,0.14285714285714285,0.14308426073131955,0.14331210191082802,0.14217252396166133,0.1424,0.14262820512820512,0.14285714285714285,0.14308681672025725,0.143317230273752,0.14378029079159935,0.14401294498381878,0.14424635332252836,0.1444805194805195,0.14471544715447154,0.1449511400651466,0.14518760195758565,0.1454248366013072,0.14566284779050737,0.14614121510673234,0.14638157894736842,0.14662273476112025,0.14686468646864687,0.14710743801652892,0.14735099337748345,0.14759535655058043,0.1478405315614618,0.1480865224625624,0.14833333333333334,0.14858096828046743,0.1488294314381271,0.1490787269681742,0.1495798319327731,0.15008431703204048,0.1505922165820643,0.15110356536502548,0.15136054421768708,0.15187713310580206,0.15213675213675212,0.1523972602739726,0.15265866209262435,0.15292096219931273,0.153184165232358,0.15344827586206897,0.153713298791019,0.1545138888888889,0.15478260869565216,0.15532286212914484,0.1555944055944056,0.15586690017513136,0.156140350877193,0.15641476274165203,0.15669014084507044,0.15696649029982362,0.15724381625441697,0.15752212389380532,0.15780141843971632,0.15808170515097691,0.1583629893238434,0.1586452762923351,0.15892857142857142,0.1592128801431127,0.15949820788530467,0.15978456014362658,0.16007194244604317,0.16036036036036036,0.1588447653429603,0.15942028985507245,0.15789473684210525,0.15818181818181817,0.15846994535519127,0.1590493601462523,0.15934065934065933,0.15867158671586715,0.1589648798521257,0.15955473098330242,0.1601489757914339,0.16074766355140188,0.16104868913857678,0.16135084427767354,0.16195856873822975,0.16257088846880907,0.16098484848484848,0.16129032258064516,0.16159695817490494,0.16,0.16030534351145037,0.16061185468451242,0.16184971098265896,0.16216216216216217,0.16247582205029013,0.16279069767441862,0.1614785992217899,0.15984405458089668,0.16015625,0.16046966731898238,0.1607843137254902,0.16205533596837945,0.16237623762376238,0.1626984126984127,0.16334661354581673,0.16367265469061876,0.164,0.16432865731462926,0.1646586345381526,0.16498993963782696,0.16565656565656567,0.1659919028340081,0.1670061099796334,0.1673469387755102,0.16768916155419222,0.1680327868852459,0.16872427983539096,0.16942148760330578,0.16977225672877846,0.17012448132780084,0.1704781704781705,0.17083333333333334,0.17154811715481172,0.1719077568134172,0.1722689075630252,0.1729957805907173,0.17124735729386892,0.1716101694915254,0.17197452229299362,0.1702127659574468,0.17057569296375266,0.17094017094017094,0.17130620985010706,0.17167381974248927,0.17204301075268819,0.1724137931034483,0.17278617710583152,0.17316017316017315,0.1735357917570499,0.17391304347826086,0.17429193899782136,0.17467248908296942,0.175054704595186,0.17543859649122806,0.17582417582417584,0.1762114537444934,0.17660044150110377,0.17699115044247787,0.17738359201773837,0.17777777777777778,0.17817371937639198,0.17857142857142858,0.1767337807606264,0.17713004484304934,0.17752808988764046,0.17792792792792791,0.17832957110609482,0.17873303167420815,0.17913832199546487,0.17954545454545454,0.17995444191343962,0.18036529680365296,0.18077803203661327,0.1811926605504587,0.18160919540229886,0.18202764976958524,0.18244803695150116,0.18287037037037038,0.18329466357308585,0.18372093023255814,0.18414918414918416,0.18457943925233644,0.18501170960187355,0.18588235294117647,0.18396226415094338,0.18439716312056736,0.1848341232227488,0.1828978622327791,0.18333333333333332,0.18377088305489261,0.18421052631578946,0.18465227817745802,0.18509615384615385,0.1855421686746988,0.1859903381642512,0.1864406779661017,0.18689320388349515,0.1873479318734793,0.1878048780487805,0.1882640586797066,0.18872549019607843,0.1891891891891892,0.18719211822660098,0.18765432098765433,0.18811881188118812,0.18858560794044665,0.1890547263681592,0.18952618453865336,0.19,0.19047619047619047,0.19095477386934673,0.19143576826196473,0.1919191919191919,0.19240506329113924,0.19289340101522842,0.19338422391857507,0.19387755102040816,0.19437340153452684,0.19487179487179487,0.1953727506426735,0.1958762886597938,0.19638242894056848,0.19689119170984457,0.1974025974025974,0.19791666666666666,0.19843342036553524,0.19895287958115182,0.2,0.20052770448548812,0.20105820105820105,0.20159151193633953,0.20212765957446807,0.20266666666666666,0.20320855614973263,0.2037533512064343,0.20430107526881722,0.20485175202156333,0.20540540540540542,0.20596205962059622,0.20652173913043478,0.20708446866485014,0.20765027322404372,0.20821917808219179,0.2087912087912088,0.209366391184573,0.20994475138121546,0.20833333333333334,0.20891364902506965,0.20949720670391062,0.21067415730337077,0.2112676056338028,0.211864406779661,0.21246458923512748,0.21306818181818182,0.21367521367521367,0.2148997134670487,0.21551724137931033,0.21613832853025935,0.21676300578034682,0.21739130434782608,0.2180232558139535,0.21865889212827988,0.21929824561403508,0.21994134897360704,0.22058823529411764,0.22123893805309736,0.22189349112426035,0.22255192878338279,0.22321428571428573,0.22388059701492538,0.2245508982035928,0.22522522522522523,0.22590361445783133,0.22658610271903323,0.22727272727272727,0.22796352583586627,0.22865853658536586,0.22935779816513763,0.23006134969325154,0.23076923076923078,0.23148148148148148,0.23219814241486067,0.2329192546583851,0.234375,0.23510971786833856,0.2358490566037736,0.23659305993690852,0.23734177215189872,0.23809523809523808,0.23885350318471338,0.23961661341853036,0.2403846153846154,0.24115755627009647,0.24193548387096775,0.24271844660194175,0.2435064935064935,0.24429967426710097,0.24509803921568626,0.2459016393442623,0.24671052631578946,0.24752475247524752,0.24834437086092714,0.25,0.2508361204013378,0.25252525252525254,0.2533783783783784,0.2542372881355932,0.25510204081632654,0.25597269624573377,0.2568493150684932,0.25773195876288657,0.25862068965517243,0.25951557093425603,0.2604166666666667,0.2613240418118467,0.26223776223776224,0.2631578947368421,0.2640845070422535,0.26501766784452296,0.26595744680851063,0.2669039145907473,0.26785714285714285,0.26881720430107525,0.2697841726618705,0.27075812274368233,0.2717391304347826,0.2727272727272727,0.2737226277372263,0.27472527472527475,0.2757352941176471,0.2767527675276753,0.2777777777777778,0.2788104089219331,0.2798507462686567,0.2808988764044944,0.2819548872180451,0.2830188679245283,0.2840909090909091,0.28517110266159695,0.2862595419847328,0.28735632183908044,0.2846153846153846,0.2857142857142857,0.2868217054263566,0.28793774319066145,0.2890625,0.2901960784313726,0.29133858267716534,0.2924901185770751,0.2896825396825397,0.2908366533864542,0.292,0.2891566265060241,0.2903225806451613,0.291497975708502,0.2926829268292683,0.2938775510204082,0.29508196721311475,0.2962962962962963,0.2975206611570248,0.2987551867219917,0.3,0.301255230125523,0.3025210084033613,0.3037974683544304,0.3050847457627119,0.30638297872340425,0.3076923076923077,0.3090128755364807,0.3103448275862069,0.3116883116883117,0.3130434782608696,0.314410480349345,0.3157894736842105,0.31718061674008813,0.3185840707964602,0.32,0.32142857142857145,0.32286995515695066,0.32432432432432434,0.3257918552036199,0.32727272727272727,0.3287671232876712,0.3302752293577982,0.3333333333333333,0.33488372093023255,0.3364485981308411,0.3380281690140845,0.33962264150943394,0.33649289099526064,0.3380952380952381,0.33653846153846156,0.33816425120772947,0.33980582524271846,0.34146341463414637,0.3431372549019608,0.3448275862068966,0.3465346534653465,0.34328358208955223,0.345,0.3417085427135678,0.3434343434343434,0.34517766497461927,0.3469387755102041,0.3487179487179487,0.34536082474226804,0.3471502590673575,0.3489583333333333,0.34554973821989526,0.3473684210526316,0.3492063492063492,0.35106382978723405,0.34759358288770054,0.34946236559139787,0.35135135135135137,0.3532608695652174,0.3551912568306011,0.35714285714285715,0.35911602209944754,0.3611111111111111,0.36312849162011174,0.3651685393258427,0.3672316384180791,0.3693181818181818,0.37142857142857144,0.3735632183908046,0.37572254335260113,0.37790697674418605,0.38011695906432746,0.38235294117647056,0.378698224852071,0.38095238095238093,0.3772455089820359,0.3795180722891566,0.38181818181818183,0.38414634146341464,0.38650306748466257,0.3888888888888889,0.391304347826087,0.39375,0.39622641509433965,0.3987341772151899,0.4012738853503185,0.40384615384615385,0.4064516129032258,0.4025974025974026,0.40522875816993464,0.40789473684210525,0.4105960264900662,0.41333333333333333,0.4161073825503356,0.4189189189189189,0.4217687074829932,0.4246575342465753,0.4206896551724138,0.4236111111111111,0.42657342657342656,0.4295774647887324,0.4326241134751773,0.4357142857142857,0.43884892086330934,0.43478260869565216,0.43795620437956206,0.4411764705882353,0.4444444444444444,0.44776119402985076,0.44360902255639095,0.44696969696969696,0.45038167938931295,0.45384615384615384,0.4573643410852713,0.4609375,0.4645669291338583,0.46825396825396826,0.472,0.47580645161290325,0.4796747967479675,0.48360655737704916,0.48760330578512395,0.49166666666666664,0.48739495798319327,0.4915254237288136,0.49572649572649574,0.5,0.5043478260869565,0.5087719298245614,0.5132743362831859,0.5178571428571429,0.5135135135135135,0.5181818181818182,0.5229357798165137,0.5277777777777778,0.5233644859813084,0.5283018867924528,0.5333333333333333,0.5384615384615384,0.5436893203883495,0.5490196078431373,0.5544554455445545,0.56,0.5656565656565656,0.5612244897959183,0.5670103092783505,0.5729166666666666,0.5789473684210527,0.574468085106383,0.5806451612903226,0.5869565217391305,0.5934065934065934,0.5888888888888889,0.5955056179775281,0.6022727272727273,0.6091954022988506,0.6162790697674418,0.611764705882353,0.6071428571428571,0.6144578313253012,0.6097560975609756,0.6172839506172839,0.625,0.6329113924050633,0.6410256410256411,0.6363636363636364,0.6447368421052632,0.6533333333333333,0.6621621621621622,0.6712328767123288,0.6666666666666666,0.6619718309859155,0.6571428571428571,0.6521739130434783,0.6617647058823529,0.6567164179104478,0.6666666666666666,0.6615384615384615,0.671875,0.6666666666666666,0.6774193548387096,0.6721311475409836,0.6833333333333333,0.6949152542372882,0.7068965517241379,0.7017543859649122,0.6964285714285714,0.7090909090909091,0.7222222222222222,0.7358490566037735,0.75,0.7647058823529411,0.76,0.7551020408163265,0.7708333333333334,0.7659574468085106,0.7608695652173914,0.7555555555555555,0.75,0.7441860465116279,0.7619047619047619,0.7804878048780488,0.775,0.7692307692307693,0.7631578947368421,0.7837837837837838,0.7777777777777778,0.8,0.7941176470588235,0.7878787878787878,0.8125,0.8064516129032258,0.8,0.8275862068965517,0.8571428571428571,0.8888888888888888,0.9230769230769231,0.92,0.9166666666666666,0.9130434782608695,0.9090909090909091,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,0.9375,0.9333333333333333,0.9285714285714286,0.9230769230769231,0.9166666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.5714)\"},\"height\":500,\"width\":700,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}]},                        {\"responsive\": true}                    )                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<html>\n<head><meta charset=\"utf-8\" /></head>\n<body>\n    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n        <script src=\"https://cdn.plot.ly/plotly-2.12.1.min.js\"></script>                <div id=\"7c033536-9a23-4b9c-9075-d069f1d83257\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7c033536-9a23-4b9c-9075-d069f1d83257\")) {                    Plotly.newPlot(                        \"7c033536-9a23-4b9c-9075-d069f1d83257\",                        [{\"fillpattern\":{\"shape\":\"\"},\"hovertemplate\":\"Recall=%{x}<br>Precision=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"stackgroup\":\"1\",\"x\":[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.98989898989899,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9797979797979798,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9696969696969697,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9595959595959596,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9494949494949495,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9393939393939394,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9292929292929293,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9191919191919192,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.9090909090909091,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.898989898989899,0.8888888888888888,0.8888888888888888,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8787878787878788,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8686868686868687,0.8585858585858586,0.8585858585858586,0.8585858585858586,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8484848484848485,0.8383838383838383,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8282828282828283,0.8181818181818182,0.8181818181818182,0.8181818181818182,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.8080808080808081,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.797979797979798,0.7878787878787878,0.7878787878787878,0.7878787878787878,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7777777777777778,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7676767676767676,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7575757575757576,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7474747474747475,0.7373737373737373,0.7373737373737373,0.7373737373737373,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7272727272727273,0.7171717171717171,0.7171717171717171,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.7070707070707071,0.696969696969697,0.696969696969697,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6868686868686869,0.6767676767676768,0.6767676767676768,0.6767676767676768,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6666666666666666,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6565656565656566,0.6464646464646465,0.6464646464646465,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6363636363636364,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6262626262626263,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6161616161616161,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.6060606060606061,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5959595959595959,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5858585858585859,0.5757575757575758,0.5757575757575758,0.5757575757575758,0.5757575757575758,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5656565656565656,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5555555555555556,0.5454545454545454,0.5454545454545454,0.5454545454545454,0.5454545454545454,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5353535353535354,0.5252525252525253,0.5151515151515151,0.5151515151515151,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.5050505050505051,0.494949494949495,0.494949494949495,0.494949494949495,0.494949494949495,0.494949494949495,0.48484848484848486,0.47474747474747475,0.46464646464646464,0.45454545454545453,0.45454545454545453,0.4444444444444444,0.4444444444444444,0.43434343434343436,0.43434343434343436,0.42424242424242425,0.42424242424242425,0.41414141414141414,0.41414141414141414,0.41414141414141414,0.41414141414141414,0.40404040404040403,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3939393939393939,0.3838383838383838,0.37373737373737376,0.37373737373737376,0.36363636363636365,0.35353535353535354,0.3434343434343434,0.3333333333333333,0.32323232323232326,0.32323232323232326,0.32323232323232326,0.31313131313131315,0.30303030303030304,0.29292929292929293,0.29292929292929293,0.2828282828282828,0.2828282828282828,0.2727272727272727,0.26262626262626265,0.26262626262626265,0.25252525252525254,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.24242424242424243,0.23232323232323232,0.2222222222222222,0.21212121212121213,0.20202020202020202,0.20202020202020202,0.1919191919191919,0.18181818181818182,0.1717171717171717,0.16161616161616163,0.15151515151515152,0.1414141414141414,0.13131313131313133,0.12121212121212122,0.1111111111111111,0.1111111111111111,0.10101010101010101,0.09090909090909091,0.08080808080808081,0.0707070707070707,0.06060606060606061,0.050505050505050504,0.04040404040404041,0.030303030303030304,0.020202020202020204,0.010101010101010102,0.0],\"xaxis\":\"x\",\"y\":[0.09546769527483125,0.09555984555984556,0.09565217391304348,0.09574468085106383,0.09583736689254599,0.09593023255813954,0.09602327837051407,0.09611650485436893,0.09620991253644315,0.0963035019455253,0.09639727361246349,0.09649122807017543,0.09658536585365854,0.0966796875,0.0967741935483871,0.09686888454011741,0.0969637610186092,0.09705882352941177,0.0971540726202159,0.09724950884086445,0.09734513274336283,0.09744094488188976,0.09753694581280788,0.09763313609467456,0.09772951628825272,0.09782608695652174,0.09792284866468842,0.0981169474727453,0.09722222222222222,0.09731876861966236,0.09741550695825049,0.09751243781094528,0.09760956175298804,0.09770687936191426,0.09780439121756487,0.0980980980980981,0.09819639278557114,0.09829488465396188,0.09839357429718876,0.09748743718592964,0.09758551307847083,0.09768378650553877,0.09778225806451613,0.09797979797979799,0.0980788675429727,0.09817813765182186,0.09827760891590678,0.09847715736040609,0.09857723577235772,0.09877800407331976,0.09887869520897044,0.09897959183673469,0.09908069458631256,0.0992835209825998,0.09938524590163934,0.09948717948717949,0.09958932238193019,0.09969167523124357,0.09979423868312758,0.09989701338825953,0.1,0.1001031991744066,0.10020661157024793,0.10031023784901758,0.10062240663900415,0.10083160083160084,0.10093652445369407,0.10104166666666667,0.10114702815432743,0.10125260960334029,0.1013584117032393,0.10146443514644352,0.10157068062827225,0.10167714884696016,0.10178384050367262,0.10189075630252101,0.10199789695057834,0.10210526315789474,0.10221285563751317,0.10232067510548523,0.10242872228088701,0.10253699788583509,0.10264550264550265,0.1027542372881356,0.10286320254506894,0.1029723991507431,0.1030818278427205,0.10319148936170212,0.1033013844515442,0.10352187833511206,0.10363247863247864,0.10374331550802139,0.10385438972162742,0.10396570203644159,0.10407725321888411,0.1041890440386681,0.1043010752688172,0.10441334768568353,0.10452586206896551,0.104638619201726,0.10475161987041037,0.10486486486486486,0.1052060737527115,0.10532030401737243,0.10543478260869565,0.10554951033732318,0.1056644880174292,0.10589519650655022,0.10601092896174863,0.1061269146608315,0.10624315443592552,0.10635964912280702,0.10537870472008781,0.1054945054945055,0.10561056105610561,0.10572687224669604,0.10584343991179714,0.10596026490066225,0.10607734806629834,0.10619469026548672,0.10643015521064302,0.10543840177580466,0.10555555555555556,0.10567296996662959,0.10590858416945373,0.10602678571428571,0.10614525139664804,0.10638297872340426,0.10650224215246637,0.10674157303370786,0.10686164229471316,0.10698198198198199,0.10710259301014656,0.1072234762979684,0.10734463276836158,0.1074660633484163,0.10758776896942242,0.10770975056689343,0.10783200908059024,0.10795454545454546,0.1080773606370876,0.1082004555808656,0.10832383124287344,0.10844748858447488,0.10869565217391304,0.10894495412844037,0.10907003444316878,0.10919540229885058,0.1093210586881473,0.10944700460829493,0.10969976905311778,0.10982658959537572,0.1099537037037037,0.11033681765389082,0.11046511627906977,0.11059371362048893,0.11072261072261072,0.11085180863477247,0.11098130841121495,0.1111111111111111,0.11137162954279015,0.11150234741784038,0.11163337250293771,0.11176470588235295,0.11189634864546526,0.11216056670602124,0.11229314420803782,0.11242603550295859,0.11255924170616113,0.11269276393831554,0.11282660332541568,0.11296076099881094,0.11323003575685339,0.11336515513126491,0.1135005973715651,0.11363636363636363,0.11377245508982035,0.11390887290167866,0.1141826923076923,0.11432009626955475,0.1144578313253012,0.11459589867310012,0.11473429951690821,0.11487303506650544,0.11501210653753027,0.11515151515151516,0.11543134872417983,0.11557177615571776,0.11571254567600488,0.11585365853658537,0.115995115995116,0.11613691931540342,0.11627906976744186,0.11642156862745098,0.1165644171779141,0.1167076167076167,0.11685116851168512,0.11699507389162561,0.11713933415536375,0.11728395061728394,0.11742892459826947,0.11757425742574257,0.11771995043370508,0.11786600496277916,0.11801242236024845,0.1181592039800995,0.11830635118306351,0.11845386533665836,0.11860174781523096,0.11875,0.11889862327909888,0.11904761904761904,0.1191969887076537,0.11934673366834171,0.11949685534591195,0.11964735516372796,0.11979823455233292,0.11994949494949494,0.12010113780025285,0.12025316455696203,0.12040557667934093,0.12055837563451777,0.1207115628970775,0.12086513994910941,0.12101910828025478,0.1211734693877551,0.12132822477650064,0.12148337595907928,0.12163892445582586,0.12179487179487179,0.12195121951219512,0.12210796915167095,0.12226512226512226,0.12242268041237113,0.12258064516129032,0.1227390180878553,0.12289780077619664,0.12305699481865284,0.12337662337662338,0.12369791666666667,0.12385919165580182,0.12418300653594772,0.1243455497382199,0.12450851900393185,0.12483574244415244,0.125,0.1251646903820817,0.12532981530343007,0.12549537648612946,0.12566137566137567,0.12582781456953643,0.1259946949602122,0.12616201859229748,0.12632978723404256,0.12649800266311584,0.12666666666666668,0.1268357810413885,0.1270053475935829,0.12717536813922356,0.12734584450402145,0.12751677852348994,0.12768817204301075,0.1278600269179004,0.1280323450134771,0.1282051282051282,0.12837837837837837,0.12855209742895804,0.12872628726287264,0.12890094979647218,0.12907608695652173,0.1292517006802721,0.12942779291553133,0.1296043656207367,0.12978142076502733,0.12995896032831739,0.13013698630136986,0.13031550068587106,0.1304945054945055,0.13085399449035812,0.1310344827586207,0.13121546961325967,0.13157894736842105,0.1317614424410541,0.13194444444444445,0.13212795549374132,0.13249651324965134,0.13268156424581007,0.13286713286713286,0.1330532212885154,0.13342696629213482,0.13361462728551335,0.13380281690140844,0.13399153737658676,0.134180790960452,0.13437057991513437,0.13456090651558072,0.1347517730496454,0.13513513513513514,0.1339031339031339,0.1340941512125535,0.13428571428571429,0.13447782546494993,0.1346704871060172,0.13486370157819225,0.13505747126436782,0.13525179856115108,0.13544668587896252,0.13564213564213565,0.13583815028901733,0.13603473227206947,0.13623188405797101,0.13642960812772134,0.13662790697674418,0.13722627737226278,0.1376281112737921,0.1378299120234604,0.13803230543318648,0.13676470588235295,0.13696612665684832,0.13716814159292035,0.13737075332348597,0.13757396449704143,0.13777777777777778,0.13798219584569732,0.13839285714285715,0.13859910581222057,0.13901345291479822,0.13922155688622753,0.13963963963963963,0.13984962406015036,0.14006024096385541,0.14027149321266968,0.1404833836858006,0.14069591527987896,0.1409090909090909,0.1398176291793313,0.1400304414003044,0.1402439024390244,0.14067278287461774,0.14088820826952528,0.1411042944785276,0.14153846153846153,0.14175654853620956,0.1419753086419753,0.14219474497681608,0.14241486068111456,0.14285714285714285,0.14307931570762053,0.14330218068535824,0.1435257410296412,0.1421875,0.14241001564945227,0.1426332288401254,0.14285714285714285,0.1430817610062893,0.14330708661417324,0.14353312302839116,0.14375987361769352,0.14240506329113925,0.14263074484944532,0.14285714285714285,0.14308426073131955,0.14331210191082802,0.14217252396166133,0.1424,0.14262820512820512,0.14285714285714285,0.14308681672025725,0.143317230273752,0.14378029079159935,0.14401294498381878,0.14424635332252836,0.1444805194805195,0.14471544715447154,0.1449511400651466,0.14518760195758565,0.1454248366013072,0.14566284779050737,0.14614121510673234,0.14638157894736842,0.14662273476112025,0.14686468646864687,0.14710743801652892,0.14735099337748345,0.14759535655058043,0.1478405315614618,0.1480865224625624,0.14833333333333334,0.14858096828046743,0.1488294314381271,0.1490787269681742,0.1495798319327731,0.15008431703204048,0.1505922165820643,0.15110356536502548,0.15136054421768708,0.15187713310580206,0.15213675213675212,0.1523972602739726,0.15265866209262435,0.15292096219931273,0.153184165232358,0.15344827586206897,0.153713298791019,0.1545138888888889,0.15478260869565216,0.15532286212914484,0.1555944055944056,0.15586690017513136,0.156140350877193,0.15641476274165203,0.15669014084507044,0.15696649029982362,0.15724381625441697,0.15752212389380532,0.15780141843971632,0.15808170515097691,0.1583629893238434,0.1586452762923351,0.15892857142857142,0.1592128801431127,0.15949820788530467,0.15978456014362658,0.16007194244604317,0.16036036036036036,0.1588447653429603,0.15942028985507245,0.15789473684210525,0.15818181818181817,0.15846994535519127,0.1590493601462523,0.15934065934065933,0.15867158671586715,0.1589648798521257,0.15955473098330242,0.1601489757914339,0.16074766355140188,0.16104868913857678,0.16135084427767354,0.16195856873822975,0.16257088846880907,0.16098484848484848,0.16129032258064516,0.16159695817490494,0.16,0.16030534351145037,0.16061185468451242,0.16184971098265896,0.16216216216216217,0.16247582205029013,0.16279069767441862,0.1614785992217899,0.15984405458089668,0.16015625,0.16046966731898238,0.1607843137254902,0.16205533596837945,0.16237623762376238,0.1626984126984127,0.16334661354581673,0.16367265469061876,0.164,0.16432865731462926,0.1646586345381526,0.16498993963782696,0.16565656565656567,0.1659919028340081,0.1670061099796334,0.1673469387755102,0.16768916155419222,0.1680327868852459,0.16872427983539096,0.16942148760330578,0.16977225672877846,0.17012448132780084,0.1704781704781705,0.17083333333333334,0.17154811715481172,0.1719077568134172,0.1722689075630252,0.1729957805907173,0.17124735729386892,0.1716101694915254,0.17197452229299362,0.1702127659574468,0.17057569296375266,0.17094017094017094,0.17130620985010706,0.17167381974248927,0.17204301075268819,0.1724137931034483,0.17278617710583152,0.17316017316017315,0.1735357917570499,0.17391304347826086,0.17429193899782136,0.17467248908296942,0.175054704595186,0.17543859649122806,0.17582417582417584,0.1762114537444934,0.17660044150110377,0.17699115044247787,0.17738359201773837,0.17777777777777778,0.17817371937639198,0.17857142857142858,0.1767337807606264,0.17713004484304934,0.17752808988764046,0.17792792792792791,0.17832957110609482,0.17873303167420815,0.17913832199546487,0.17954545454545454,0.17995444191343962,0.18036529680365296,0.18077803203661327,0.1811926605504587,0.18160919540229886,0.18202764976958524,0.18244803695150116,0.18287037037037038,0.18329466357308585,0.18372093023255814,0.18414918414918416,0.18457943925233644,0.18501170960187355,0.18588235294117647,0.18396226415094338,0.18439716312056736,0.1848341232227488,0.1828978622327791,0.18333333333333332,0.18377088305489261,0.18421052631578946,0.18465227817745802,0.18509615384615385,0.1855421686746988,0.1859903381642512,0.1864406779661017,0.18689320388349515,0.1873479318734793,0.1878048780487805,0.1882640586797066,0.18872549019607843,0.1891891891891892,0.18719211822660098,0.18765432098765433,0.18811881188118812,0.18858560794044665,0.1890547263681592,0.18952618453865336,0.19,0.19047619047619047,0.19095477386934673,0.19143576826196473,0.1919191919191919,0.19240506329113924,0.19289340101522842,0.19338422391857507,0.19387755102040816,0.19437340153452684,0.19487179487179487,0.1953727506426735,0.1958762886597938,0.19638242894056848,0.19689119170984457,0.1974025974025974,0.19791666666666666,0.19843342036553524,0.19895287958115182,0.2,0.20052770448548812,0.20105820105820105,0.20159151193633953,0.20212765957446807,0.20266666666666666,0.20320855614973263,0.2037533512064343,0.20430107526881722,0.20485175202156333,0.20540540540540542,0.20596205962059622,0.20652173913043478,0.20708446866485014,0.20765027322404372,0.20821917808219179,0.2087912087912088,0.209366391184573,0.20994475138121546,0.20833333333333334,0.20891364902506965,0.20949720670391062,0.21067415730337077,0.2112676056338028,0.211864406779661,0.21246458923512748,0.21306818181818182,0.21367521367521367,0.2148997134670487,0.21551724137931033,0.21613832853025935,0.21676300578034682,0.21739130434782608,0.2180232558139535,0.21865889212827988,0.21929824561403508,0.21994134897360704,0.22058823529411764,0.22123893805309736,0.22189349112426035,0.22255192878338279,0.22321428571428573,0.22388059701492538,0.2245508982035928,0.22522522522522523,0.22590361445783133,0.22658610271903323,0.22727272727272727,0.22796352583586627,0.22865853658536586,0.22935779816513763,0.23006134969325154,0.23076923076923078,0.23148148148148148,0.23219814241486067,0.2329192546583851,0.234375,0.23510971786833856,0.2358490566037736,0.23659305993690852,0.23734177215189872,0.23809523809523808,0.23885350318471338,0.23961661341853036,0.2403846153846154,0.24115755627009647,0.24193548387096775,0.24271844660194175,0.2435064935064935,0.24429967426710097,0.24509803921568626,0.2459016393442623,0.24671052631578946,0.24752475247524752,0.24834437086092714,0.25,0.2508361204013378,0.25252525252525254,0.2533783783783784,0.2542372881355932,0.25510204081632654,0.25597269624573377,0.2568493150684932,0.25773195876288657,0.25862068965517243,0.25951557093425603,0.2604166666666667,0.2613240418118467,0.26223776223776224,0.2631578947368421,0.2640845070422535,0.26501766784452296,0.26595744680851063,0.2669039145907473,0.26785714285714285,0.26881720430107525,0.2697841726618705,0.27075812274368233,0.2717391304347826,0.2727272727272727,0.2737226277372263,0.27472527472527475,0.2757352941176471,0.2767527675276753,0.2777777777777778,0.2788104089219331,0.2798507462686567,0.2808988764044944,0.2819548872180451,0.2830188679245283,0.2840909090909091,0.28517110266159695,0.2862595419847328,0.28735632183908044,0.2846153846153846,0.2857142857142857,0.2868217054263566,0.28793774319066145,0.2890625,0.2901960784313726,0.29133858267716534,0.2924901185770751,0.2896825396825397,0.2908366533864542,0.292,0.2891566265060241,0.2903225806451613,0.291497975708502,0.2926829268292683,0.2938775510204082,0.29508196721311475,0.2962962962962963,0.2975206611570248,0.2987551867219917,0.3,0.301255230125523,0.3025210084033613,0.3037974683544304,0.3050847457627119,0.30638297872340425,0.3076923076923077,0.3090128755364807,0.3103448275862069,0.3116883116883117,0.3130434782608696,0.314410480349345,0.3157894736842105,0.31718061674008813,0.3185840707964602,0.32,0.32142857142857145,0.32286995515695066,0.32432432432432434,0.3257918552036199,0.32727272727272727,0.3287671232876712,0.3302752293577982,0.3333333333333333,0.33488372093023255,0.3364485981308411,0.3380281690140845,0.33962264150943394,0.33649289099526064,0.3380952380952381,0.33653846153846156,0.33816425120772947,0.33980582524271846,0.34146341463414637,0.3431372549019608,0.3448275862068966,0.3465346534653465,0.34328358208955223,0.345,0.3417085427135678,0.3434343434343434,0.34517766497461927,0.3469387755102041,0.3487179487179487,0.34536082474226804,0.3471502590673575,0.3489583333333333,0.34554973821989526,0.3473684210526316,0.3492063492063492,0.35106382978723405,0.34759358288770054,0.34946236559139787,0.35135135135135137,0.3532608695652174,0.3551912568306011,0.35714285714285715,0.35911602209944754,0.3611111111111111,0.36312849162011174,0.3651685393258427,0.3672316384180791,0.3693181818181818,0.37142857142857144,0.3735632183908046,0.37572254335260113,0.37790697674418605,0.38011695906432746,0.38235294117647056,0.378698224852071,0.38095238095238093,0.3772455089820359,0.3795180722891566,0.38181818181818183,0.38414634146341464,0.38650306748466257,0.3888888888888889,0.391304347826087,0.39375,0.39622641509433965,0.3987341772151899,0.4012738853503185,0.40384615384615385,0.4064516129032258,0.4025974025974026,0.40522875816993464,0.40789473684210525,0.4105960264900662,0.41333333333333333,0.4161073825503356,0.4189189189189189,0.4217687074829932,0.4246575342465753,0.4206896551724138,0.4236111111111111,0.42657342657342656,0.4295774647887324,0.4326241134751773,0.4357142857142857,0.43884892086330934,0.43478260869565216,0.43795620437956206,0.4411764705882353,0.4444444444444444,0.44776119402985076,0.44360902255639095,0.44696969696969696,0.45038167938931295,0.45384615384615384,0.4573643410852713,0.4609375,0.4645669291338583,0.46825396825396826,0.472,0.47580645161290325,0.4796747967479675,0.48360655737704916,0.48760330578512395,0.49166666666666664,0.48739495798319327,0.4915254237288136,0.49572649572649574,0.5,0.5043478260869565,0.5087719298245614,0.5132743362831859,0.5178571428571429,0.5135135135135135,0.5181818181818182,0.5229357798165137,0.5277777777777778,0.5233644859813084,0.5283018867924528,0.5333333333333333,0.5384615384615384,0.5436893203883495,0.5490196078431373,0.5544554455445545,0.56,0.5656565656565656,0.5612244897959183,0.5670103092783505,0.5729166666666666,0.5789473684210527,0.574468085106383,0.5806451612903226,0.5869565217391305,0.5934065934065934,0.5888888888888889,0.5955056179775281,0.6022727272727273,0.6091954022988506,0.6162790697674418,0.611764705882353,0.6071428571428571,0.6144578313253012,0.6097560975609756,0.6172839506172839,0.625,0.6329113924050633,0.6410256410256411,0.6363636363636364,0.6447368421052632,0.6533333333333333,0.6621621621621622,0.6712328767123288,0.6666666666666666,0.6619718309859155,0.6571428571428571,0.6521739130434783,0.6617647058823529,0.6567164179104478,0.6666666666666666,0.6615384615384615,0.671875,0.6666666666666666,0.6774193548387096,0.6721311475409836,0.6833333333333333,0.6949152542372882,0.7068965517241379,0.7017543859649122,0.6964285714285714,0.7090909090909091,0.7222222222222222,0.7358490566037735,0.75,0.7647058823529411,0.76,0.7551020408163265,0.7708333333333334,0.7659574468085106,0.7608695652173914,0.7555555555555555,0.75,0.7441860465116279,0.7619047619047619,0.7804878048780488,0.775,0.7692307692307693,0.7631578947368421,0.7837837837837838,0.7777777777777778,0.8,0.7941176470588235,0.7878787878787878,0.8125,0.8064516129032258,0.8,0.8275862068965517,0.8571428571428571,0.8888888888888888,0.9230769230769231,0.92,0.9166666666666666,0.9130434782608695,0.9090909090909091,0.9523809523809523,0.95,0.9473684210526315,0.9444444444444444,0.9411764705882353,0.9375,0.9333333333333333,0.9285714285714286,0.9230769230769231,0.9166666666666666,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Recall\"},\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Precision\"},\"scaleanchor\":\"x\",\"scaleratio\":1},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Precision-Recall Curve (AUC=0.5714)\"},\"height\":500,\"width\":700,\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}]},                        {\"responsive\": true}                    )                };                            </script>        </div>\n</body>\n</html>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(y_test_c, probs)\n",
    "\n",
    "fig = px.area(\n",
    "    x=recall, y=precision,\n",
    "    title=f'Precision-Recall Curve (AUC={auc(recall, precision):.4f})',\n",
    "    labels=dict(x='Recall', y='Precision'),\n",
    "    width=700, height=500\n",
    ")\n",
    "fig.add_shape(\n",
    "    type='line', line=dict(dash='dash'),\n",
    "    x0=0, x1=1, y0=1, y1=0\n",
    ")\n",
    "fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "fig.update_xaxes(constrain='domain')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf5f3d9-4ba4-4d82-8756-21bc278ced39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We conclude the testing phase by updating our running comparison of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d869d238-c888-41bb-b6ee-c7665c0aee1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>PR AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.695275</td>\n",
       "      <td>0.205962</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.571415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Method</th>\n      <th>Accuracy</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>PR AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logistic</td>\n      <td>0.695275</td>\n      <td>0.205962</td>\n      <td>0.767677</td>\n      <td>0.571415</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Final_Metrics = pd.DataFrame({'Method':['Logistic'],'Accuracy':[acc_lrs],'Precision':[prec_lrs],'Recall':[sens_lrs],'PR AUC':[auc(recall, precision)]})\n",
    "Final_Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83564ac4-3081-4196-a98e-e8c469c8db2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "These metrics may be utilized to evaluate the quality of the model in two primary ways\n",
    "\n",
    "  1. As performance metrics we can compare with those from other models to make a final choice on which to deploy.\n",
    "\n",
    "  Multiple logistic regression will be the yardstick we use to measure other models.\n",
    "  \n",
    "  2. By comparing test set metric values with those from the training set, close values indicate the ability of our model to generalize.\n",
    "\n",
    "  Test metrics are only slightly worse than training metrics, indicating both models are useful for generalizing to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "037b5efc-d3cf-4a1a-930f-d35adbabee66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#VIDEO 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a09d8d7-97d0-4b86-a10f-cdd1f122d7d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Deploying the Data for Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc56cb79-5a8a-4844-b7b8-5444567ae028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Predicting Outcomes for new Cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f179a7d6-e108-48b9-81f4-4167a09fba47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With the trained, tested and validated model in hand, Shontelle is ready to utilize it to glean insights concerning a random sample of students who have shown various signs of struggling in their university experience. She then downloads a spreadsheet entitled **classif_data.csv**. Let's take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "566359c8-92b8-4ad8-8201-4af1d751cf6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SID</th>\n",
       "      <th>ENROLLMENT_YEAR</th>\n",
       "      <th>ENROLLMENT_TERM</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>FIRST_SEM_W</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>DFW_UNITS_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>CUM_GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>DFW_UNITS_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>CUM_GPA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>000GPJ93V</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.970239</td>\n",
       "      <td>3.205086</td>\n",
       "      <td>3.152426</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.125</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bethany</td>\n",
       "      <td>000M7YLAX</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.702649</td>\n",
       "      <td>3.119864</td>\n",
       "      <td>3.191927</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Marisol</td>\n",
       "      <td>000NSOJN5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.751494</td>\n",
       "      <td>3.044736</td>\n",
       "      <td>2.935482</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kent</td>\n",
       "      <td>000O3VNKL</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.282063</td>\n",
       "      <td>3.466105</td>\n",
       "      <td>3.823987</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tasha</td>\n",
       "      <td>000VJZY7Q</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.890517</td>\n",
       "      <td>3.794312</td>\n",
       "      <td>3.512793</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.800</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Peggy</td>\n",
       "      <td>000ABCDE1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.972042</td>\n",
       "      <td>3.093119</td>\n",
       "      <td>3.920177</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Fred</td>\n",
       "      <td>000ABCDE2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.502444</td>\n",
       "      <td>3.431067</td>\n",
       "      <td>3.193452</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Alex</td>\n",
       "      <td>000ABCDE3</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.938181</td>\n",
       "      <td>3.583889</td>\n",
       "      <td>3.971437</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>000ABCDE4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.525838</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>3.168331</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ana</td>\n",
       "      <td>000ABCDE5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.639249</td>\n",
       "      <td>3.097655</td>\n",
       "      <td>3.906897</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.750</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>NAME</th>\n      <th>SID</th>\n      <th>ENROLLMENT_YEAR</th>\n      <th>ENROLLMENT_TERM</th>\n      <th>COHORT</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>FIRST_SEM_W</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>DFW_UNITS_1</th>\n      <th>GPA_1</th>\n      <th>CUM_GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>DFW_UNITS_2</th>\n      <th>GPA_2</th>\n      <th>CUM_GPA_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jaime</td>\n      <td>000GPJ93V</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.970239</td>\n      <td>3.205086</td>\n      <td>3.152426</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>3.125</td>\n      <td>3.125</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.90</td>\n      <td>3.050</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Bethany</td>\n      <td>000M7YLAX</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.702649</td>\n      <td>3.119864</td>\n      <td>3.191927</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>12</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2.250</td>\n      <td>2.250</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0</td>\n      <td>2.25</td>\n      <td>2.250</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Marisol</td>\n      <td>000NSOJN5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.751494</td>\n      <td>3.044736</td>\n      <td>2.935482</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1.500</td>\n      <td>1.500</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>1.20</td>\n      <td>1.300</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Kent</td>\n      <td>000O3VNKL</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.282063</td>\n      <td>3.466105</td>\n      <td>3.823987</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>15</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2.000</td>\n      <td>2.000</td>\n      <td>12</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2.00</td>\n      <td>2.000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Tasha</td>\n      <td>000VJZY7Q</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.890517</td>\n      <td>3.794312</td>\n      <td>3.512793</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0</td>\n      <td>3.800</td>\n      <td>3.800</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0</td>\n      <td>3.00</td>\n      <td>3.400</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Peggy</td>\n      <td>000ABCDE1</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.972042</td>\n      <td>3.093119</td>\n      <td>3.920177</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2</td>\n      <td>3.100</td>\n      <td>3.100</td>\n      <td>16</td>\n      <td>15</td>\n      <td>1</td>\n      <td>3.75</td>\n      <td>3.500</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Fred</td>\n      <td>000ABCDE2</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.502444</td>\n      <td>3.431067</td>\n      <td>3.193452</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>15</td>\n      <td>12</td>\n      <td>3</td>\n      <td>2.400</td>\n      <td>2.400</td>\n      <td>14</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.20</td>\n      <td>2.308</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Alex</td>\n      <td>000ABCDE3</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.938181</td>\n      <td>3.583889</td>\n      <td>3.971437</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>14</td>\n      <td>3</td>\n      <td>11</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>15</td>\n      <td>6</td>\n      <td>9</td>\n      <td>2.08</td>\n      <td>1.840</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Kelly</td>\n      <td>000ABCDE4</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.525838</td>\n      <td>3.678231</td>\n      <td>3.168331</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>13</td>\n      <td>12</td>\n      <td>1</td>\n      <td>3.000</td>\n      <td>3.000</td>\n      <td>13</td>\n      <td>11</td>\n      <td>2</td>\n      <td>2.70</td>\n      <td>2.890</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Ana</td>\n      <td>000ABCDE5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.639249</td>\n      <td>3.097655</td>\n      <td>3.906897</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.750</td>\n      <td>2.750</td>\n      <td>13</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1.30</td>\n      <td>1.875</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "esam = pd.read_csv('/dbfs/FileStore/ml-file-store/bronze/classif_data')\n",
    "esam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2845f344-a5f9-4265-bf7c-914b2c6789b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Shontelle is happy with the sample, as a quick glance indicates ethnic and academic diversity, a reflection of her university. She notices that the data indicates that Marisol, Alex and Ana are currently in academc warning due to their CUM_GPA_2 being less than 2.0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e35a9db-e6dd-410a-a91b-910cd7095691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[90]: 2    Marisol\n7       Alex\n9        Ana\nName: NAME, dtype: object"
     ]
    }
   ],
   "source": [
    "esam['NAME'][esam['CUM_GPA_2']<2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24816273-d01e-417a-9969-24a468f744b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "As academic disqualification is not completely determined until the end of term 3, she aims to use our validated model to predict status at the beginning of semester 3.\n",
    "\n",
    "Based on our approach above she realizes she has some feature engineering to do, and so she then calculates DFW rates and grade points for each term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db149e6c-0f9b-4382-ba16-03196de96d2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SID</th>\n",
       "      <th>ENROLLMENT_YEAR</th>\n",
       "      <th>ENROLLMENT_TERM</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>FIRST_SEM_W</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>DFW_UNITS_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>CUM_GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>DFW_UNITS_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>CUM_GPA_2</th>\n",
       "      <th>DFW_RATE_1</th>\n",
       "      <th>DFW_RATE_2</th>\n",
       "      <th>GRADE_POINTS_1</th>\n",
       "      <th>GRADE_POINTS_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>000GPJ93V</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.970239</td>\n",
       "      <td>3.205086</td>\n",
       "      <td>3.152426</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.125</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bethany</td>\n",
       "      <td>000M7YLAX</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.702649</td>\n",
       "      <td>3.119864</td>\n",
       "      <td>3.191927</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Marisol</td>\n",
       "      <td>000NSOJN5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.751494</td>\n",
       "      <td>3.044736</td>\n",
       "      <td>2.935482</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kent</td>\n",
       "      <td>000O3VNKL</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.282063</td>\n",
       "      <td>3.466105</td>\n",
       "      <td>3.823987</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tasha</td>\n",
       "      <td>000VJZY7Q</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.890517</td>\n",
       "      <td>3.794312</td>\n",
       "      <td>3.512793</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.800</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.8</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Peggy</td>\n",
       "      <td>000ABCDE1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.972042</td>\n",
       "      <td>3.093119</td>\n",
       "      <td>3.920177</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>43.4</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Fred</td>\n",
       "      <td>000ABCDE2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.502444</td>\n",
       "      <td>3.431067</td>\n",
       "      <td>3.193452</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.308</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Alex</td>\n",
       "      <td>000ABCDE3</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.938181</td>\n",
       "      <td>3.583889</td>\n",
       "      <td>3.971437</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.840</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>000ABCDE4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.525838</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>3.168331</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.890</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ana</td>\n",
       "      <td>000ABCDE5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.639249</td>\n",
       "      <td>3.097655</td>\n",
       "      <td>3.906897</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.750</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.875</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>NAME</th>\n      <th>SID</th>\n      <th>ENROLLMENT_YEAR</th>\n      <th>ENROLLMENT_TERM</th>\n      <th>COHORT</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>FIRST_SEM_W</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>DFW_UNITS_1</th>\n      <th>GPA_1</th>\n      <th>CUM_GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>DFW_UNITS_2</th>\n      <th>GPA_2</th>\n      <th>CUM_GPA_2</th>\n      <th>DFW_RATE_1</th>\n      <th>DFW_RATE_2</th>\n      <th>GRADE_POINTS_1</th>\n      <th>GRADE_POINTS_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jaime</td>\n      <td>000GPJ93V</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.970239</td>\n      <td>3.205086</td>\n      <td>3.152426</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>3.125</td>\n      <td>3.125</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.90</td>\n      <td>3.050</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>25.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Bethany</td>\n      <td>000M7YLAX</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.702649</td>\n      <td>3.119864</td>\n      <td>3.191927</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>12</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2.250</td>\n      <td>2.250</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0</td>\n      <td>2.25</td>\n      <td>2.250</td>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>27.0</td>\n      <td>27.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Marisol</td>\n      <td>000NSOJN5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.751494</td>\n      <td>3.044736</td>\n      <td>2.935482</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1.500</td>\n      <td>1.500</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>1.20</td>\n      <td>1.300</td>\n      <td>0.666667</td>\n      <td>0.800000</td>\n      <td>13.5</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Kent</td>\n      <td>000O3VNKL</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.282063</td>\n      <td>3.466105</td>\n      <td>3.823987</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>15</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2.000</td>\n      <td>2.000</td>\n      <td>12</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2.00</td>\n      <td>2.000</td>\n      <td>0.266667</td>\n      <td>0.500000</td>\n      <td>30.0</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Tasha</td>\n      <td>000VJZY7Q</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.890517</td>\n      <td>3.794312</td>\n      <td>3.512793</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0</td>\n      <td>3.800</td>\n      <td>3.800</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0</td>\n      <td>3.00</td>\n      <td>3.400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>60.8</td>\n      <td>51.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Peggy</td>\n      <td>000ABCDE1</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.972042</td>\n      <td>3.093119</td>\n      <td>3.920177</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2</td>\n      <td>3.100</td>\n      <td>3.100</td>\n      <td>16</td>\n      <td>15</td>\n      <td>1</td>\n      <td>3.75</td>\n      <td>3.500</td>\n      <td>0.142857</td>\n      <td>0.062500</td>\n      <td>43.4</td>\n      <td>60.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Fred</td>\n      <td>000ABCDE2</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.502444</td>\n      <td>3.431067</td>\n      <td>3.193452</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>15</td>\n      <td>12</td>\n      <td>3</td>\n      <td>2.400</td>\n      <td>2.400</td>\n      <td>14</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.20</td>\n      <td>2.308</td>\n      <td>0.200000</td>\n      <td>0.214286</td>\n      <td>36.0</td>\n      <td>30.8</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Alex</td>\n      <td>000ABCDE3</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.938181</td>\n      <td>3.583889</td>\n      <td>3.971437</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>14</td>\n      <td>3</td>\n      <td>11</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>15</td>\n      <td>6</td>\n      <td>9</td>\n      <td>2.08</td>\n      <td>1.840</td>\n      <td>0.785714</td>\n      <td>0.600000</td>\n      <td>14.0</td>\n      <td>31.2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Kelly</td>\n      <td>000ABCDE4</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.525838</td>\n      <td>3.678231</td>\n      <td>3.168331</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>13</td>\n      <td>12</td>\n      <td>1</td>\n      <td>3.000</td>\n      <td>3.000</td>\n      <td>13</td>\n      <td>11</td>\n      <td>2</td>\n      <td>2.70</td>\n      <td>2.890</td>\n      <td>0.076923</td>\n      <td>0.153846</td>\n      <td>39.0</td>\n      <td>35.1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Ana</td>\n      <td>000ABCDE5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.639249</td>\n      <td>3.097655</td>\n      <td>3.906897</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.750</td>\n      <td>2.750</td>\n      <td>13</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1.30</td>\n      <td>1.875</td>\n      <td>0.300000</td>\n      <td>0.692308</td>\n      <td>27.5</td>\n      <td>16.9</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Initialize the new dataframe\n",
    "esam1 = esam.copy()\n",
    "\n",
    "\n",
    "esam1['DFW_RATE_1'] = (esam1['UNITS_ATTEMPTED_1']-esam1['UNITS_COMPLETED_1'])/esam1['UNITS_ATTEMPTED_1']\n",
    "\n",
    "#DFW Rate Term 2\n",
    "esam1['DFW_RATE_2'] = (esam1['UNITS_ATTEMPTED_2']-esam1['UNITS_COMPLETED_2'])/esam1['UNITS_ATTEMPTED_2']\n",
    "\n",
    "#Grade points Term 1\n",
    "esam1['GRADE_POINTS_1'] = esam1['UNITS_ATTEMPTED_1']*esam1['GPA_1']\n",
    "\n",
    "#Grade points Term 2\n",
    "esam1['GRADE_POINTS_2'] = esam1['UNITS_ATTEMPTED_2']*esam1['GPA_2']\n",
    "\n",
    "esam1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7721685-507c-423c-a788-e6400e241543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To prepare her dataframe for the pipelines used in this notebook, she removes variables not included in the modeling process, and verifies that they match our work above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12001f4c-2438-448a-bf3b-b12dfc84eab6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>DFW_RATE_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>DFW_RATE_2</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.152426</td>\n",
       "      <td>3.205086</td>\n",
       "      <td>3.125</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.191927</td>\n",
       "      <td>3.119864</td>\n",
       "      <td>2.250</td>\n",
       "      <td>12</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>12</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.935482</td>\n",
       "      <td>3.044736</td>\n",
       "      <td>1.500</td>\n",
       "      <td>9</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.823987</td>\n",
       "      <td>3.466105</td>\n",
       "      <td>2.000</td>\n",
       "      <td>15</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>12</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.512793</td>\n",
       "      <td>3.794312</td>\n",
       "      <td>3.800</td>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.920177</td>\n",
       "      <td>3.093119</td>\n",
       "      <td>3.100</td>\n",
       "      <td>14</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>16</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.193452</td>\n",
       "      <td>3.431067</td>\n",
       "      <td>2.400</td>\n",
       "      <td>15</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>14</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.971437</td>\n",
       "      <td>3.583889</td>\n",
       "      <td>1.000</td>\n",
       "      <td>14</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>15</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.168331</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>3.000</td>\n",
       "      <td>13</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>13</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.906897</td>\n",
       "      <td>3.097655</td>\n",
       "      <td>2.750</td>\n",
       "      <td>10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>13</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>HS_ENGL_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>GPA_1</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>DFW_RATE_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>GPA_2</th>\n      <th>DFW_RATE_2</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.152426</td>\n      <td>3.205086</td>\n      <td>3.125</td>\n      <td>8</td>\n      <td>0.000000</td>\n      <td>10</td>\n      <td>2.90</td>\n      <td>0.300000</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.191927</td>\n      <td>3.119864</td>\n      <td>2.250</td>\n      <td>12</td>\n      <td>0.250000</td>\n      <td>12</td>\n      <td>2.25</td>\n      <td>0.000000</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.935482</td>\n      <td>3.044736</td>\n      <td>1.500</td>\n      <td>9</td>\n      <td>0.666667</td>\n      <td>10</td>\n      <td>1.20</td>\n      <td>0.800000</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.823987</td>\n      <td>3.466105</td>\n      <td>2.000</td>\n      <td>15</td>\n      <td>0.266667</td>\n      <td>12</td>\n      <td>2.00</td>\n      <td>0.500000</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3.512793</td>\n      <td>3.794312</td>\n      <td>3.800</td>\n      <td>16</td>\n      <td>0.000000</td>\n      <td>17</td>\n      <td>3.00</td>\n      <td>0.000000</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>First Generation</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3.920177</td>\n      <td>3.093119</td>\n      <td>3.100</td>\n      <td>14</td>\n      <td>0.142857</td>\n      <td>16</td>\n      <td>3.75</td>\n      <td>0.062500</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3.193452</td>\n      <td>3.431067</td>\n      <td>2.400</td>\n      <td>15</td>\n      <td>0.200000</td>\n      <td>14</td>\n      <td>2.20</td>\n      <td>0.214286</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>First Generation</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3.971437</td>\n      <td>3.583889</td>\n      <td>1.000</td>\n      <td>14</td>\n      <td>0.785714</td>\n      <td>15</td>\n      <td>2.08</td>\n      <td>0.600000</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3.168331</td>\n      <td>3.678231</td>\n      <td>3.000</td>\n      <td>13</td>\n      <td>0.076923</td>\n      <td>13</td>\n      <td>2.70</td>\n      <td>0.153846</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.906897</td>\n      <td>3.097655</td>\n      <td>2.750</td>\n      <td>10</td>\n      <td>0.300000</td>\n      <td>13</td>\n      <td>1.30</td>\n      <td>0.692308</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>First Generation</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "esam2 = esam1[selected_columns]\n",
    "esam2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dcfeb17-7e4b-4b86-9815-59085f8c4ccb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Next she runs her risk data through the feature engineering pipeline for qualitative and quantitative variables. Finally she uses our final, \"best\" model validated and selected above to predict probability of departure for each student, and uses a 0.5 threshold to classify 0's and 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61247cf9-f64d-4ee7-ab70-a8db27139fa3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning:\n\nIn a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NAME</th>\n",
       "      <th>SID</th>\n",
       "      <th>ENROLLMENT_YEAR</th>\n",
       "      <th>ENROLLMENT_TERM</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>RACE_ETHNICITY</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>FIRST_GEN_STATUS</th>\n",
       "      <th>HS_GPA</th>\n",
       "      <th>HS_MATH_GPA</th>\n",
       "      <th>HS_ENGL_GPA</th>\n",
       "      <th>COLLEGE</th>\n",
       "      <th>FIRST_SEM_W</th>\n",
       "      <th>UNITS_ATTEMPTED_1</th>\n",
       "      <th>UNITS_COMPLETED_1</th>\n",
       "      <th>DFW_UNITS_1</th>\n",
       "      <th>GPA_1</th>\n",
       "      <th>CUM_GPA_1</th>\n",
       "      <th>UNITS_ATTEMPTED_2</th>\n",
       "      <th>UNITS_COMPLETED_2</th>\n",
       "      <th>DFW_UNITS_2</th>\n",
       "      <th>GPA_2</th>\n",
       "      <th>CUM_GPA_2</th>\n",
       "      <th>DFW_RATE_1</th>\n",
       "      <th>DFW_RATE_2</th>\n",
       "      <th>GRADE_POINTS_1</th>\n",
       "      <th>GRADE_POINTS_2</th>\n",
       "      <th>Pred_SEM_3_STATUS_prob</th>\n",
       "      <th>Pred_SEM_3_STATUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Peggy</td>\n",
       "      <td>000ABCDE1</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.972042</td>\n",
       "      <td>3.093119</td>\n",
       "      <td>3.920177</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3.100</td>\n",
       "      <td>3.100</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.500</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>43.4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.091473</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Tasha</td>\n",
       "      <td>000VJZY7Q</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.890517</td>\n",
       "      <td>3.794312</td>\n",
       "      <td>3.512793</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.800</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.8</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.127277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Bethany</td>\n",
       "      <td>000M7YLAX</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.702649</td>\n",
       "      <td>3.119864</td>\n",
       "      <td>3.191927</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.250</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.291826</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>000ABCDE4</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Black or African American</td>\n",
       "      <td>Female</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.525838</td>\n",
       "      <td>3.678231</td>\n",
       "      <td>3.168331</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.890</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>39.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.451064</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Fred</td>\n",
       "      <td>000ABCDE2</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.502444</td>\n",
       "      <td>3.431067</td>\n",
       "      <td>3.193452</td>\n",
       "      <td>Business</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2.400</td>\n",
       "      <td>2.400</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.308</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>36.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>0.452450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jaime</td>\n",
       "      <td>000GPJ93V</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.970239</td>\n",
       "      <td>3.205086</td>\n",
       "      <td>3.152426</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.125</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.667733</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Alex</td>\n",
       "      <td>000ABCDE3</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>Continuing Generation</td>\n",
       "      <td>3.938181</td>\n",
       "      <td>3.583889</td>\n",
       "      <td>3.971437</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.840</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.696773</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Kent</td>\n",
       "      <td>000O3VNKL</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Asian</td>\n",
       "      <td>Male</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.282063</td>\n",
       "      <td>3.466105</td>\n",
       "      <td>3.823987</td>\n",
       "      <td>Science</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.733894</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Ana</td>\n",
       "      <td>000ABCDE5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.639249</td>\n",
       "      <td>3.097655</td>\n",
       "      <td>3.906897</td>\n",
       "      <td>Liberal Arts</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2.750</td>\n",
       "      <td>2.750</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.875</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>27.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>0.918486</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Marisol</td>\n",
       "      <td>000NSOJN5</td>\n",
       "      <td>2021</td>\n",
       "      <td>Fall</td>\n",
       "      <td>20214</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Female</td>\n",
       "      <td>First Generation</td>\n",
       "      <td>3.751494</td>\n",
       "      <td>3.044736</td>\n",
       "      <td>2.935482</td>\n",
       "      <td>Health</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1.500</td>\n",
       "      <td>1.500</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.300</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.961784</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>NAME</th>\n      <th>SID</th>\n      <th>ENROLLMENT_YEAR</th>\n      <th>ENROLLMENT_TERM</th>\n      <th>COHORT</th>\n      <th>RACE_ETHNICITY</th>\n      <th>GENDER</th>\n      <th>FIRST_GEN_STATUS</th>\n      <th>HS_GPA</th>\n      <th>HS_MATH_GPA</th>\n      <th>HS_ENGL_GPA</th>\n      <th>COLLEGE</th>\n      <th>FIRST_SEM_W</th>\n      <th>UNITS_ATTEMPTED_1</th>\n      <th>UNITS_COMPLETED_1</th>\n      <th>DFW_UNITS_1</th>\n      <th>GPA_1</th>\n      <th>CUM_GPA_1</th>\n      <th>UNITS_ATTEMPTED_2</th>\n      <th>UNITS_COMPLETED_2</th>\n      <th>DFW_UNITS_2</th>\n      <th>GPA_2</th>\n      <th>CUM_GPA_2</th>\n      <th>DFW_RATE_1</th>\n      <th>DFW_RATE_2</th>\n      <th>GRADE_POINTS_1</th>\n      <th>GRADE_POINTS_2</th>\n      <th>Pred_SEM_3_STATUS_prob</th>\n      <th>Pred_SEM_3_STATUS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>Peggy</td>\n      <td>000ABCDE1</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.972042</td>\n      <td>3.093119</td>\n      <td>3.920177</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>14</td>\n      <td>12</td>\n      <td>2</td>\n      <td>3.100</td>\n      <td>3.100</td>\n      <td>16</td>\n      <td>15</td>\n      <td>1</td>\n      <td>3.75</td>\n      <td>3.500</td>\n      <td>0.142857</td>\n      <td>0.062500</td>\n      <td>43.4</td>\n      <td>60.0</td>\n      <td>0.091473</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Tasha</td>\n      <td>000VJZY7Q</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.890517</td>\n      <td>3.794312</td>\n      <td>3.512793</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>16</td>\n      <td>16</td>\n      <td>0</td>\n      <td>3.800</td>\n      <td>3.800</td>\n      <td>17</td>\n      <td>17</td>\n      <td>0</td>\n      <td>3.00</td>\n      <td>3.400</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>60.8</td>\n      <td>51.0</td>\n      <td>0.127277</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Bethany</td>\n      <td>000M7YLAX</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.702649</td>\n      <td>3.119864</td>\n      <td>3.191927</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>12</td>\n      <td>9</td>\n      <td>3</td>\n      <td>2.250</td>\n      <td>2.250</td>\n      <td>12</td>\n      <td>12</td>\n      <td>0</td>\n      <td>2.25</td>\n      <td>2.250</td>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>27.0</td>\n      <td>27.0</td>\n      <td>0.291826</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>Kelly</td>\n      <td>000ABCDE4</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Black or African American</td>\n      <td>Female</td>\n      <td>Continuing Generation</td>\n      <td>3.525838</td>\n      <td>3.678231</td>\n      <td>3.168331</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>13</td>\n      <td>12</td>\n      <td>1</td>\n      <td>3.000</td>\n      <td>3.000</td>\n      <td>13</td>\n      <td>11</td>\n      <td>2</td>\n      <td>2.70</td>\n      <td>2.890</td>\n      <td>0.076923</td>\n      <td>0.153846</td>\n      <td>39.0</td>\n      <td>35.1</td>\n      <td>0.451064</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>Fred</td>\n      <td>000ABCDE2</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.502444</td>\n      <td>3.431067</td>\n      <td>3.193452</td>\n      <td>Business</td>\n      <td>0</td>\n      <td>15</td>\n      <td>12</td>\n      <td>3</td>\n      <td>2.400</td>\n      <td>2.400</td>\n      <td>14</td>\n      <td>11</td>\n      <td>3</td>\n      <td>2.20</td>\n      <td>2.308</td>\n      <td>0.200000</td>\n      <td>0.214286</td>\n      <td>36.0</td>\n      <td>30.8</td>\n      <td>0.452450</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Jaime</td>\n      <td>000GPJ93V</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.970239</td>\n      <td>3.205086</td>\n      <td>3.152426</td>\n      <td>Engineering</td>\n      <td>0</td>\n      <td>8</td>\n      <td>8</td>\n      <td>0</td>\n      <td>3.125</td>\n      <td>3.125</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.90</td>\n      <td>3.050</td>\n      <td>0.000000</td>\n      <td>0.300000</td>\n      <td>25.0</td>\n      <td>29.0</td>\n      <td>0.667733</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>Alex</td>\n      <td>000ABCDE3</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>Continuing Generation</td>\n      <td>3.938181</td>\n      <td>3.583889</td>\n      <td>3.971437</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>14</td>\n      <td>3</td>\n      <td>11</td>\n      <td>1.000</td>\n      <td>1.000</td>\n      <td>15</td>\n      <td>6</td>\n      <td>9</td>\n      <td>2.08</td>\n      <td>1.840</td>\n      <td>0.785714</td>\n      <td>0.600000</td>\n      <td>14.0</td>\n      <td>31.2</td>\n      <td>0.696773</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Kent</td>\n      <td>000O3VNKL</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Asian</td>\n      <td>Male</td>\n      <td>First Generation</td>\n      <td>3.282063</td>\n      <td>3.466105</td>\n      <td>3.823987</td>\n      <td>Science</td>\n      <td>0</td>\n      <td>15</td>\n      <td>11</td>\n      <td>4</td>\n      <td>2.000</td>\n      <td>2.000</td>\n      <td>12</td>\n      <td>6</td>\n      <td>6</td>\n      <td>2.00</td>\n      <td>2.000</td>\n      <td>0.266667</td>\n      <td>0.500000</td>\n      <td>30.0</td>\n      <td>24.0</td>\n      <td>0.733894</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>Ana</td>\n      <td>000ABCDE5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>White</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.639249</td>\n      <td>3.097655</td>\n      <td>3.906897</td>\n      <td>Liberal Arts</td>\n      <td>0</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2.750</td>\n      <td>2.750</td>\n      <td>13</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1.30</td>\n      <td>1.875</td>\n      <td>0.300000</td>\n      <td>0.692308</td>\n      <td>27.5</td>\n      <td>16.9</td>\n      <td>0.918486</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Marisol</td>\n      <td>000NSOJN5</td>\n      <td>2021</td>\n      <td>Fall</td>\n      <td>20214</td>\n      <td>Hispanic</td>\n      <td>Female</td>\n      <td>First Generation</td>\n      <td>3.751494</td>\n      <td>3.044736</td>\n      <td>2.935482</td>\n      <td>Health</td>\n      <td>0</td>\n      <td>9</td>\n      <td>3</td>\n      <td>6</td>\n      <td>1.500</td>\n      <td>1.500</td>\n      <td>10</td>\n      <td>2</td>\n      <td>8</td>\n      <td>1.20</td>\n      <td>1.300</td>\n      <td>0.666667</td>\n      <td>0.800000</td>\n      <td>13.5</td>\n      <td>12.0</td>\n      <td>0.961784</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "esam3 = pd.DataFrame(preprocessor.fit_transform(esam2),columns=all_column_names)\n",
    "esam4 = esam3[selected_features]\n",
    "esam_sm = sm.add_constant(esam4)\n",
    "\n",
    "esam1['Pred_SEM_3_STATUS_prob'] = lrs1.predict(esam_sm)\n",
    "esam1['Pred_SEM_3_STATUS'] = list(map(round,lrs1.predict(esam_sm)))\n",
    "esam1.sort_values(by='Pred_SEM_3_STATUS_prob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3786036f-c25f-43c2-af9c-d78777ee3f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Addressing the Higher Ed Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b94fe31-1334-4b5e-8e5a-82dc2bca5597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The model predicts Marisol, Alex, Ana and Kent to be in danger of leaving the university before the start of the next semester. Given that our test precision is about 22%, she understands that not all students predicted to be 1 will actually depart; and not all students predicted to stay will. So she utilizes the predictions as a starting point, synthesizes it with her findings from the focus group and literature, and identifies Kent and Marisol as at particular risk for dropping out. She arranges time to meet with them to ensure that they have the academic and socio-emotional support they need. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "570e400a-4f63-47de-9d21-58214f054d3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#HOMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "432fa7bb-37b1-4cd1-a840-bff727559117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MODULE X: Logistic Classification with Statsmodels",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
